{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Ingest data on Google Earth Engine\n",
    "-------------------------------------------------------------------------------\n",
    "This notebook will upload the geotiff files from the Google Cloud Storage to\n",
    "the WRI/aqueduct earthengine bucket. \n",
    "\n",
    "Requirements:\n",
    "    Authorize earthengine by running in your terminal: earthengine \n",
    "                                                       authenticate\n",
    "\n",
    "    you need to have access to the WRI-Aquaduct (yep a Google employee made a\n",
    "    typo) bucket to ingest the data. Rutger can grant access to write to this \n",
    "    folder. \n",
    "\n",
    "    Have access to the Google Cloud Storage Bucker\n",
    "\n",
    "Make sure to set the project to Aqueduct30 by running\n",
    "`gcloud config set project aqueduct30`\n",
    "\n",
    "Code follows the Google for Python Styleguide. Exception are the scripts that \n",
    "use earth engine since this is camelCase instead of underscore.\n",
    "\n",
    "Author: Rutger Hofste\n",
    "Date: 20170802\n",
    "Kernel: python27\n",
    "Docker: rutgerhofste/gisdocker:ubuntu16.04\n",
    "\n",
    "Args:    \n",
    "    TESTING (Boolean) : Toggle Testing Mode.\n",
    "    OVERWRITE (Boolean) : Overwrite old folder !CAUTION!\n",
    "    SCRIPT_NAME (string) : Script name.\n",
    "    GCS_BASE (string) : Google Cloud Storage namespace.\n",
    "    EE_BASE (string) : Earth Engine folder to store the imageCollections\n",
    "    OUTPUT_FILE_NAME (string) : File Name for a csv file containing the failed tasks. \n",
    "    S3_OUTPUT_PATH (string) : Amazon S3 Output path.\n",
    "\n",
    "Returns:\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Input Parameters\n",
    "\n",
    "TESTING = 1\n",
    "OVERWRITE = 1 # !CAUTION!\n",
    "SCRIPT_NAME = \"Y2017M08D02_RH_Ingest_GCS_EE_V02\"\n",
    "GCS_BASE = \"gs://aqueduct30_v01/Y2017M08D02_RH_Upload_to_GoogleCS_V02/\"\n",
    "EE_BASE = \"projects/WRI-Aquaduct/PCRGlobWB20V08\"\n",
    "OUTPUT_FILE_NAME = \"df_errorsV01.csv\"\n",
    "S3_OUTPUT_PATH = \"s3://wri-projects/Aqueduct30/processData/{}/output\".format(SCRIPT_NAME)\n",
    "\n",
    "# Output Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Y2018M04D05', 'UTC 11:56')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.7.14 |Anaconda, Inc.| (default, Dec  7 2017, 17:05:42) \\n[GCC 7.2.0]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time, datetime, sys\n",
    "dateString = time.strftime(\"Y%YM%mD%d\")\n",
    "timeString = time.strftime(\"UTC %H:%M\")\n",
    "start = datetime.datetime.now()\n",
    "print(dateString,timeString)\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import subprocess\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import aqueduct3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "earthengine rm -r projects/WRI-Aquaduct/PCRGlobWB20V08\n",
      "earthengine create folder projects/WRI-Aquaduct/PCRGlobWB20V08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ETL\n",
    "\n",
    "ec2_output_path = \"/volumes/data/{}/output\".format(SCRIPT_NAME)\n",
    "\n",
    "if OVERWRITE:\n",
    "    command = \"earthengine rm -r {}\".format(EE_BASE)\n",
    "    print(command)\n",
    "    subprocess.check_output(command,shell=True)\n",
    "\n",
    "command = \"earthengine create folder {}\".format(EE_BASE)\n",
    "print(command)\n",
    "subprocess.check_output(command,shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def split_key(key):\n",
    "    \"\"\" Split key into dictionary\n",
    "    -------------------------------------------------------------------------------\n",
    "    WARNING: This function is dependant on the name convention of PCRGLOBWB\n",
    "    Do not use with other keys\n",
    "    \n",
    "    Args:\n",
    "        key (string) : key containing information about parameter, year month etc.\n",
    "        \n",
    "    Returns:\n",
    "        out_dict (dictionary): Dictionary containing all information contained\n",
    "                               in key.      \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # will yield the root file code and extension of a set of keys\n",
    "    prefix, extension = key.split(\".\")\n",
    "    file_name = prefix.split(\"/\")[-1]\n",
    "    parameter = file_name[:-12]\n",
    "    month = file_name[-2:] #can also do this with regular expressions if you like\n",
    "    year = file_name[-7:-3]\n",
    "    identifier = file_name[-11:-8]\n",
    "    out_dict = {\"file_name\":file_name,\"extension\":extension,\"parameter\":parameter,\"month\":month,\"year\":year,\"identifier\":identifier}\n",
    "    return out_dict\n",
    "\n",
    "def split_parameter(parameter):\n",
    "    \"\"\"Split parameter \n",
    "    -------------------------------------------------------------------------------\n",
    "    WARNING: This function is dependant on the name convention of PCRGLOBWB\n",
    "    Do not use with other keys.\n",
    "    \n",
    "    Args:\n",
    "        parameter (string) : parameter string.\n",
    "    \n",
    "    Returns:\n",
    "        out_dict (dictionary) : dictionary containing all information contained\n",
    "                                in parameter key.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    values = re.split(\"_|-\", parameter) #soilmoisture uses a hyphen instead of underscore between the years\n",
    "    keys = [\"geographic_range\",\"temporal_range\",\"indicator\",\"temporal_resolution\",\"units\",\"spatial_resolution\",\"temporal_range_min\",\"temporal_range_max\"]\n",
    "    # ['global', 'historical', 'PDomWN', 'month', 'millionm3', '5min', '1960', '2014']\n",
    "    out_dict = dict(zip(keys, values))\n",
    "    out_dict[\"parameter\"] = parameter\n",
    "    return out_dict\n",
    "\n",
    "\n",
    "def get_GCS_keys(GCS_BASE):\n",
    "    \"\"\" get list of keys from Google Cloud Storage\n",
    "    -------------------------------------------------------------------------------\n",
    "    \n",
    "    Args:\n",
    "        GCS_BASE (string) : Google Cloud Storage namespace containing files.\n",
    "        \n",
    "    Returns:\n",
    "        df (pd.DataFrame) : DataFrame with properties useful to Aqueduct. \n",
    "    \n",
    "    \"\"\"\n",
    "    command = \"/opt/google-cloud-sdk/bin/gsutil ls {}\".format(GCS_BASE)\n",
    "    keys = subprocess.check_output(command,shell=True)\n",
    "    keys = keys.decode('UTF-8').splitlines()\n",
    "    \n",
    "    df = keys_to_df(keys)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def keys_to_df(keys):\n",
    "    \"\"\" helper function for 'get_GCS_keys'\n",
    "    \n",
    "    Args:\n",
    "        keys (list) : list of strings with keys.\n",
    "        \n",
    "    Returns:\n",
    "        df (pd.DataFrame) : Pandas DataFrame with all relvant properties for\n",
    "                            Aqueduct 3.0.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    i = 0\n",
    "    for key in keys:\n",
    "        i = i+1\n",
    "        out_dict = split_key(key)\n",
    "        df2 = pd.DataFrame(out_dict,index=[i])\n",
    "        df = df.append(df2)    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9290, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_GCS_keys(GCS_BASE)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'subprocess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-171f01177a45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparameter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mic_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEE_BASE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mparameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maqueduct3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_imageCollection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mic_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/volumes/repos/Aqueduct30Docker/notebooks/production/aqueduct3.py\u001b[0m in \u001b[0;36mcreate_imageCollection\u001b[0;34m(ic_id)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \"\"\"\n\u001b[1;32m    307\u001b[0m     \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"earthengine create collection {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mic_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'subprocess' is not defined"
     ]
    }
   ],
   "source": [
    "# Create ImageCollections\n",
    "parameters = df.parameter.unique()\n",
    "for parameter in parameters:\n",
    "    ic_id = EE_BASE + \"/\" + parameter\n",
    "    command, result = aqueduct3.create_imageCollection(ic_id)\n",
    "    print(command,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Dataframe\n",
    "df_parameter = pd.DataFrame()\n",
    "i = 0\n",
    "for parameter in parameters:\n",
    "    i = i+1\n",
    "    out_dict_parameter = split_parameter(parameter)\n",
    "    df_parameter2 = pd.DataFrame(out_dict_parameter,index=[i])\n",
    "    df_parameter = df_parameter.append(df_parameter2)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parameter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_complete = df.merge(df_parameter,how='left',left_on='parameter',right_on='parameter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding NoData value, ingested_by and exportdescription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_complete[\"nodata_value\"] = -9999\n",
    "df_complete[\"ingested_by\"] =\"RutgerHofste\"\n",
    "df_complete[\"exportdescription\"] = df_complete[\"indicator\"] + \"_\" + df_complete[\"temporal_resolution\"]+\"Y\"+df_complete[\"year\"]+\"M\"+df_complete[\"month\"]\n",
    "df_complete[\"script_used\"] = SCRIPT_NAME\n",
    "df_complete = df_complete.apply(pd.to_numeric, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_complete.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if TESTING:\n",
    "    df_complete = df_complete[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_errors = pd.DataFrame()\n",
    "start_time = time.time()\n",
    "for index, row in df_complete.iterrows():\n",
    "    elapsed_time = time.time() - start_time \n",
    "    print(index,\"%.2f\" %((index/df_complete.shape[0])*100), \"elapsed: \", str(timedelta(seconds=elapsed_time)))\n",
    "    \n",
    "    geotiff_gcs_path = GCS_BASE + row.file_name + \".\" + row.extension\n",
    "    output_ee_asset_id = EE_BASE +\"/\"+ row.parameter + \"/\" + row.file_name\n",
    "    properties = row.to_dict()\n",
    "    \n",
    "    df_errors2 = upload_geotiff_to_EE_imageCollection(geotiff_gcs_path, output_ee_asset_id, properties)\n",
    "    df_errors = df_errors.append(df_errors2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p {ec2_output_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_errors.to_csv(\"{}/{}\".format(ec2_output_path,OUTPUT_FILE_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp  {ec2_output_path} {S3_OUTPUT_PATH} --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retry the ones with errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_retry = df_errors.loc[df_errors['error'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index, row in df_retry.iterrows():\n",
    "    response = subprocess.check_output(row.command, shell=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uniques = df_errors[\"error\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print(elapsed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 27",
   "language": "python",
   "name": "python27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
