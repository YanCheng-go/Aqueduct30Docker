{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Table:  y2018m07d30_rh_coalesce_columns_v01_v01 \n",
      "Output ec2:  /volumes/data/Y2018M07D17_RH_RDS_To_S3_V02/output_V02/ \n",
      "Output s3:  s3://wri-projects/Aqueduct30/processData/Y2018M07D17_RH_RDS_To_S3_V02/output_V02/ \n",
      "Output gcs:  gs://aqueduct30_v01/Y2018M07D17_RH_RDS_To_S3_V02/output_V02/\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Convert RDS table to csv files on S3 and GCS\n",
    "-------------------------------------------------------------------------------\n",
    "\n",
    "After the files are stored on GCS, use the BigQuery Web UI to load the csv \n",
    "files in a table. \n",
    "\n",
    "Author: Rutger Hofste\n",
    "Date: 20180712\n",
    "Kernel: python35\n",
    "Docker: rutgerhofste/gisdocker:ubuntu16.04\n",
    "\"\"\"\n",
    "\n",
    "# imports\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from retrying import retry\n",
    "from datetime import timedelta\n",
    "from sqlalchemy import *\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import multiprocessing\n",
    "\n",
    "SCRIPT_NAME = 'Y2018M07D17_RH_RDS_To_S3_V02'\n",
    "OUTPUT_VERSION = 2\n",
    "\n",
    "TESTING = 0\n",
    "\n",
    "DATABASE_ENDPOINT = \"aqueduct30v05.cgpnumwmfcqc.eu-central-1.rds.amazonaws.com\"\n",
    "DATABASE_NAME = \"database01\"\n",
    "\n",
    "INPUT_TABLE_NAME = \"y2018m07d30_rh_coalesce_columns_v01_v01\"\n",
    "\n",
    "\n",
    "\n",
    "ec2_output_path = \"/volumes/data/{}/output_V{:02.0f}/\".format(SCRIPT_NAME,OUTPUT_VERSION)\n",
    "s3_output_path = \"s3://wri-projects/Aqueduct30/processData/{}/output_V{:02.0f}/\".format(SCRIPT_NAME,OUTPUT_VERSION)\n",
    "gcs_output_path = \"gs://aqueduct30_v01/{}/output_V{:02.0f}/\".format(SCRIPT_NAME,OUTPUT_VERSION)\n",
    "\n",
    "print(\"Input Table: \" , INPUT_TABLE_NAME,\n",
    "      \"\\nOutput ec2: \", ec2_output_path,\n",
    "      \"\\nOutput s3: \" , s3_output_path,\n",
    "      \"\\nOutput gcs: \", gcs_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y2018M07D30 UTC 12:08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.5.4 |Anaconda, Inc.| (default, Nov 20 2017, 18:44:38) \\n[GCC 7.2.0]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time, datetime, sys\n",
    "dateString = time.strftime(\"Y%YM%mD%d\")\n",
    "timeString = time.strftime(\"UTC %H:%M\")\n",
    "start = datetime.datetime.now()\n",
    "print(dateString,timeString)\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r {ec2_output_path}\n",
    "!mkdir -p {ec2_output_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F = open(\"/.password\",\"r\")\n",
    "password = F.read().splitlines()[0]\n",
    "F.close()\n",
    "\n",
    "engine = create_engine(\"postgresql://rutgerhofste:{}@{}:5432/{}\".format(password,DATABASE_ENDPOINT,DATABASE_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power to the maxxx: 2\n"
     ]
    }
   ],
   "source": [
    "cpu_count = multiprocessing.cpu_count()\n",
    "print(\"Power to the maxxx:\", cpu_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql = \"SELECT DISTINCT pfafid_30spfaf06 FROM {} ORDER BY pfafid_30spfaf06\".format(INPUT_TABLE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_sql(sql,engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if TESTING:\n",
    "    df = df[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_split = np.array_split(df, cpu_count*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def basin_to_csv(df):\n",
    "    for index, row in df.iterrows():\n",
    "        pfafid = row[\"pfafid_30spfaf06\"]\n",
    "        sql = \"SELECT * FROM {} WHERE pfafid_30spfaf06 = {}\".format(INPUT_TABLE_NAME,pfafid)\n",
    "        df_basin = pd.read_sql(sql,engine)\n",
    "        now = datetime.datetime.now()\n",
    "        df_basin[\"processed_timestamp\"] = pd.Timestamp(now)  \n",
    "        output_file_name = \"{}_V{:02.0f}.csv\".format(pfafid,OUTPUT_VERSION)\n",
    "        output_file_path = \"{}/{}\".format(ec2_output_path,output_file_name)\n",
    "        df_basin.to_csv(output_file_path)\n",
    "        print(output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p= multiprocessing.Pool()\n",
    "results_buffered = p.map(basin_to_csv,df_split)\n",
    "p.close()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!aws s3 cp {ec2_output_path} {s3_output_path} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!gsutil -m cp \\\n",
    "{ec2_output_path}/*.csv \\\n",
    "{gcs_output_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print(elapsed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 35",
   "language": "python",
   "name": "python35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
