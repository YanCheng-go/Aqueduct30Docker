{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input gcs:  gs://aqueduct30_v01/Y2018M07D17_RH_RDS_To_S3_V02/output_V09/ \n",
      "Output bq dataset name:  aqueduct30v01 \n",
      "Output bq table name:  y2018m07d30_rh_gcs_to_bq_v01_v06\n"
     ]
    }
   ],
   "source": [
    "# ready to run\n",
    "\"\"\" Store Cloudstorage CSV files into bigquery table.\n",
    "-------------------------------------------------------------------------------\n",
    "\n",
    "Author: Rutger Hofste\n",
    "Date: 20180712\n",
    "Kernel: python35\n",
    "Docker: rutgerhofste/gisdocker:ubuntu16.04\n",
    "\"\"\"\n",
    "\n",
    "SCRIPT_NAME = 'Y2018M07D30_RH_GCS_To_BQ_V01'\n",
    "OUTPUT_VERSION = 6\n",
    "OVERWRITE_OUTPUT = 1 \n",
    "\n",
    "\n",
    "GCS_INPUT_PATH = \"gs://aqueduct30_v01/Y2018M07D17_RH_RDS_To_S3_V02/output_V09/\"\n",
    "\n",
    "DATABASE_ENDPOINT = \"aqueduct30v05.cgpnumwmfcqc.eu-central-1.rds.amazonaws.com\"\n",
    "DATABASE_NAME = \"database01\"\n",
    "INPUT_TABLE_NAME = \"y2018m07d30_rh_coalesce_columns_v01_v07\" #For header\n",
    "\n",
    "\n",
    "OUTPUT_DATASET_NAME = \"aqueduct30v01\"\n",
    "OUTPUT_TABLE_NAME = \"{}_v{:02.0f}\".format(SCRIPT_NAME,OUTPUT_VERSION).lower()\n",
    "\n",
    "print(\"Input gcs: \", GCS_INPUT_PATH,\n",
    "      \"\\nOutput bq dataset name: \", OUTPUT_DATASET_NAME,\n",
    "      \"\\nOutput bq table name: \", OUTPUT_TABLE_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y2018M08D24 UTC 07:41\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.5.4 |Anaconda, Inc.| (default, Nov 20 2017, 18:44:38) \\n[GCC 7.2.0]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time, datetime, sys\n",
    "dateString = time.strftime(\"Y%YM%mD%d\")\n",
    "timeString = time.strftime(\"UTC %H:%M\")\n",
    "start = datetime.datetime.now()\n",
    "print(dateString,timeString)\n",
    "sys.version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import *\n",
    "from google.cloud import bigquery\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/.google.json\"\n",
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F = open(\"/.password\",\"r\")\n",
    "password = F.read().splitlines()[0]\n",
    "F.close()\n",
    "\n",
    "engine = create_engine(\"postgresql://rutgerhofste:{}@{}:5432/{}\".format(password,DATABASE_ENDPOINT,DATABASE_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bq_check_if_exists(dataset_name,table_name):\n",
    "    dataset_ref = client.dataset(dataset_name)\n",
    "    tables_server = list(client.list_tables(dataset_ref))\n",
    "    tables_client = list(map(lambda x: x.table_id,tables_server))\n",
    "    return table_name in tables_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bq_delete_table(dataset_name,table_name):\n",
    "    table_ref = client.dataset(dataset_name).table(table_name)\n",
    "    client.delete_table(table_ref)\n",
    "    print('Table {}:{} deleted.'.format(dataset_name, table_name))\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exists = bq_check_if_exists(OUTPUT_DATASET_NAME,OUTPUT_TABLE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if exists and OVERWRITE_OUTPUT:\n",
    "    print(\"table exists, overwriting table\")\n",
    "    bq_delete_table(OUTPUT_DATASET_NAME,OUTPUT_TABLE_NAME)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT column_name,data_type FROM information_schema.columns where table_name = 'y2018m07d30_rh_coalesce_columns_v01_v02';\n"
     ]
    }
   ],
   "source": [
    "# obtain schema from PostgreSQL\n",
    "sql =  \"SELECT column_name,data_type\"\n",
    "sql += \" FROM information_schema.columns\"\n",
    "sql += \" where table_name = '{}';\".format(INPUT_TABLE_NAME)\n",
    "print(sql)\n",
    "df = pd.read_sql(sql,engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [column_name, data_type]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SQL_to_BQ_dict(sql_type):\n",
    "    \"\"\"\n",
    "    SQL to Bigquery type (string)\n",
    "    \"\"\"\n",
    "    \n",
    "    if sql_type == \"bigint\" or sql_type == \"integer\":\n",
    "        bq_type = \"INTEGER\"\n",
    "    elif sql_type == \"text\":\n",
    "        bq_type = \"STRING\"\n",
    "    elif sql_type == \"double precision\":\n",
    "        bq_type = \"FLOAT\"\n",
    "    else:\n",
    "        bq_type = \"error!!\"\n",
    "    return bq_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schema = []\n",
    "for index, row in df.iterrows():\n",
    "    sql_type = row[\"data_type\"]\n",
    "    bq_type = SQL_to_BQ_dict(sql_type)\n",
    "    if bq_type == \"error!!\":\n",
    "        print(sql_type)\n",
    "    schema.append(bigquery.SchemaField(row[\"column_name\"], bq_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_ref = client.dataset(OUTPUT_DATASET_NAME)\n",
    "job_config = bigquery.LoadJobConfig()\n",
    "#job_config.schema = schema\n",
    "job_config.write_disposition = \"WRITE_APPEND\"\n",
    "job_config.autodetect = True\n",
    "job_config.skip_leading_rows = 1\n",
    "# The source format defaults to CSV, so the line below is optional.\n",
    "job_config.source_format = bigquery.SourceFormat.CSV\n",
    "#uri = 'gs://aqueduct30_v01/Y2018M07D17_RH_RDS_To_S3_V02/output_V02/*'\n",
    "uri = '{}*'.format(GCS_INPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting job 39dcc17e-fff1-4050-b635-de0eb9c64e93\n",
      "Job finished.\n"
     ]
    }
   ],
   "source": [
    "load_job = client.load_table_from_uri(source_uris = uri,\n",
    "                                      destination = dataset_ref.table(OUTPUT_TABLE_NAME),\n",
    "                                      job_config=job_config) \n",
    "print('Starting job {}'.format(load_job.job_id))\n",
    "load_job.result()\n",
    "print('Job finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:02:21.296729\n"
     ]
    }
   ],
   "source": [
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous runs:  \n",
    "0:03:08.852822  \n",
    "0:02:24.556886  \n",
    "0:02:31.501342  \n",
    "0:02:21.296729\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 35",
   "language": "python",
   "name": "python35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
