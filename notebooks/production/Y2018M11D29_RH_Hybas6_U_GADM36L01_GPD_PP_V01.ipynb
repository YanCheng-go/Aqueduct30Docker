{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Union of hydrobasin and GADM 36 level 1 using geopandas parallel processing.\n",
    "-------------------------------------------------------------------------------\n",
    "\n",
    "Step 1:\n",
    "Create polygons (10x10 degree, 648).\n",
    "\n",
    "Step 2:\n",
    "Clip all geodataframes with polygons (intersect).\n",
    "\n",
    "Step 3:\n",
    "Peform union per polygon.\n",
    "\n",
    "Step 4: \n",
    "Merge results into large geodataframe.\n",
    "\n",
    "Step 5:\n",
    "Dissolve on unique identifier.\n",
    "\n",
    "Step 6:\n",
    "Save output\n",
    "\n",
    "Author: Rutger Hofste\n",
    "Date: 20181128\n",
    "Kernel: python35+\n",
    "Docker: rutgerhofste/gisdocker:ubuntu16.04\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "TESTING = 1\n",
    "SCRIPT_NAME = \"Y2018M11D29_RH_Hybas6_U_GADM36L01_GPD_PP_V01\"\n",
    "OUTPUT_VERSION = 13\n",
    "\n",
    "SIMPLIFY_TOLERANCE = 0.000001 #appr. 11 cm\n",
    "\n",
    "RDS_DATABASE_ENDPOINT = \"aqueduct30v05.cgpnumwmfcqc.eu-central-1.rds.amazonaws.com\"\n",
    "RDS_DATABASE_NAME = \"database01\"\n",
    "RDS_INPUT_TABLE_LEFT = \"y2018m11d12_rh_gadm36_level1_to_rds_v01_v02\"\n",
    "RDS_INPUT_TABLE_RIGHT = \"hybas06_v04\"\n",
    "\n",
    "ec2_output_path = \"/volumes/data/{}/output_V{:02.0f}\".format(SCRIPT_NAME,OUTPUT_VERSION)\n",
    "ec2_output_path_df = \"/volumes/data/{}/outputdf_V{:02.0f}\".format(SCRIPT_NAME,OUTPUT_VERSION)\n",
    "\n",
    "s3_output_path = \"s3://wri-projects/Aqueduct30/processData/{}/output_V{:02.0f}/\".format(SCRIPT_NAME,OUTPUT_VERSION)\n",
    "s3_output_path_df = \"s3://wri-projects/Aqueduct30/processData/{}/outputdf_V{:02.0f}/\".format(SCRIPT_NAME,OUTPUT_VERSION)\n",
    "\n",
    "\n",
    "print(\"\\nec2_output_path:\", ec2_output_path,\n",
    "      \"\\ns3_output_path: \", s3_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, datetime, sys\n",
    "dateString = time.strftime(\"Y%YM%mD%d\")\n",
    "timeString = time.strftime(\"UTC %H:%M\")\n",
    "start = datetime.datetime.now()\n",
    "print(dateString,timeString)\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlalchemy\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from google.cloud import bigquery\n",
    "from shapely.geometry import MultiPolygon, Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!rm -r {ec2_output_path}\n",
    "#!rm -r {ec2_output_path}\n",
    "!mkdir -p {ec2_output_path}\n",
    "!mkdir -p {ec2_output_path_df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_count = multiprocessing.cpu_count()\n",
    "cpu_count = cpu_count -2 #Avoid freeze\n",
    "print(\"Power to the maxxx:\", cpu_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F = open(\"/.password\",\"r\")\n",
    "password = F.read().splitlines()[0]\n",
    "F.close()\n",
    "\n",
    "engine = sqlalchemy.create_engine(\"postgresql://rutgerhofste:{}@{}:5432/{}\".format(password,RDS_DATABASE_ENDPOINT,RDS_DATABASE_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cell_size = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_fishnet_gdf(cell_size):\n",
    "    crs = {'init': 'epsg:4326'}\n",
    "    lats = np.arange(-90,90,cell_size)\n",
    "    lons = np.arange(-180,180,cell_size)\n",
    "    geoms = []\n",
    "    for lat in lats:\n",
    "        for lon in lons:\n",
    "            llcr = (lon,lat)\n",
    "            lrcr = (lon+cell_size, lat)\n",
    "            urcr = (lon+cell_size, lat+cell_size)\n",
    "            ulcr = (lon, lat+ cell_size)\n",
    "            geom = Polygon([llcr,lrcr,urcr,ulcr])\n",
    "            geoms.append(geom)\n",
    "    gs = gpd.GeoSeries(geoms)\n",
    "    gdf_grid = gpd.GeoDataFrame(geometry=gs)\n",
    "    gdf_grid.crs = crs\n",
    "    return gdf_grid\n",
    "\n",
    "def post_process_geometry(geometry):\n",
    "    \"\"\" Post Process Shapely Geometries after Intersection\n",
    "    \n",
    "    Shapely does not always create the desired output geometry. When\n",
    "    vertices overlap, the result can be a geometryCollection with\n",
    "    (mutli)polygons and LineStrings or Points. \n",
    "    \n",
    "    This function converts the results of an intersection\n",
    "    \n",
    "    Args: \n",
    "        SIMPLIFY_TOLERANCE(double): Global parameter to specify \n",
    "            simplification tolerance.\n",
    "        geomerty (shapely object): GeometryCollection, Multipolygon\n",
    "            Polygon, Linestring etc.\n",
    "            \n",
    "    Returns:\n",
    "        geometry_out(shapely object): MultiPolygon or\n",
    "            Polygon of simplified geometry.\n",
    "            \n",
    "    Usage:\n",
    "        apply to geodataframe geometry column.\n",
    "    \n",
    "    \"\"\"\n",
    "    geometry_buffered = geometry.buffer(0)\n",
    "    geometry_simplified = geometry_buffered.simplify(tolerance=SIMPLIPY_TOLERANCE)\n",
    "    return geometry_simplified\n",
    "\n",
    "\n",
    "def clip_gdf(gdf_in,polygon):\n",
    "    \"\"\"\n",
    "    Clip geodataframe using shapely polygon.\n",
    "    Make sure crs is compatible.\n",
    "    \n",
    "    Removes any geometry that is (multi)polygon. i.e. LineStrings and Points are Removed\n",
    "    \n",
    "    Args:\n",
    "        gdf (GeoDataFrame): GeoDataFrame in.\n",
    "        polygon (Shapely Polygon): Polygon used for clipping\n",
    "    \n",
    "    \"\"\"\n",
    "    crs = gdf_in.crs\n",
    "    gdf_intersects = gdf_in.loc[gdf_in.geometry.intersects(polygon)]\n",
    "    df_intersects = gdf_intersects.drop(columns=[gdf_intersects.geometry.name])\n",
    "    gs_intersections = gpd.GeoSeries(gdf_intersects.geometry.intersection(polygon),crs=crs)\n",
    "    gdf_clipped = gpd.GeoDataFrame(df_intersects,geometry=gs_intersections)  \n",
    "    \n",
    "    # Some clipping results in GeometryCollections with polygons and LineStrings or Points. Convert valid geometry to Multipolygon    gdf_clipped.geometry = gdf_clipped.geometry.apply(post_process_geometry)\n",
    "    \n",
    "    return gdf_clipped\n",
    "\n",
    "\n",
    "def create_union_gdfs(gdf):\n",
    "    df_out = pd.DataFrame()\n",
    "    start = datetime.datetime.now()\n",
    "    polygon = gdf.iloc[0].geometry\n",
    "    index = gdf.index[0]\n",
    "    destination_path = \"{}/gdf_union_{}.pkl\".format(ec2_output_path,index)\n",
    "    \n",
    "    gdf_left_clipped= clip_gdf(gdf_left,polygon)\n",
    "    gdf_right_clipped = clip_gdf(gdf_right,polygon)\n",
    "    \n",
    "    print(\"gdf_left_clipped.shape[0]\",gdf_left_clipped.shape[0])\n",
    "    print(\"gdf_right_clipped.shape[0]\",gdf_right_clipped.shape[0])    \n",
    "    \n",
    "    if gdf_left_clipped.shape[0] == 0 and gdf_right_clipped.shape[0] == 0:\n",
    "        print(\"No geometry in index\", index)\n",
    "        gdf_out = None\n",
    "        write_output = False\n",
    "    elif gdf_left_clipped.shape[0] != 0 and gdf_right_clipped.shape[0] == 0:\n",
    "        print(\"Only left geometry in index\", index)\n",
    "        gdf_out = gdf_left_clipped\n",
    "        write_output = True\n",
    "    elif gdf_left_clipped.shape[0] == 0 and gdf_right_clipped.shape[0] != 0:\n",
    "        print(\"Only right geometry in index\", index)\n",
    "        gdf_out = gdf_right_clipped\n",
    "        write_output = True\n",
    "    elif gdf_left_clipped.shape[0] != 0 and gdf_right_clipped.shape[0] != 0:\n",
    "        print(\"Both geometries in index\", index)\n",
    "        gdf_union = gpd.overlay(gdf_left_clipped,gdf_right_clipped,how=\"union\")\n",
    "        gdf_out = gdf_union\n",
    "        write_output = True        \n",
    "    \n",
    "    \n",
    "    if write_output:\n",
    "        if TESTING:\n",
    "            end = datetime.datetime.now()\n",
    "            elapsed = end - start\n",
    "            gdf_out[\"time_processed\"] = elapsed.total_seconds()\n",
    "            gdf_out[\"tile_index\"] = index\n",
    "        else:\n",
    "            pass\n",
    "        gdf_out.to_pickle(path=destination_path)\n",
    "    else:\n",
    "        pass\n",
    "       \n",
    "    return  gdf_left_clipped,gdf_right_clipped\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdf_grid = create_fishnet_gdf(cell_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_grid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT\n",
    "  gid_1,\n",
    "  geom\n",
    "FROM\n",
    "  {}\n",
    "\"\"\".format(RDS_INPUT_TABLE_LEFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdf_left = gpd.read_postgis(sql=sql,\n",
    "                            con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_left.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_left.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT\n",
    "  pfaf_id,\n",
    "  geom\n",
    "FROM\n",
    "  {}\n",
    "\"\"\".format(RDS_INPUT_TABLE_RIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdf_right = gpd.read_postgis(sql=sql,\n",
    "                             con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_right.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_right.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect case for Egypt index = 417, case for Canada index = 515\n",
    "gdf_grid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gdf_grid_list = np.array_split(gdf_grid, cpu_count*10)\n",
    "gdf_grid_list = np.array_split(gdf_grid, gdf_grid.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gdf_grid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdf_grid_list_test = gdf_grid_list[417:418]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p= multiprocessing.Pool()\n",
    "df_out_list = p.map(create_union_gdfs,gdf_grid_list)\n",
    "p.close()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_out = pd.concat(df_out_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_path_df = \"{}/df_out.pkl\".format(ec2_output_path_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_out.to_pickle(output_path_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!aws s3 cp {ec2_output_path} {s3_output_path} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!aws s3 cp {ec2_output_path_df} {s3_output_path_df} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous Runs:  \n",
    "0:45:12.187817 (10x10)  \n",
    "0:44:55.686081 (10x10)  \n",
    "1:16:26.394030 (1x1 sindex=true)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 35",
   "language": "python",
   "name": "python35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
