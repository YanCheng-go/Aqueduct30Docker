{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ec2_input_path: /volumes/data/Y2019M04D15_RH_GA_Aqueduct_Results_V01/input_V05\n",
      "ec2_output_path: /volumes/data/Y2019M04D15_RH_GA_Aqueduct_Results_V01/output_V05\n",
      "s3_output_path: s3://wri-projects/Aqueduct30/finalData/Y2019M04D15_RH_GA_Aqueduct_Results_V01/output_V05/\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Share country aggregation results with external party in multiple formats. \n",
    "-------------------------------------------------------------------------------\n",
    "\n",
    "Update 2019 07 17:\n",
    "Based on discussions with WRI, we add an extra column with un-membership status.\n",
    "We remove all geometries that are non un member.\n",
    "\n",
    "Merge country and province datasets into consistent database. \n",
    "\n",
    "Please note there is an inconsistency in GADM. Countries with one province\n",
    "disappear in level 1. \n",
    "\n",
    "We merge three data sources:\n",
    "\n",
    "Indicators based on PCR-GLOBWB 2: Baseline water stress, baseline water \n",
    "depletion, interannual variability and seasonal variability.\n",
    "\n",
    "drought risk\n",
    "\n",
    "riverine flood risk\n",
    "\n",
    "\n",
    "Added on 2019 06 12:\n",
    "not all countries are well represented by the hydroBasin level 6 sub-basins\n",
    "and we decided to mask out based on inspection. \n",
    "\n",
    "\n",
    "Author: Rutger Hofste\n",
    "Date: 20190415\n",
    "Kernel: python35\n",
    "Docker: rutgerhofste/gisdocker:ubuntu16.04\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "SCRIPT_NAME = \"Y2019M04D15_RH_GA_Aqueduct_Results_V01\"\n",
    "OUTPUT_VERSION = 5\n",
    "\n",
    "\n",
    "BQ_PROJECT_ID = \"aqueduct30\"\n",
    "BQ_DATASET_NAME = \"aqueduct30v01\"\n",
    "\n",
    "BQ_INPUT_TABLE_NAME = {}\n",
    "BQ_INPUT_TABLE_NAME[\"country\"] = {}\n",
    "BQ_INPUT_TABLE_NAME[\"country\"][\"PCRGLOBWB\"] = \"y2019m01d28_rh_ga_zonal_stats_table_v01_country_v13\"\n",
    "BQ_INPUT_TABLE_NAME[\"country\"][\"drought\"] = \"y2019m04d11_rh_ga_drr_zonal_stats_table_v01_country_v06\"\n",
    "BQ_INPUT_TABLE_NAME[\"country\"][\"flood\"] = \"y2019m04d11_rh_ga_rfr_post_process_v01_country_v05\"\n",
    "\n",
    "\n",
    "BQ_INPUT_TABLE_NAME[\"province\"] = {}\n",
    "BQ_INPUT_TABLE_NAME[\"province\"][\"PCRGLOBWB\"]  = \"y2019m01d28_rh_ga_zonal_stats_table_v01_province_v13\"\n",
    "BQ_INPUT_TABLE_NAME[\"province\"][\"drought\"] = \"y2019m04d11_rh_ga_drr_zonal_stats_table_v01_province_v06\"\n",
    "BQ_INPUT_TABLE_NAME[\"province\"][\"flood\"] = \"y2019m04d11_rh_ga_rfr_post_process_v01_province_v05\"\n",
    "\n",
    "BQ_OUTPUT_TABLE_NAME = \"{}_v{:02.0f}\".format(SCRIPT_NAME,OUTPUT_VERSION).lower()\n",
    "\n",
    "S3_INPUT_PATH_VALIDHYBAS = \"s3://wri-projects/Aqueduct30/processData/Y2019M06D12_RH_GA_Check_HydroBasin6_V01/output_V01/\"\n",
    "S3_INPUT_PATH_WRIALL = \"s3://wri-projects/Aqueduct30/processData/Y2019M07D16_Rh_GA_Extra_Data_V01/input_V01\"\n",
    "S3_INPUT_PARH_POPULATION = \"s3://wri-projects/Aqueduct30/processData/Y2019M07D16_Rh_GA_Extra_Data_V01/input_V01\"\n",
    "\n",
    "\n",
    "ec2_input_path = \"/volumes/data/{}/input_V{:02.0f}\".format(SCRIPT_NAME,OUTPUT_VERSION) \n",
    "ec2_output_path = \"/volumes/data/{}/output_V{:02.0f}\".format(SCRIPT_NAME,OUTPUT_VERSION) \n",
    "\n",
    "s3_output_path = \"s3://wri-projects/Aqueduct30/finalData/{}/output_V{:02.0f}/\".format(SCRIPT_NAME,OUTPUT_VERSION)\n",
    "\n",
    "print(\"\\nec2_input_path: \" +  ec2_input_path + \n",
    "      \"\\nec2_output_path: \" + ec2_output_path + \n",
    "      \"\\ns3_output_path: \" + s3_output_path  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y2019M07D17 UTC 10:45\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.5.4 |Anaconda, Inc.| (default, Nov 20 2017, 18:44:38) \\n[GCC 7.2.0]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time, datetime, sys\n",
    "dateString = time.strftime(\"Y%YM%mD%d\")\n",
    "timeString = time.strftime(\"UTC %H:%M\")\n",
    "start = datetime.datetime.now()\n",
    "print(dateString,timeString)\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r {ec2_input_path}\n",
    "!rm -r {ec2_output_path}\n",
    "!mkdir -p {ec2_input_path}\n",
    "!mkdir -p {ec2_output_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://wri-projects/Aqueduct30/processData/Y2019M06D12_RH_GA_Check_HydroBasin6_V01/output_V01/gadm0_valid_hybas6_V01.csv to ../../../../data/Y2019M04D15_RH_GA_Aqueduct_Results_V01/input_V05/gadm0_valid_hybas6_V01.csv\n",
      "download: s3://wri-projects/Aqueduct30/processData/Y2019M06D12_RH_GA_Check_HydroBasin6_V01/output_V01/gadm0_valid_hybas6_V01.gpkg to ../../../../data/Y2019M04D15_RH_GA_Aqueduct_Results_V01/input_V05/gadm0_valid_hybas6_V01.gpkg\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp {S3_INPUT_PATH_VALIDHYBAS} {ec2_input_path} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://wri-projects/Aqueduct30/processData/Y2019M07D16_Rh_GA_Extra_Data_V01/input_V01/pop_2019.csv to ../../../../data/Y2019M04D15_RH_GA_Aqueduct_Results_V01/input_V05/pop_2019.csv\n",
      "download: s3://wri-projects/Aqueduct30/processData/Y2019M07D16_Rh_GA_Extra_Data_V01/input_V01/wri_all_countries.csv to ../../../../data/Y2019M04D15_RH_GA_Aqueduct_Results_V01/input_V05/wri_all_countries.csv\n",
      "download: s3://wri-projects/Aqueduct30/processData/Y2019M07D16_Rh_GA_Extra_Data_V01/input_V01/wri_primary_countries.csv to ../../../../data/Y2019M04D15_RH_GA_Aqueduct_Results_V01/input_V05/wri_primary_countries.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp {S3_INPUT_PATH_WRIALL} {ec2_input_path} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/.google.json\"\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = \"aqueduct30\"\n",
    "client = bigquery.Client(project=BQ_PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_df_valid_hybas():\n",
    "    input_filename= \"gadm0_valid_hybas6_V01.csv\"\n",
    "    input_path = \"{}/{}\".format(ec2_input_path,input_filename)\n",
    "    df = pd.read_csv(input_path)\n",
    "    df = df[[\"GID_0\",\"valid_hybas6\"]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_validhybas = get_df_valid_hybas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_df_wriprimary():\n",
    "    input_filename = \"wri_all_countries.csv\"\n",
    "    input_path = \"{}/{}\".format(ec2_input_path,input_filename)\n",
    "    df = pd.read_csv(input_path)\n",
    "    df = df[[\"iso_a3\",\"iso_n3\",\"primary\",\"un_region\",\"wb_region\"]]\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_wriprimary  = get_df_wriprimary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_df_population():\n",
    "    input_filename = \"pop_2019.csv\"\n",
    "    input_path = \"{}/{}\".format(ec2_input_path,input_filename)\n",
    "    df = pd.read_csv(input_path)\n",
    "    df[\"population_2019_million\"] = df[\"PopTotal\"] / 1000\n",
    "    df = df[[\"LocID\",\"population_2019_million\"]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_population = get_df_population()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_df(geographic_scale,indicator_group,table_name):\n",
    "    if geographic_scale == \"country\":\n",
    "        sql = \"\"\"\n",
    "        SELECT\n",
    "          gid_0,\n",
    "          name_0,\n",
    "          indicator_name,\n",
    "          weight,\n",
    "          score,\n",
    "          score_ranked,\n",
    "          cat,\n",
    "          label,\n",
    "          sum_weights,\n",
    "          sum_weighted_indicator,\n",
    "          count_valid,\n",
    "          fraction_valid\n",
    "        FROM\n",
    "          `{}.{}.{}`\n",
    "        \"\"\".format(BQ_PROJECT_ID,BQ_DATASET_NAME,table_name)\n",
    "    elif geographic_scale == \"province\":\n",
    "        sql = \"\"\"\n",
    "        SELECT\n",
    "          gid_1,\n",
    "          name_1,\n",
    "          gid_0,\n",
    "          name_0,\n",
    "          indicator_name,\n",
    "          weight,\n",
    "          score,\n",
    "          score_ranked,\n",
    "          cat,\n",
    "          label,\n",
    "          sum_weights,\n",
    "          sum_weighted_indicator,\n",
    "          count_valid,\n",
    "          fraction_valid\n",
    "        FROM\n",
    "          `{}.{}.{}`\n",
    "        \"\"\".format(BQ_PROJECT_ID,BQ_DATASET_NAME,table_name)\n",
    "    df = pd.read_gbq(query=sql,\n",
    "                     project_id =BQ_PROJECT_ID,\n",
    "                     dialect=\"standard\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment_df(df):\n",
    "    \"\"\"\n",
    "    Augment the dataframe with a few extra columns.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    df_out2 = pd.merge(left=df,\n",
    "                       right=df_validhybas,\n",
    "                       how=\"left\",\n",
    "                       left_on=\"gid_0\",\n",
    "                       right_on=\"GID_0\")\n",
    "    df_out2.drop(columns=[\"GID_0\"],\n",
    "                 inplace=True)\n",
    "    \n",
    "    df_out2 = pd.merge(left=df_out2,\n",
    "                       right=df_wriprimary,\n",
    "                       how=\"left\",\n",
    "                       left_on=\"gid_0\",\n",
    "                       right_on=\"iso_a3\")\n",
    "    df_out2 = pd.merge(left=df_out2,\n",
    "                       right=df_population,\n",
    "                       how=\"left\",\n",
    "                       left_on=\"iso_n3\",\n",
    "                       right_on=\"LocID\")\n",
    "    \n",
    "    \n",
    "    return df_out2\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_invalid(df):\n",
    "    \"\"\"\n",
    "    mask if fraction valid < 0.5 OR NOT hydrology_valid \n",
    "    For Riverine Flood Risk, we don't have fraction_valid. \n",
    "    \n",
    "    \"\"\"\n",
    "    cond = (((df[\"fraction_valid\"]>0.5) | (df[\"indicator_name\"] == \"rfr\" ))& (df[\"valid_hybas6\"] ==1))\n",
    "    df['score'] = np.where(cond, df[\"score\"], -9999)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_vertical(df,geographic_scale):\n",
    "    \"\"\"\n",
    "    Clean up vertical dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    if geographic_scale == \"country\":\n",
    "        columns = [\"iso_a3\",\n",
    "                   \"iso_n3\",\n",
    "                   \"primary\",\n",
    "                   \"name_0\",\n",
    "                   \"indicator_name\",\n",
    "                   \"weight\",\n",
    "                   \"score\",\n",
    "                   \"score_ranked\",\n",
    "                   \"cat\",\n",
    "                   \"label\",\n",
    "                   \"sum_weights\",\n",
    "                   \"sum_weighted_indicator\",\n",
    "                   \"count_valid\",\n",
    "                   \"fraction_valid\",\n",
    "                   \"valid_hybas6\",                   \n",
    "                   \"un_region\",\n",
    "                   \"wb_region\",\n",
    "                   \"population_2019_million\"\n",
    "                   ]\n",
    "    elif geographic_scale == \"province\":\n",
    "        columns = [\"gid_1\",\n",
    "                   \"name_1\",\n",
    "                   \"iso_a3\",\n",
    "                   \"iso_n3\",\n",
    "                   \"primary\",\n",
    "                   \"name_0\",\n",
    "                   \"indicator_name\",\n",
    "                   \"weight\",\n",
    "                   \"score\",\n",
    "                   \"score_ranked\",\n",
    "                   \"cat\",\n",
    "                   \"label\",\n",
    "                   \"sum_weights\",\n",
    "                   \"sum_weighted_indicator\",\n",
    "                   \"count_valid\",\n",
    "                   \"fraction_valid\",\n",
    "                   \"valid_hybas6\",                   \n",
    "                   \"un_region\",\n",
    "                   \"wb_region\",\n",
    "                   \"population_2019_million\"\n",
    "                   ]\n",
    "    df_out = df[columns]\n",
    "    return df_out\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "province drought y2019m04d11_rh_ga_drr_zonal_stats_table_v01_province_v06\n",
      "province flood y2019m04d11_rh_ga_rfr_post_process_v01_province_v05\n",
      "province PCRGLOBWB y2019m01d28_rh_ga_zonal_stats_table_v01_province_v13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/python35/lib/python3.5/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "11it [00:51,  5.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country drought y2019m04d11_rh_ga_drr_zonal_stats_table_v01_country_v06\n",
      "country flood y2019m04d11_rh_ga_rfr_post_process_v01_country_v05\n",
      "country PCRGLOBWB y2019m01d28_rh_ga_zonal_stats_table_v01_country_v13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:03,  3.61s/it]\n"
     ]
    }
   ],
   "source": [
    "dict_out = {}\n",
    "for geographic_scale, dictje  in BQ_INPUT_TABLE_NAME.items():\n",
    "    df_out = pd.DataFrame()\n",
    "    for indicator_group, table_name in dictje.items():\n",
    "        print(geographic_scale,indicator_group,table_name)\n",
    "        \n",
    "        df = get_df(geographic_scale,indicator_group,table_name)\n",
    "        df_out = df_out.append(df)\n",
    "    \n",
    "    \n",
    "    df_out2 = augment_df(df_out)\n",
    "    df_out3 = mask_invalid(df_out2)\n",
    "\n",
    "\n",
    "    #df_out3[\"score_ranked_all\"] = df_out3.groupby(by=[\"indicator_name\",\"weight\"])[\"score\"].rank(ascending=False,method=\"min\")\n",
    "    # Only primary (UN member) countries: \n",
    "    df_out4 = df_out3.loc[df_out3[\"primary\"] == 1]\n",
    "    df_out4[\"score_ranked\"] =  df_out4.groupby(by=[\"indicator_name\",\"weight\"])[\"score\"].rank(ascending=False,method=\"min\")\n",
    "\n",
    "    dict_out[geographic_scale] = clean_vertical(df_out4,geographic_scale)\n",
    "    \n",
    "    output_file_path_ec2 = \"{}/{}_{}_V{:02.0f}.csv\".format(ec2_output_path,SCRIPT_NAME,geographic_scale,OUTPUT_VERSION)\n",
    "    dict_out[geographic_scale].to_csv(path_or_buf=output_file_path_ec2,index=True)\n",
    "    destination_table = \"{}.{}_{}_V{:02.0f}\".format(BQ_DATASET_NAME,SCRIPT_NAME,geographic_scale,OUTPUT_VERSION).lower()\n",
    "\n",
    "    dict_out[geographic_scale].to_gbq(destination_table=destination_table,\n",
    "                  project_id=BQ_PROJECT_ID,\n",
    "                  if_exists=\"replace\")\n",
    "\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ../../../../data/Y2019M04D15_RH_GA_Aqueduct_Results_V01/output_V05/Y2019M04D15_RH_GA_Aqueduct_Results_V01_country_V05.csv to s3://wri-projects/Aqueduct30/finalData/Y2019M04D15_RH_GA_Aqueduct_Results_V01/output_V05/Y2019M04D15_RH_GA_Aqueduct_Results_V01_country_V05.csv\n",
      "upload: ../../../../data/Y2019M04D15_RH_GA_Aqueduct_Results_V01/output_V05/Y2019M04D15_RH_GA_Aqueduct_Results_V01_province_V05.csv to s3://wri-projects/Aqueduct30/finalData/Y2019M04D15_RH_GA_Aqueduct_Results_V01/output_V05/Y2019M04D15_RH_GA_Aqueduct_Results_V01_province_V05.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp {ec2_output_path} {s3_output_path} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:01:43.278152\n"
     ]
    }
   ],
   "source": [
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous runs:  \n",
    "0:01:55.346004\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 35",
   "language": "python",
   "name": "python35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
