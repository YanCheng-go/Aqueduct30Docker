{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3_INPUT_PATH:  s3://wri-projects/Aqueduct30/finalData/Floods \n",
      "ec2_input_path:  /volumes/data/Y2019M04D11_RH_GA_RFR_Post_Process_V01/input_V04 \n",
      "ec2_output_path:  /volumes/data/Y2019M04D11_RH_GA_RFR_Post_Process_V01/output_V04 \n",
      "s3_output_path: s3://wri-projects/Aqueduct30/processData/Y2019M04D11_RH_GA_RFR_Post_Process_V01/output_V04/\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Post process aggregations from riverine flood risk.\n",
    "-------------------------------------------------------------------------------\n",
    "\n",
    "Riverine flood risk calculated per province and country by research partner.\n",
    "\n",
    "impacted_pop -> sum_weighted_indicator\n",
    "total_pop -> sum_weights\n",
    "\n",
    "Please note there is an inconsistency in GADM. Countries with one province\n",
    "disappear in level 1. \n",
    "\n",
    "Author: Rutger Hofste\n",
    "Date: 20190411\n",
    "Kernel: python35\n",
    "Docker: rutgerhofste/gisdocker:ubuntu16.04\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "SCRIPT_NAME = \"Y2019M04D11_RH_GA_RFR_Post_Process_V01\"\n",
    "OUTPUT_VERSION = 4\n",
    "\n",
    "S3_INPUT_PATH = \"s3://wri-projects/Aqueduct30/finalData/Floods\"\n",
    "INPUT_FILE_NAME_PROVINCE = \"flood_State_results.csv\"\n",
    "INPUT_FILE_NAME_COUNTRY = \"flood_Country_results.csv\"\n",
    "\n",
    "# Updating labels to new format\n",
    "labels_dict_country = {\n",
    "\"Low (0 to 2 in 1,000)\" : \"Low (0 to 2 in 1,000)\",\n",
    "\"Low to medium (2 in 1,000 to 4 in 1,000)\" : \"Low - Medium (2 in 1,000 to 4 in 1,000)\",\n",
    "\"Medium to high (4 in 1,000 to 8 in 1,000)\" : \"Medium - High (4 in 1,000 to 8 in 1,000)\",\n",
    "\"High (8 in 1,000 to 1 in 100)\" : \"High (8 in 1,000 to 1 in 100)\",\n",
    "\"Extremely High (more than 1 in 100)\":\"Extremely High (more than 1 in 100)\"\n",
    "}\n",
    "\n",
    "labels_dict_province = {\n",
    "\"Low (0 to 1 in 1,000)\" : \"Low (0 to 1 in 1,000)\",\n",
    "\"Low to medium (1 in 1,000 to 3 in 1,000)\" : \"Low - Medium (1 in 1,000 to 3 in 1,000)\" ,\n",
    "\"Medium to high (3 in 1,000 to 7 in 1,000)\" : \"Medium - High (3 in 1,000 to 7 in 1,000)\",\n",
    "\"High (7 in 1,000 to 1 in 100)\" : \"High (7 in 1,000 to 1 in 100)\",\n",
    "\"Extremely High (more than 1 in 100)\" : \"Extremely High (more than 1 in 100)\"\n",
    "}\n",
    "\n",
    "BQ_PROJECT_ID = \"aqueduct30\"\n",
    "BQ_DATASET_NAME = \"aqueduct30v01\"\n",
    "BQ_INPUT_TABLE_NAME_LABEL = \"y2018m12d04_rh_master_merge_rawdata_gpd_v02_v09\"\n",
    "BQ_INPUT_TABLE_NAME_GADM  = \"y2018m11d12_rh_gadm36_level1_rds_to_bq_v01_v01\"\n",
    "BQ_OUTPUT_TABLE_NAME = \"{}_v{:02.0f}\".format(SCRIPT_NAME,OUTPUT_VERSION).lower()\n",
    "\n",
    "ec2_input_path = \"/volumes/data/{}/input_V{:02.0f}\".format(SCRIPT_NAME,OUTPUT_VERSION) \n",
    "ec2_output_path = \"/volumes/data/{}/output_V{:02.0f}\".format(SCRIPT_NAME,OUTPUT_VERSION) \n",
    "\n",
    "s3_output_path = \"s3://wri-projects/Aqueduct30/processData/{}/output_V{:02.0f}/\".format(SCRIPT_NAME,OUTPUT_VERSION)\n",
    "\n",
    "print(\"S3_INPUT_PATH: \",S3_INPUT_PATH,\n",
    "      \"\\nec2_input_path: \",ec2_input_path,\n",
    "      \"\\nec2_output_path: \",ec2_output_path,\n",
    "      \"\\ns3_output_path: \" + s3_output_path  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y2019M04D15 UTC 14:51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.5.4 |Anaconda, Inc.| (default, Nov 20 2017, 18:44:38) \\n[GCC 7.2.0]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time, datetime, sys\n",
    "dateString = time.strftime(\"Y%YM%mD%d\")\n",
    "timeString = time.strftime(\"UTC %H:%M\")\n",
    "start = datetime.datetime.now()\n",
    "print(dateString,timeString)\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r {ec2_input_path}\n",
    "!rm -r {ec2_output_path}\n",
    "!mkdir -p {ec2_input_path}\n",
    "!mkdir -p {ec2_output_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://wri-projects/Aqueduct30/finalData/Floods/README.txt to ../../../../data/Y2019M04D11_RH_GA_RFR_Post_Process_V01/input_V04/README.txt\n",
      "download: s3://wri-projects/Aqueduct30/finalData/Floods/flood_State_results.CPG to ../../../../data/Y2019M04D11_RH_GA_RFR_Post_Process_V01/input_V04/flood_State_results.CPG\n",
      "download: s3://wri-projects/Aqueduct30/finalData/Floods/flood_State_results.sbx to ../../../../data/Y2019M04D11_RH_GA_RFR_Post_Process_V01/input_V04/flood_State_results.sbx\n",
      "download: s3://wri-projects/Aqueduct30/finalData/Floods/flood_Country_results.csv to ../../../../data/Y2019M04D11_RH_GA_RFR_Post_Process_V01/input_V04/flood_Country_results.csv\n",
      "download: s3://wri-projects/Aqueduct30/finalData/Floods/flood_State_results.shp.xml to ../../../../data/Y2019M04D11_RH_GA_RFR_Post_Process_V01/input_V04/flood_State_results.shp.xml\n",
      "download: s3://wri-projects/Aqueduct30/finalData/Floods/flood_results.CPG to ../../../../data/Y2019M04D11_RH_GA_RFR_Post_Process_V01/input_V04/flood_results.CPG\n",
      "download: s3://wri-projects/Aqueduct30/finalData/Floods/flood_State_results.prj to ../../../../data/Y2019M04D11_RH_GA_RFR_Post_Process_V01/input_V04/flood_State_results.prj\n",
      "download: s3://wri-projects/Aqueduct30/finalData/Floods/flood_State_results.shx to ../../../../data/Y2019M04D11_RH_GA_RFR_Post_Process_V01/input_V04/flood_State_results.shx\n",
      "download: s3://wri-projects/Aqueduct30/finalData/Floods/flood_State_results.sbn to ../../../../data/Y2019M04D11_RH_GA_RFR_Post_Process_V01/input_V04/flood_State_results.sbn\n",
      "download: s3://wri-projects/Aqueduct30/finalData/Floods/flood_results.prj to ../../../../data/Y2019M04D11_RH_GA_RFR_Post_Process_V01/input_V04/flood_results.prj\n",
      "download: s3://wri-projects/Aqueduct30/finalData/Floods/flood_results.sbx to ../../../../data/Y2019M04D11_RH_GA_RFR_Post_Process_V01/input_V04/flood_results.sbx\n",
      "download: s3://wri-projects/Aqueduct30/finalData/Floods/flood_State_results.csv to ../../../../data/Y2019M04D11_RH_GA_RFR_Post_Process_V01/input_V04/flood_State_results.csv\n",
      "download: s3://wri-projects/Aqueduct30/finalData/Floods/flood_results.sbn to ../../../../data/Y2019M04D11_RH_GA_RFR_Post_Process_V01/input_V04/flood_results.sbn\n",
      "download: s3://wri-projects/Aqueduct30/finalData/Floods/flood_results.shp.xml to ../../../../data/Y2019M04D11_RH_GA_RFR_Post_Process_V01/input_V04/flood_results.shp.xml\n",
      "download: s3://wri-projects/Aqueduct30/finalData/Floods/flood_State_results.dbf to ../../../../data/Y2019M04D11_RH_GA_RFR_Post_Process_V01/input_V04/flood_State_results.dbf\n",
      "download: s3://wri-projects/Aqueduct30/finalData/Floods/flood_results.csv to ../../../../data/Y2019M04D11_RH_GA_RFR_Post_Process_V01/input_V04/flood_results.csv\n",
      "download: s3://wri-projects/Aqueduct30/finalData/Floods/flood_results.shx to ../../../../data/Y2019M04D11_RH_GA_RFR_Post_Process_V01/input_V04/flood_results.shx\n",
      "download: s3://wri-projects/Aqueduct30/finalData/Floods/floods_state_lookup.py to ../../../../data/Y2019M04D11_RH_GA_RFR_Post_Process_V01/input_V04/floods_state_lookup.py\n",
      "download: s3://wri-projects/Aqueduct30/finalData/Floods/flood_results.dbf to ../../../../data/Y2019M04D11_RH_GA_RFR_Post_Process_V01/input_V04/flood_results.dbf\n",
      "download: s3://wri-projects/Aqueduct30/finalData/Floods/flood_results.shp to ../../../../data/Y2019M04D11_RH_GA_RFR_Post_Process_V01/input_V04/flood_results.shp\n",
      "download: s3://wri-projects/Aqueduct30/finalData/Floods/lookup_stateid.csv to ../../../../data/Y2019M04D11_RH_GA_RFR_Post_Process_V01/input_V04/lookup_stateid.csv\n",
      "download: s3://wri-projects/Aqueduct30/finalData/Floods/wri_aqueduct3_Floods.py to ../../../../data/Y2019M04D11_RH_GA_RFR_Post_Process_V01/input_V04/wri_aqueduct3_Floods.py\n",
      "download: s3://wri-projects/Aqueduct30/finalData/Floods/wri_aqueduct3_Floods_countries.py to ../../../../data/Y2019M04D11_RH_GA_RFR_Post_Process_V01/input_V04/wri_aqueduct3_Floods_countries.py\n",
      "download: s3://wri-projects/Aqueduct30/finalData/Floods/wri_aqueduct3_Floods_states.py to ../../../../data/Y2019M04D11_RH_GA_RFR_Post_Process_V01/input_V04/wri_aqueduct3_Floods_states.py\n",
      "download: s3://wri-projects/Aqueduct30/finalData/Floods/flood_State_results.shp to ../../../../data/Y2019M04D11_RH_GA_RFR_Post_Process_V01/input_V04/flood_State_results.shp\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp {S3_INPUT_PATH} {ec2_input_path} --recursive --exclude 'inundationMaps/*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/.google.json\"\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = \"aqueduct30\"\n",
    "client = bigquery.Client(project=BQ_PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql_labels = \"\"\"\n",
    "SELECT\n",
    "  indicator,\n",
    "  AVG(cat) AS cat,\n",
    "  label\n",
    "FROM\n",
    "  `{}.{}.{}`\n",
    "GROUP BY\n",
    "  label, indicator\n",
    "ORDER BY\n",
    "  indicator, cat\n",
    "\"\"\".format(BQ_PROJECT_ID,BQ_DATASET_NAME,BQ_INPUT_TABLE_NAME_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_labels = pd.read_gbq(query=sql_labels,\n",
    "                        project_id =BQ_PROJECT_ID,\n",
    "                        dialect=\"standard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql_gadm0 = \"\"\"\n",
    "SELECT\n",
    "  name_0,\n",
    "  ANY_VALUE(gid_0) as gid_0\n",
    "FROM\n",
    "  `{}.{}.{}`\n",
    "GROUP BY\n",
    "  name_0\n",
    "ORDER BY\n",
    "  name_0\n",
    "\"\"\".format(BQ_PROJECT_ID,BQ_DATASET_NAME,BQ_INPUT_TABLE_NAME_GADM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql_gadm1 = \"\"\"\n",
    "SELECT\n",
    "  gid_1,\n",
    "  gid_0,\n",
    "  name_1,\n",
    "  name_0\n",
    "FROM\n",
    "  `{}.{}.{}`\n",
    "ORDER BY\n",
    "  gid_1\n",
    "\"\"\".format(BQ_PROJECT_ID,BQ_DATASET_NAME,BQ_INPUT_TABLE_NAME_GADM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_gadm_0 = pd.read_gbq(query=sql_gadm0,\n",
    "                       project_id =BQ_PROJECT_ID,\n",
    "                       dialect=\"standard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_gadm_1 = pd.read_gbq(query=sql_gadm1,\n",
    "                       project_id =BQ_PROJECT_ID,\n",
    "                       dialect=\"standard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_rfr_country = pd.read_csv(\"{}/{}\".format(ec2_input_path,INPUT_FILE_NAME_COUNTRY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_rfr_province = pd.read_csv(\"{}/{}\".format(ec2_input_path,INPUT_FILE_NAME_PROVINCE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_to_category(score):\n",
    "    if score != 5:\n",
    "        cat = int(np.floor(score))\n",
    "    else:\n",
    "        cat = 4\n",
    "    return cat\n",
    "\n",
    "def process_dataframe(df,geographic_scale):\n",
    "    \"\"\"\n",
    "    Clean dataframes by dropping unnescary columns\n",
    "    \"\"\"\n",
    "    df.drop(columns=[\"Coast_pop_impacted\",\n",
    "                     \"CST_raw\",\n",
    "                     \"CST_s\",\n",
    "                     \"CST_cat\"],inplace=True)\n",
    "    df_out = df.rename(columns={\"PFAF_ID\":\"pfaf_id\",\n",
    "                        \"RVR_raw\":\"raw\",\n",
    "                        \"RVR_s\":\"score\",\n",
    "                        \"RVR_cat\":\"label\",\n",
    "                        \"River_pop_impacted\":\"sum_weighted_indicator\",\n",
    "                        \"pop_total\":\"sum_weights\"})\n",
    "\n",
    "    df_out[\"indicator_name\"] = \"rfr\"\n",
    "    df_out[\"weight\"] = \"pop\"\n",
    "    df_out[\"cat\"] = df_out[\"score\"].apply(score_to_category)\n",
    "    df_out[\"score_ranked\"] = df_out[\"score\"].rank(ascending=False,method=\"min\")\n",
    "    \n",
    "    if geographic_scale == \"country\":\n",
    "        df_out[\"label\"] = df_out[\"label\"].apply(lambda x: labels_dict_country[x])\n",
    "        df_out = pd.merge(left=df_out,\n",
    "                          right=df_gadm_0,\n",
    "                          how=\"left\",\n",
    "                          left_on=\"gid_0\",\n",
    "                          right_on=\"gid_0\")\n",
    "        df_out = df_out.reindex(sorted(df_out.columns), axis=1)\n",
    "        df_out = df_out.set_index(\"gid_0\",drop=False)\n",
    "        \n",
    "    elif geographic_scale == \"province\":\n",
    "        df_out[\"label\"] = df_out[\"label\"].apply(lambda x: labels_dict_province[x])\n",
    "        df_out = pd.merge(left=df_out,\n",
    "                          right=df_gadm_1,\n",
    "                          how=\"left\",\n",
    "                          left_on=\"gid_1\",\n",
    "                          right_on=\"gid_1\")\n",
    "        df_out = df_out.reindex(sorted(df_out.columns), axis=1)\n",
    "        df_out = df_out.set_index(\"gid_1\",drop=False)\n",
    "    \n",
    "    # Export\n",
    "    output_file_path_ec2 = \"{}/{}_{}_V{:02.0f}.csv\".format(ec2_output_path,SCRIPT_NAME,geographic_scale,OUTPUT_VERSION)\n",
    "    df_out.to_csv(path_or_buf=output_file_path_ec2,index=True)\n",
    "    destination_table = \"{}.{}_{}_V{:02.0f}\".format(BQ_DATASET_NAME,SCRIPT_NAME,geographic_scale,OUTPUT_VERSION).lower()\n",
    "    df_out.to_gbq(destination_table=destination_table,\n",
    "                  project_id=BQ_PROJECT_ID,\n",
    "                  if_exists=\"replace\")\n",
    "    return df_out\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:04,  4.01s/it]\n"
     ]
    }
   ],
   "source": [
    "df_out_country = process_dataframe(df_rfr_country,\"country\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:04,  4.90s/it]\n"
     ]
    }
   ],
   "source": [
    "df_out_province = process_dataframe(df_rfr_province,\"province\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>gid_0</th>\n",
       "      <th>indicator_name</th>\n",
       "      <th>label</th>\n",
       "      <th>name_0</th>\n",
       "      <th>raw</th>\n",
       "      <th>score</th>\n",
       "      <th>score_ranked</th>\n",
       "      <th>sum_weighted_indicator</th>\n",
       "      <th>sum_weights</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gid_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ABW</th>\n",
       "      <td>0</td>\n",
       "      <td>ABW</td>\n",
       "      <td>rfr</td>\n",
       "      <td>Low (0 to 2 in 1,000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>190.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.070000e+05</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFG</th>\n",
       "      <td>4</td>\n",
       "      <td>AFG</td>\n",
       "      <td>rfr</td>\n",
       "      <td>Extremely High (more than 1 in 100)</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0.031816</td>\n",
       "      <td>4.268904</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.002293e+06</td>\n",
       "      <td>3.150258e+07</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGO</th>\n",
       "      <td>0</td>\n",
       "      <td>AGO</td>\n",
       "      <td>rfr</td>\n",
       "      <td>Low (0 to 2 in 1,000)</td>\n",
       "      <td>Angola</td>\n",
       "      <td>0.001789</td>\n",
       "      <td>0.811343</td>\n",
       "      <td>163.0</td>\n",
       "      <td>3.415051e+04</td>\n",
       "      <td>1.909383e+07</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AIA</th>\n",
       "      <td>0</td>\n",
       "      <td>AIA</td>\n",
       "      <td>rfr</td>\n",
       "      <td>Low (0 to 2 in 1,000)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>190.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALA</th>\n",
       "      <td>0</td>\n",
       "      <td>ALA</td>\n",
       "      <td>rfr</td>\n",
       "      <td>Low (0 to 2 in 1,000)</td>\n",
       "      <td>Åland</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>190.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cat gid_0 indicator_name                                label  \\\n",
       "gid_0                                                                  \n",
       "ABW      0   ABW            rfr                Low (0 to 2 in 1,000)   \n",
       "AFG      4   AFG            rfr  Extremely High (more than 1 in 100)   \n",
       "AGO      0   AGO            rfr                Low (0 to 2 in 1,000)   \n",
       "AIA      0   AIA            rfr                Low (0 to 2 in 1,000)   \n",
       "ALA      0   ALA            rfr                Low (0 to 2 in 1,000)   \n",
       "\n",
       "            name_0       raw     score  score_ranked  sum_weighted_indicator  \\\n",
       "gid_0                                                                          \n",
       "ABW            NaN  0.000000  0.000000         190.0            0.000000e+00   \n",
       "AFG    Afghanistan  0.031816  4.268904          12.0            1.002293e+06   \n",
       "AGO         Angola  0.001789  0.811343         163.0            3.415051e+04   \n",
       "AIA            NaN  0.000000  0.000000         190.0            0.000000e+00   \n",
       "ALA          Åland  0.000000  0.000000         190.0            0.000000e+00   \n",
       "\n",
       "        sum_weights weight  \n",
       "gid_0                       \n",
       "ABW    1.070000e+05    pop  \n",
       "AFG    3.150258e+07    pop  \n",
       "AGO    1.909383e+07    pop  \n",
       "AIA    0.000000e+00    pop  \n",
       "ALA    0.000000e+00    pop  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out_country.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:35.524093\n"
     ]
    }
   ],
   "source": [
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous runs:   \n",
    "0:00:39.233810  \n",
    "0:00:41.319815"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 35",
   "language": "python",
   "name": "python35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
