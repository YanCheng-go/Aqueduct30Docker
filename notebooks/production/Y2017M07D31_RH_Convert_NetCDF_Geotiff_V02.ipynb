{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" convert netCDF4 to Geotiff.\n",
    "-------------------------------------------------------------------------------\n",
    "\n",
    "Convert individual images from a netCDF to geotiffs. Output is stored in \n",
    "Amazon S3 folder. \n",
    "\n",
    "\n",
    "Author: Rutger Hofste\n",
    "Date: 20180327\n",
    "Kernel: python36\n",
    "Docker: rutgerhofste/gisdocker:ubuntu16.04\n",
    "\n",
    "Args:\n",
    "\n",
    "    SCRIPT_NAME (string) : Script name\n",
    "    EC2_INPUT_PATH (string) : path to output of previous script. See Readme \n",
    "                              for more details. \n",
    "    PRINT_METADATA (boolean) : Print out metadata in Jupyter Notebook\n",
    "\n",
    "\n",
    "Returns:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Input Parameters\n",
    "\n",
    "SCRIPT_NAME = \"Y2017M07D31_RH_Convert_NetCDF_Geotiff_V02\"\n",
    "\n",
    "EC2_INPUT_PATH = \"/volumes/data/Y2017M07D31_RH_download_PCRGlobWB_data_V02/output/\"\n",
    "\n",
    "PRINT_METADATA = False\n",
    "\n",
    "X_DIMENSION_5MIN = 4320\n",
    "Y_DIMENSION_5MIN = 2160\n",
    "\n",
    "# Output Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Y2018M03D28', 'UTC 12:44')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.7.14 | packaged by conda-forge | (default, Dec 25 2017, 01:16:05) \\n[GCC 4.8.2 20140120 (Red Hat 4.8.2-15)]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time, datetime, sys\n",
    "dateString = time.strftime(\"Y%YM%mD%d\")\n",
    "timeString = time.strftime(\"UTC %H:%M\")\n",
    "start = datetime.datetime.now()\n",
    "print(dateString,timeString)\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import datetime\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pyproj\n",
    "import warnings\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "try:\n",
    "    from osgeo import ogr, osr, gdal\n",
    "except:\n",
    "    sys.exit('ERROR: cannot find GDAL/OGR modules')\n",
    "\n",
    "if 'GDAL_DATA' not in os.environ:\n",
    "    os.environ['GDAL_DATA'] = r'/usr/share/gdal/2.1'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL\n",
    "\n",
    "ec2_input_path_additional = \"/volumes/data/{}/input\".format(SCRIPT_NAME)\n",
    "\n",
    "S3_INPUT_PATH_ADDITIONAL = \"s3://wri-projects/Aqueduct30/rawData/WRI/samplegeotiff/\"\n",
    "\n",
    "ec2_output_path = \"/volumes/data/{}/output/\".format(SCRIPT_NAME)\n",
    "\n",
    "s3_output_path = \"s3://wri-projects/Aqueduct30/processData/{}/output/\".format(SCRIPT_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.ones([y_dimension,x_dimenstion])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = create_global_geotiff(output_path,array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp {ec2_output_path} {s3_output_path} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir -p {ec2_input_path_additional}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir -p {EC2_OUTPUTPATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp {S3_INPUT_PATH_ADDITIONAL} {ec2_input_path_additional} --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the file is actually copied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {EC2_INPUT_PATH_ADDITIONAL}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputLocationSampleGeotiff = os.path.join(ec2_input_path_additional,\"sampleGeotiff.tiff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inputLocationSampleGeotiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def read_gdal_file(input_path):\n",
    "    \"\"\" Reads file using GDAL\n",
    "    -------------------------------------------------------------------------------\n",
    "    \n",
    "    WARNING: This function only reads the first band. Data Stored in memory\n",
    "    \n",
    "    Args:\n",
    "        input_path (string) : path to input file\n",
    "    \n",
    "    Returns:\n",
    "        xsize (integer) : number of columns\n",
    "        ysize (integer) : number of rows\n",
    "        geotransform (tuple) : geotransform\n",
    "        geoproj (string) : geoprojection in osr format\n",
    "        Z (np.array) : array with values \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    filehandle = gdal.Open(input_path)\n",
    "    band1 = filehandle.GetRasterBand(1)\n",
    "    geotransform = filehandle.GetGeoTransform()\n",
    "    geoproj = filehandle.GetProjection()\n",
    "    Z = band1.ReadAsArray()\n",
    "    xsize = filehandle.RasterXSize\n",
    "    ysize = filehandle.RasterYSize\n",
    "    filehandle = None\n",
    "    return xsize,ysize,geotransform,geoproj,Z\n",
    "\n",
    "\n",
    "\n",
    "def global_georeference(array):\n",
    "    \"\"\" Get the geotransform and projection for a numpy array\n",
    "    -------------------------------------------------------------------------------\n",
    "    \n",
    "    Returns a geotransform and projection for a global extent in epsg 4326 \n",
    "    projection.\n",
    "    \n",
    "    Args:\n",
    "        array (np.array) : numpy array\n",
    "    \n",
    "    Returns:\n",
    "        geotransform (tuple) : geotransform\n",
    "        geoprojection (string) : geoprojection in osr format    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    y_dimension = array.shape[0] #rows, lat\n",
    "    x_dimension = array.shape[1] #cols, lon\n",
    "    geotransform = (-180,360.0/x_dimension,0,90,0,-180.0/y_dimension)\n",
    "    \n",
    "    srs = osr.SpatialReference()\n",
    "    srs.ImportFromEPSG(4326)\n",
    "    geoprojection = srs.ExportToWkt()\n",
    "    \n",
    "    if len(geoprojection) == 0:\n",
    "        warnings.warn(\"GDAL_DATA path not set correctly. Assert os.environ \" \\\n",
    "                      \"contains GDAL_DATA \\n\" \\\n",
    "                      \"Code will execute without projection set\")\n",
    "\n",
    "    return geotransform, geoprojection\n",
    "\n",
    "\n",
    "def write_geotiff(output_path,geotransform,geoprojection,data,nodata_value=-9999,datatype=gdal.GDT_Float32):\n",
    "    \n",
    "    \"\"\" Write data to geotiff file\n",
    "    -------------------------------------------------------------------------------\n",
    "    \n",
    "    Args: \n",
    "        output_path (string) : output_path \n",
    "        geotransform (tuple) : geotransform\n",
    "        geoprojection (string) : geoprojection in osr format\n",
    "        data (np.array) : numpy array    \n",
    "        nodata_value (integer) : NoData value\n",
    "        datatype (GDAL datatype)\n",
    "    \n",
    "    \"\"\"  \n",
    "    \n",
    "    (x,y) = data.shape\n",
    "    format = \"GTiff\"\n",
    "    driver = gdal.GetDriverByName(format)\n",
    "    # you can change the dataformat but be sure to be able to store negative values including -9999\n",
    "    dst_ds = driver.Create(output_path,y,x,1,datatype, [ 'COMPRESS=LZW' ])\n",
    "    dst_ds.GetRasterBand(1).SetNoDataValue(nodata_value)\n",
    "    dst_ds.GetRasterBand(1).WriteArray(data)\n",
    "    dst_ds.SetGeoTransform(geotransform)\n",
    "    dst_ds.SetProjection(geoprojection)\n",
    "    dst_ds = None\n",
    "    return 1\n",
    "\n",
    "\n",
    "def netCDF4_to_geotiff(fileName,fileLocation):\n",
    "    netCDFInputBaseName = fileName.split('.')[0]\n",
    "    nc_fid = Dataset(fileLocation, 'r')\n",
    "    nc_attrs, nc_dims, nc_vars = ncdump(nc_fid, PRINT_METADATA)\n",
    "    parameter = nc_vars[3]\n",
    "    lats = nc_fid.variables['latitude'][:]  # extract/copy the data\n",
    "    lons = nc_fid.variables['longitude'][:]\n",
    "    times = nc_fid.variables['time'][:]\n",
    "    timeUnit = nc_fid.variables[\"time\"].getncattr(\"units\")\n",
    "    timeNormal =[]\n",
    "    for time in times:\n",
    "        if timeUnit == (\"days since 1900-01-01 00:00:00\") or (timeUnit ==\"Days since 1900-01-01\"):\n",
    "            timeNormal.append(datetime.datetime(1900,1,1) + datetime.timedelta(days=time))\n",
    "        elif timeUnit == \"days since 1901-01-01 00:00:00\":\n",
    "            timeNormal.append(datetime.datetime(1901,1,1) + datetime.timedelta(days=time))\n",
    "        else:\n",
    "            print \"Error\"\n",
    "            timeNormal.append(-9999)\n",
    "            \n",
    "    for i in range(0,len(timeNormal)):\n",
    "        #print timeNormal[i].year\n",
    "        Z = nc_fid.variables[parameter][i, :, :]\n",
    "        Z[Z<-9990]= -9999\n",
    "        Z[Z>1e19] = -9999\n",
    "        outputFilename = netCDFInputBaseName + \"I%0.3dY%0.2dM%0.2d.tif\" %(i,timeNormal[i].year,timeNormal[i].month)\n",
    "        writefilename = os.path.join(EC2_OUTPUTPATH,outputFilename)\n",
    "        writeFile(writefilename,geotransform,geoproj,Z)\n",
    "    \n",
    "    return time, timeUnit, timeNormal\n",
    "\n",
    "\n",
    "\n",
    "def ncdump(nc_fid, verb=True):\n",
    "    '''\n",
    "    ncdump outputs dimensions, variables and their attribute information.\n",
    "    The information is similar to that of NCAR's ncdump utility.\n",
    "    ncdump requires a valid instance of Dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    nc_fid : netCDF4.Dataset\n",
    "        A netCDF4 dateset object\n",
    "    verb : Boolean\n",
    "        whether or not nc_attrs, nc_dims, and nc_vars are printed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    nc_attrs : list\n",
    "        A Python list of the NetCDF file global attributes\n",
    "    nc_dims : list\n",
    "        A Python list of the NetCDF file dimensions\n",
    "    nc_vars : list\n",
    "        A Python list of the NetCDF file variables\n",
    "    '''\n",
    "    def print_ncattr(key):\n",
    "        \"\"\"\n",
    "        Prints the NetCDF file attributes for a given key\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        key : unicode\n",
    "            a valid netCDF4.Dataset.variables key\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print \"\\t\\ttype:\", repr(nc_fid.variables[key].dtype)\n",
    "            for ncattr in nc_fid.variables[key].ncattrs():\n",
    "                print '\\t\\t%s:' % ncattr,\\\n",
    "                      repr(nc_fid.variables[key].getncattr(ncattr))\n",
    "        except KeyError:\n",
    "            print \"\\t\\tWARNING: %s does not contain variable attributes\" % key\n",
    "\n",
    "    # NetCDF global attributes\n",
    "    nc_attrs = nc_fid.ncattrs()\n",
    "    if verb:\n",
    "        print \"NetCDF Global Attributes:\"\n",
    "        for nc_attr in nc_attrs:\n",
    "            print '\\t%s:' % nc_attr, repr(nc_fid.getncattr(nc_attr))\n",
    "    nc_dims = [dim for dim in nc_fid.dimensions]  # list of nc dimensions\n",
    "    # Dimension shape information.\n",
    "    if verb:\n",
    "        print \"NetCDF dimension information:\"\n",
    "        for dim in nc_dims:\n",
    "            print \"\\tName:\", dim\n",
    "            print \"\\t\\tsize:\", len(nc_fid.dimensions[dim])\n",
    "            print_ncattr(dim)\n",
    "    # Variable information.\n",
    "    nc_vars = [var for var in nc_fid.variables]  # list of nc variables\n",
    "    if verb:\n",
    "        print \"NetCDF variable information:\"\n",
    "        for var in nc_vars:\n",
    "            if var not in nc_dims:\n",
    "                print '\\tName:', var\n",
    "                print \"\\t\\tdimensions:\", nc_fid.variables[var].dimensions\n",
    "                print \"\\t\\tsize:\", nc_fid.variables[var].size\n",
    "                print_ncattr(var)\n",
    "    return nc_attrs, nc_dims, nc_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "array = np.ones([2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "geotransform, geoprojection = global_georeference(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ZSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print xsize, ysize, geotransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(EC2_INPUT_PATH):\n",
    "    for oneFile in files:\n",
    "        if oneFile.endswith(\".nc4\") or oneFile.endswith(\".nc\"):\n",
    "            print(oneFile)\n",
    "            fileLocation = os.path.join(root, oneFile)\n",
    "            fileName = oneFile\n",
    "            netCDF4toGeotiff(fileName,fileLocation)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = os.listdir(OUTPUTPATH)\n",
    "print(\"Number of files: \" + str(len(files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some files from Utrecht contain double years, removing the erroneous ones (used Panoply/Qgis to inspect those files):\n",
    "\n",
    "global_historical_PDomWN_year_millionm3_5min_1960_2014I055Y1960M01.tif\n",
    "global_historical_PDomWN_month_millionm3_5min_1960_2014I660Y1960M01.tif\n",
    "global_historical_PDomWN_month_millionm3_5min_1960_2014I661Y1960M01.tif\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir /volumes/data/trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mv /volumes/data/Y2017M07D31_RH_Convert_NetCDF_Geotiff_V01/global_historical_PDomWN_year_millionm3_5min_1960_2014I055Y1960M01.tif /volumes/data/trash/global_historical_PDomWN_year_millionm3_5min_1960_2014I055Y1960M01.tif\n",
    "!mv /volumes/data/Y2017M07D31_RH_Convert_NetCDF_Geotiff_V01/global_historical_PDomWN_month_millionm3_5min_1960_2014I660Y1960M01.tif /volumes/data/trash/global_historical_PDomWN_month_millionm3_5min_1960_2014I660Y1960M01.tif\n",
    "!mv /volumes/data/Y2017M07D31_RH_Convert_NetCDF_Geotiff_V01/global_historical_PDomWN_month_millionm3_5min_1960_2014I661Y1960M01.tif /volumes/data/trash/global_historical_PDomWN_month_millionm3_5min_1960_2014I661Y1960M01.tif\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = os.listdir(OUTPUTPATH)\n",
    "print(\"Number of files: \" + str(len(files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_global_geotiff_from_array(output_path,array,nodata_value=-9999,datatype=gdal.GDT_Int16):\n",
    "    \"\"\" Writes array to global geotiff\n",
    "    -------------------------------------------------------------------------------\n",
    "    \n",
    "    In many geospatial debugging analyses, a raster with only ones or random values\n",
    "    is useful. Stores the output geotiff in the output_path. \n",
    "        \n",
    "    Uses the WGS epsg 4326 projection. Make sure the array and data type are \n",
    "    compatible. Requires GDAL to be installed with GDAL_DATA added to the system\n",
    "    path. \n",
    "    \n",
    "    Args:\n",
    "        output_path (string) : file path with write permission to store geotiff.\n",
    "        array (np.array) : numpy array to write to geotiff.\n",
    "        datatype (gdal datatype) : datatype of output image. See https://naturalatlas.github.io/node-gdal/classes/Constants%20(GDT).html\n",
    "                                   for options. Defaults to gdal.GDT_Float32\n",
    "        nodata_value (integer) : NoData value. Defaults to -9999.\n",
    "    \n",
    "    Returns:\n",
    "        image (geoTiff) : geotiff image with all\n",
    "        \n",
    "    \n",
    "    TODO: Support other crs\n",
    "    \n",
    "    \"\"\"\n",
    "    y_dimension = array.shape[0] #rows, lat\n",
    "    x_dimension = array.shape[1] #cols, lon\n",
    "    geotransform = (-180,360.0/x_dimension,0,90,0,-180.0/y_dimension)\n",
    "        \n",
    "    out_raster_srs = osr.SpatialReference()\n",
    "    out_raster_srs.ImportFromEPSG(4326)\n",
    "    projection = out_raster_srs.ExportToWkt()\n",
    "    \n",
    "    if len(projection) == 0:\n",
    "        warnings.warn(\"GDAL_DATA path not set correctly. Assert os.environ \" \\\n",
    "                      \"contains GDAL_DATA \\n\" \\\n",
    "                      \"Code will execute without projection set\")\n",
    "       \n",
    "    out_raster = write_geotiff(output_path,geotransform,geoprojection,data,nodata_value,datatype)    \n",
    "    return out_raster"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 27",
   "language": "python",
   "name": "python27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
