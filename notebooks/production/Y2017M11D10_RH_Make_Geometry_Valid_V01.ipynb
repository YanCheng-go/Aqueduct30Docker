{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Upstream Downstream with FAO names \n",
    "\n",
    "* Purpose of script: Create a shapefile and csv file with both the upstream / downstream relation and the FAO basin names\n",
    "* Author: Rutger Hofste\n",
    "* Kernel used: python35\n",
    "* Date created: 20170829"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script requires some additional steps that are not automated yet. The objective is to set up a PosGIS enabled PostgreSQL AWS RDS instance. \n",
    "\n",
    "https://gis.stackexchange.com/questions/239198/geopandas-dataframe-to-postgis-table-help\n",
    "\n",
    "http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ConnectToPostgreSQLInstance.html\n",
    "\n",
    "http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Appendix.PostgreSQL.CommonDBATasks.html#Appendix.PostgreSQL.CommonDBATasks.PostGIS\n",
    "\n",
    "database is not protected by default. Basic workflow:\n",
    "\n",
    "1. Create database\n",
    "1. Load data into geopandas\n",
    "1. split by geometry type\n",
    "1. upload to postGIS database\n",
    "1. Make valid\n",
    "1. combine results in geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y2017M11D13 UTC 14:40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.5.4 |Continuum Analytics, Inc.| (default, Aug 14 2017, 13:26:58) \\n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time, datetime, sys\n",
    "dateString = time.strftime(\"Y%YM%mD%d\")\n",
    "timeString = time.strftime(\"UTC %H:%M\")\n",
    "start = datetime.datetime.now()\n",
    "print(dateString,timeString)\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SCRIPT_NAME = \"Y2017M11D10_RH_Make_Geometry_Valid_V01\"\n",
    "\n",
    "INPUT_VERSION = 1\n",
    "OUTPUT_VERSION = 1\n",
    "\n",
    "S3_INPUT_PATH = \"s3://wri-projects/Aqueduct30/processData/Y2017M08D29_RH_Merge_FAONames_Upstream_V01/output/\"\n",
    "S3_OUTPUT_PATH = \"s3://wri-projects/Aqueduct30/processData/%s/output/\" %(SCRIPT_NAME)\n",
    "\n",
    "INPUT_FILENAME = \"hybas_lev06_v1c_merged_fiona_upstream_downstream_FAO_V%0.2d\" %(INPUT_VERSION)\n",
    "\n",
    "EC2_INPUT_PATH = \"/volumes/data/%s/input\" %(SCRIPT_NAME)\n",
    "EC2_OUTPUT_PATH = \"/volumes/data/%s/output\" %(SCRIPT_NAME)\n",
    "\n",
    "OUTPUT_FILE_NAME = \"Y2017M11D10_RH_Make_Geometry_Valid_V%0.2d\" %(OUTPUT_VERSION)\n",
    "\n",
    "S3_OUTPUT_PATH = \"s3://wri-projects/Aqueduct30/processData/%s/output/\" %(SCRIPT_NAME)\n",
    "\n",
    "# Database settings\n",
    "DATABASE_IDENTIFIER = \"aqueduct30v07\"\n",
    "DATABASE_NAME = \"database01\"\n",
    "TABLE_NAME = \"hybasvalid01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geoalchemy2 import Geometry, WKTElement\n",
    "from sqlalchemy import *\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "from shapely.geometry.multipolygon import MultiPolygon\n",
    "from shapely.geometry.polygon import Polygon\n",
    "import boto3\n",
    "import botocore\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup of PostGIS Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!aws configure set default.region eu-central-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rds = boto3.client('rds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDB():\n",
    "    db_identifier = DATABASE_IDENTIFIER\n",
    "    rds.create_db_instance(DBInstanceIdentifier=db_identifier,\n",
    "                       AllocatedStorage=20,\n",
    "                       DBName=DATABASE_NAME,\n",
    "                       Engine='postgres',\n",
    "                       # General purpose SSD\n",
    "                       StorageType='gp2',\n",
    "                       StorageEncrypted=False,\n",
    "                       AutoMinorVersionUpgrade=True,\n",
    "                       # Set this to true later?\n",
    "                       MultiAZ=False,\n",
    "                       MasterUsername='rutgerhofste',\n",
    "                       MasterUserPassword='nopassword',\n",
    "                       VpcSecurityGroupIds=['sg-1da15e77'], #You will need to create a security group in the console. \n",
    "                       DBInstanceClass='db.t2.micro',\n",
    "                       Tags=[{'Key': 'test', 'Value': 'test'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "createDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative using Jupyter Magic\n",
    "#!aws rds create-db-instance --db-name {DATABASE_NAME} --db-instance-identifier {DATABASE_IDENTIFIER} --allocated-storage 20 --db-instance-class \"db.t2.micro\" --engine \"postgres\" --master-username \"rutgerhofste\" --master-user-password \"nopassword\" --publicly-accessible --vpc-security-group-ids vpc-f6312f9e "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rds.describe_db_instances(DBInstanceIdentifier=\"%s\"%(DATABASE_IDENTIFIER)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "status = response[\"DBInstances\"][0][\"DBInstanceStatus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating\n",
      "creating\n",
      "creating\n",
      "creating\n",
      "creating\n",
      "creating\n",
      "creating\n",
      "creating\n",
      "creating\n",
      "backing-up\n",
      "backing-up\n",
      "backing-up\n",
      "backing-up\n",
      "backing-up\n",
      "backing-up\n",
      "backing-up\n",
      "backing-up\n",
      "backing-up\n",
      "available\n"
     ]
    }
   ],
   "source": [
    "# Pause the script while the database is being created\n",
    "while status != \"available\":\n",
    "    response = rds.describe_db_instances(DBInstanceIdentifier=\"%s\"%(DATABASE_IDENTIFIER)) \n",
    "    status = response[\"DBInstances\"][0][\"DBInstanceStatus\"]\n",
    "    time.sleep(20)\n",
    "    print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = response[\"DBInstances\"][0][\"Endpoint\"][\"Address\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aqueduct30v07.cgpnumwmfcqc.eu-central-1.rds.amazonaws.com\n"
     ]
    }
   ],
   "source": [
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to database and setup PostGIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://rutgerhofste:nopassword@%s:5432/%s' %(endpoint,DATABASE_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlList = []\n",
    "sqlList.append(\"select current_user;\")\n",
    "sqlList.append(\"create extension postgis;\")\n",
    "sqlList.append(\"create extension fuzzystrmatch;\")\n",
    "sqlList.append(\"create extension postgis_tiger_geocoder;\")\n",
    "sqlList.append(\"create extension postgis_topology;\")\n",
    "sqlList.append(\"alter schema tiger owner to rds_superuser;\")\n",
    "sqlList.append(\"alter schema tiger_data owner to rds_superuser;\")\n",
    "sqlList.append(\"alter schema topology owner to rds_superuser;\")\n",
    "sqlList.append(\"CREATE FUNCTION exec(text) returns text language plpgsql volatile AS $f$ BEGIN EXECUTE $1; RETURN $1; END; $f$;\")      \n",
    "sqlList.append(\"SELECT exec('ALTER TABLE ' || quote_ident(s.nspname) || '.' || quote_ident(s.relname) || ' OWNER TO rds_superuser;') FROM ( SELECT nspname, relname FROM pg_class c JOIN pg_namespace n ON (c.relnamespace = n.oid) WHERE nspname in ('tiger','topology') AND relkind IN ('r','S','v') ORDER BY relkind = 'S')s;\")\n",
    "sqlList.append(\"SET search_path=public,tiger;\")\n",
    "sqlList.append(\"select na.address, na.streetname, na.streettypeabbrev, na.zip from normalize_address('1 Devonshire Place, Boston, MA 02109') as na;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultList = []\n",
    "for sql in sqlList:\n",
    "    #print(sql)\n",
    "    resultList.append(connection.execute(sql))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -r {EC2_INPUT_PATH}\n",
    "!rm -r {EC2_OUTPUT_PATH}\n",
    "\n",
    "!mkdir -p {EC2_INPUT_PATH}\n",
    "!mkdir -p {EC2_OUTPUT_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://wri-projects/Aqueduct30/processData/Y2017M08D29_RH_Merge_FAONames_Upstream_V01/output/hybas_lev06_v1c_merged_fiona_upstream_downstream_FAO_V01.cpg to ../../../../data/Y2017M11D10_RH_Make_Geometry_Valid_V01/input/hybas_lev06_v1c_merged_fiona_upstream_downstream_FAO_V01.cpg\n",
      "download: s3://wri-projects/Aqueduct30/processData/Y2017M08D29_RH_Merge_FAONames_Upstream_V01/output/hybas_lev06_v1c_merged_fiona_upstream_downstream_FAO_V01.prj to ../../../../data/Y2017M11D10_RH_Make_Geometry_Valid_V01/input/hybas_lev06_v1c_merged_fiona_upstream_downstream_FAO_V01.prj\n",
      "download: s3://wri-projects/Aqueduct30/processData/Y2017M08D29_RH_Merge_FAONames_Upstream_V01/output/hybas_lev06_v1c_merged_fiona_upstream_downstream_FAO_V01.shx to ../../../../data/Y2017M11D10_RH_Make_Geometry_Valid_V01/input/hybas_lev06_v1c_merged_fiona_upstream_downstream_FAO_V01.shx\n",
      "download: s3://wri-projects/Aqueduct30/processData/Y2017M08D29_RH_Merge_FAONames_Upstream_V01/output/hybas_lev06_v1c_merged_fiona_upstream_downstream_FAO_V01.dbf to ../../../../data/Y2017M11D10_RH_Make_Geometry_Valid_V01/input/hybas_lev06_v1c_merged_fiona_upstream_downstream_FAO_V01.dbf\n",
      "download: s3://wri-projects/Aqueduct30/processData/Y2017M08D29_RH_Merge_FAONames_Upstream_V01/output/hybas_lev06_v1c_merged_fiona_upstream_downstream_FAO_V01.pkl to ../../../../data/Y2017M11D10_RH_Make_Geometry_Valid_V01/input/hybas_lev06_v1c_merged_fiona_upstream_downstream_FAO_V01.pkl\n",
      "download: s3://wri-projects/Aqueduct30/processData/Y2017M08D29_RH_Merge_FAONames_Upstream_V01/output/hybas_lev06_v1c_merged_fiona_upstream_downstream_FAO_V01.csv to ../../../../data/Y2017M11D10_RH_Make_Geometry_Valid_V01/input/hybas_lev06_v1c_merged_fiona_upstream_downstream_FAO_V01.csv\n",
      "download: s3://wri-projects/Aqueduct30/processData/Y2017M08D29_RH_Merge_FAONames_Upstream_V01/output/hybas_lev06_v1c_merged_fiona_upstream_downstream_FAO_V01.shp to ../../../../data/Y2017M11D10_RH_Make_Geometry_Valid_V01/input/hybas_lev06_v1c_merged_fiona_upstream_downstream_FAO_V01.shp\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp {S3_INPUT_PATH} {EC2_INPUT_PATH} --recursive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(os.path.join(EC2_INPUT_PATH,INPUT_FILENAME+\".shp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdf = gdf.set_index(\"PFAF_ID\", drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PFAF_ID</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PFAF_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>611001</th>\n",
       "      <td>611001</td>\n",
       "      <td>(POLYGON ((-78.99722222222219 9.45416666666669...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611002</th>\n",
       "      <td>611002</td>\n",
       "      <td>POLYGON ((-77.00416666666663 5.770833333333362...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611003</th>\n",
       "      <td>611003</td>\n",
       "      <td>POLYGON ((-76.88749999999997 7.679166666666696...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611004</th>\n",
       "      <td>611004</td>\n",
       "      <td>POLYGON ((-76.51249999999996 7.587500000000028...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611005</th>\n",
       "      <td>611005</td>\n",
       "      <td>(POLYGON ((-76.17638888888887 9.37500000000002...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PFAF_ID                                           geometry\n",
       "PFAF_ID                                                            \n",
       "611001    611001  (POLYGON ((-78.99722222222219 9.45416666666669...\n",
       "611002    611002  POLYGON ((-77.00416666666663 5.770833333333362...\n",
       "611003    611003  POLYGON ((-76.88749999999997 7.679166666666696...\n",
       "611004    611004  POLYGON ((-76.51249999999996 7.587500000000028...\n",
       "611005    611005  (POLYGON ((-76.17638888888887 9.37500000000002..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16397, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdf2 = gdf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef explode(indf):\\n    outdf = gpd.GeoDataFrame(columns=indf.columns)\\n    for idx, row in indf.iterrows():\\n        if type(row.geometry) == Polygon:\\n            outdf = outdf.append(row,ignore_index=True)\\n        if type(row.geometry) == MultiPolygon:\\n            multdf = gpd.GeoDataFrame(columns=indf.columns)\\n            recs = len(row.geometry)\\n            multdf = multdf.append([row]*recs,ignore_index=True)\\n            for geom in range(recs):\\n                multdf.loc[geom,'geometry'] = row.geometry[geom]\\n            outdf = outdf.append(multdf,ignore_index=True)\\n    return outdf\\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def explode(indf):\n",
    "    outdf = gpd.GeoDataFrame(columns=indf.columns)\n",
    "    for idx, row in indf.iterrows():\n",
    "        if type(row.geometry) == Polygon:\n",
    "            outdf = outdf.append(row,ignore_index=True)\n",
    "        if type(row.geometry) == MultiPolygon:\n",
    "            multdf = gpd.GeoDataFrame(columns=indf.columns)\n",
    "            recs = len(row.geometry)\n",
    "            multdf = multdf.append([row]*recs,ignore_index=True)\n",
    "            for geom in range(recs):\n",
    "                multdf.loc[geom,'geometry'] = row.geometry[geom]\n",
    "            outdf = outdf.append(multdf,ignore_index=True)\n",
    "    return outdf\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf2[\"type\"] = gdf2.geometry.geom_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdfPolygon = gdf2.loc[gdf2[\"type\"]==\"Polygon\"]\n",
    "gdfMultiPolygon = gdf2.loc[gdf2[\"type\"]==\"MultiPolygon\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdfPolygon2 = gdfPolygon.copy()\n",
    "gdfMultiPolygon2 = gdfMultiPolygon.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gdfPolygon2['geom'] = gdfPolygon['geometry'].apply(lambda x: WKTElement(x.wkt, srid=4326))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdfMultiPolygon2['geom'] = gdfMultiPolygon['geometry'].apply(lambda x: WKTElement(x.wkt, srid=4326))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdfPolygon2.drop(\"geometry\",1, inplace=True)\n",
    "gdfMultiPolygon2.drop(\"geometry\",1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command will connect to a temporary free tier AWS RDS instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tableNamePolygon = TABLE_NAME+\"polygon\"\n",
    "tableNameMultiPolygon = TABLE_NAME+\"multipolygon\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdfPolygon2.to_sql(tableNamePolygon, engine, if_exists='replace', index=False, \n",
    "                         dtype={'geom': Geometry('POLYGON', srid= 4326)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdfMultiPolygon2.to_sql(tableNameMultiPolygon, engine, if_exists='replace', index=False, \n",
    "                         dtype={'geom': Geometry('MULTIPOLYGON', srid= 4326)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql = \"update %s set geom = st_makevalid(geom)\" %(tableNamePolygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = connection.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql = \"update %s set geom = st_makevalid(geom)\" %(tableNameMultiPolygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = connection.execute(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if operation succesful "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql = \"select * from %s\" %(tableNamePolygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdfAWSPolygon=gpd.GeoDataFrame.from_postgis(sql,connection,geom_col='geom' ).set_index(\"PFAF_ID\", drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql = \"select * from %s\" %(tableNameMultiPolygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdfAWSMultiPolygon=gpd.GeoDataFrame.from_postgis(sql,connection,geom_col='geom' ).set_index(\"PFAF_ID\", drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdfAWSPolygon.crs = {'init' :'epsg:4326'}\n",
    "gdfAWSMultiPolygon.crs = {'init' :'epsg:4326'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdfAWS = gdfAWSPolygon.append(gdfAWSMultiPolygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdfAWS.to_file(os.path.join(EC2_OUTPUT_PATH,OUTPUT_FILE_NAME+\".shp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ../../../../data/Y2017M11D10_RH_Make_Geometry_Valid_V01/output/Y2017M11D10_RH_Make_Geometry_Valid_V01.prj to s3://wri-projects/Aqueduct30/processData/Y2017M11D10_RH_Make_Geometry_Valid_V01/output/Y2017M11D10_RH_Make_Geometry_Valid_V01.prj\n",
      "upload: ../../../../data/Y2017M11D10_RH_Make_Geometry_Valid_V01/output/Y2017M11D10_RH_Make_Geometry_Valid_V01.cpg to s3://wri-projects/Aqueduct30/processData/Y2017M11D10_RH_Make_Geometry_Valid_V01/output/Y2017M11D10_RH_Make_Geometry_Valid_V01.cpg\n",
      "upload: ../../../../data/Y2017M11D10_RH_Make_Geometry_Valid_V01/output/Y2017M11D10_RH_Make_Geometry_Valid_V01.shx to s3://wri-projects/Aqueduct30/processData/Y2017M11D10_RH_Make_Geometry_Valid_V01/output/Y2017M11D10_RH_Make_Geometry_Valid_V01.shx\n",
      "upload: ../../../../data/Y2017M11D10_RH_Make_Geometry_Valid_V01/output/Y2017M11D10_RH_Make_Geometry_Valid_V01.dbf to s3://wri-projects/Aqueduct30/processData/Y2017M11D10_RH_Make_Geometry_Valid_V01/output/Y2017M11D10_RH_Make_Geometry_Valid_V01.dbf\n",
      "upload: ../../../../data/Y2017M11D10_RH_Make_Geometry_Valid_V01/output/Y2017M11D10_RH_Make_Geometry_Valid_V01.shp to s3://wri-projects/Aqueduct30/processData/Y2017M11D10_RH_Make_Geometry_Valid_V01/output/Y2017M11D10_RH_Make_Geometry_Valid_V01.shp\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp {EC2_OUTPUT_PATH} {S3_OUTPUT_PATH} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:11:29.313599\n"
     ]
    }
   ],
   "source": [
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print(elapsed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 35",
   "language": "python",
   "name": "python35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
