{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input gcs: gs://aqueduct30_v01/Y2017M08D02_RH_Merge_HydroBasins_V02/output_V04/\n",
      "Output ec2: /volumes/data/Y2018M04D20_RH_Ingest_HydroBasins_GCS_EE_V01/output_V01\n",
      "Output ee: projects/WRI-Aquaduct/Y2018M04D20_RH_Ingest_HydroBasins_GCS_EE_V01/output_V01\n",
      "Output S3: s3://wri-projects/Aqueduct30/processData/Y2018M04D20_RH_Ingest_HydroBasins_GCS_EE_V01/output_V01\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Ingest hydrobasin rasters in earthengine.\n",
    "-------------------------------------------------------------------------------\n",
    "Ingests rasterized hydrobasin geotiffs in earthengine.\n",
    "\n",
    "\n",
    "Author: Rutger Hofste\n",
    "Date: 20180420\n",
    "Kernel: python35\n",
    "Docker: rutgerhofste/gisdocker:ubuntu16.04\n",
    "\n",
    "Args:\n",
    "\n",
    "    SCRIPT_NAME (string) : Script name.\n",
    "    PREVIOUS_SCRIPT_NAME (string) : Previous script name.\n",
    "    INPUT_VERSION (integer) : Input version.\n",
    "    OUTPUT_VERSION (integer) : Output version.\n",
    "    OUTPUT_FILE_NAME (string) : Ouput filename of error dataframe. \n",
    "        make sure to add a '.csv' extension.\n",
    "    X_DIMENSION_5MIN (integer) : Longitudinal dimension at 5 arc minutes.\n",
    "    Y_DIMENSION_5MIN (integer) : Latitudinal dimension at 5 arc minutes.\n",
    "    X_DIMENSION_30S (integer) : Longitudinal dimension at 30 arc seconds.\n",
    "    Y_DIMENSION_30S (integer) : Latitudinal dimension at 30 arc seconds.\n",
    "    SEPARATOR (regex) : Regular expression used to convert filename into \n",
    "        metadata.\n",
    "    SCHEMA (list) : List of strings with metadata keys. \n",
    "    EXTRA_PROPERTIES (dictionary) :  Dictionary with additional key value pairs\n",
    "        that will be stored as properties in earthengine image. \n",
    "\n",
    "\n",
    "Returns:\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Input Parameters\n",
    "\n",
    "OVERWRITE = 0 \n",
    "\n",
    "SCRIPT_NAME = \"Y2018M04D20_RH_Ingest_HydroBasins_GCS_EE_V01\"\n",
    "PREVIOUS_SCRIPT_NAME = \"Y2017M08D02_RH_Merge_HydroBasins_V02\"\n",
    "INPUT_VERSION = 4\n",
    "OUTPUT_VERSION = 1\n",
    "OUTPUT_FILE_NAME = \"df_errors.csv\"\n",
    "\n",
    "X_DIMENSION_5MIN = 4320\n",
    "Y_DIMENSION_5MIN = 2160\n",
    "X_DIMENSION_30S = 43200\n",
    "Y_DIMENSION_30S = 21600\n",
    "\n",
    "SEPARATOR = \"_|-\"\n",
    "SCHEMA = [\"indicator\",\n",
    "          \"pfafstetter_level\",\n",
    "          \"WWF_version\",\n",
    "          \"geographic_range\",\n",
    "          \"algorithm_used_for_merge\",\n",
    "          \"sparial_resolution\",\n",
    "          \"output_version\"]\n",
    "\n",
    "EXTRA_PROPERTIES = {\"WWF_lakes\":\"standard_no_lakes\",\n",
    "                    \"nodata_value\":-9999,\n",
    "                    \"ingested_by\" : \"RutgerHofste\",\n",
    "                    \"script_used\": SCRIPT_NAME,\n",
    "                    \"output_version\":OUTPUT_VERSION}\n",
    "                    \n",
    "\n",
    "# ETL\n",
    "ec2_output_path = \"/volumes/data/{}/output_V{:02.0f}\".format(SCRIPT_NAME,OUTPUT_VERSION)\n",
    "gcs_input_path = \"gs://aqueduct30_v01/{}/output_V{:02.0f}/\".format(PREVIOUS_SCRIPT_NAME,INPUT_VERSION)\n",
    "ee_output_path = \"projects/WRI-Aquaduct/{}/output_V{:02.0f}\".format(SCRIPT_NAME,OUTPUT_VERSION)\n",
    "s3_output_path = \"s3://wri-projects/Aqueduct30/processData/{}/output_V{:02.0f}\".format(SCRIPT_NAME,OUTPUT_VERSION)\n",
    "\n",
    "print(\"Input gcs: \" +  gcs_input_path+\n",
    "      \"\\nOutput ec2: \" + ec2_output_path +\n",
    "      \"\\nOutput ee: \" + ee_output_path +\n",
    "      \"\\nOutput S3: \" + s3_output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y2018M04D20 UTC 13:58\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.5.4 |Anaconda, Inc.| (default, Nov 20 2017, 18:44:38) \\n[GCC 7.2.0]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time, datetime, sys\n",
    "dateString = time.strftime(\"Y%YM%mD%d\")\n",
    "timeString = time.strftime(\"UTC %H:%M\")\n",
    "start = datetime.datetime.now()\n",
    "print(dateString,timeString)\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import subprocess\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import aqueduct3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "earthengine create folder projects/WRI-Aquaduct/Y2018M04D20_RH_Ingest_HydroBasins_GCS_EE_V01/output_V01\n",
      "1 25.00elapsed:  0:00:04.040156\n",
      "2 50.00elapsed:  0:00:07.027524\n",
      "3 75.00elapsed:  0:00:10.117768\n",
      "4 100.00elapsed:  0:00:13.182042\n",
      "\n",
      "usage: aws s3 cp <LocalPath> <S3Uri> or <S3Uri> <LocalPath> or <S3Uri> <S3Uri>\n",
      "Error: Invalid argument type\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    start_time = time.time()\n",
    "    !mkdir -p {ec2_output_path}\n",
    "    keys = aqueduct3.get_GCS_keys(gcs_input_path)\n",
    "    # Limiting to tiffs for now.\n",
    "    keys = list(filter(lambda x: x.endswith('.tif'), keys))\n",
    "    df = aqueduct3.keys_to_df(keys,SEPARATOR,SCHEMA)\n",
    "    df = df.assign(**EXTRA_PROPERTIES)\n",
    "    df[\"exportdescription\"] = df[\"file_name\"]\n",
    "    df = df.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "    # Earth Engine Preparations\n",
    "    # Create folder (create parent if non existent)\n",
    "    if OVERWRITE:\n",
    "        command = \"earthengine rm -r {}\".format(ee_output_path)\n",
    "        print(command)\n",
    "        subprocess.check_output(command,shell=True)\n",
    "\n",
    "    command = \"earthengine create folder {}\".format(ee_output_path)\n",
    "    print(command)\n",
    "    subprocess.check_output(command,shell=True)\n",
    "    \n",
    "    df_errors = pd.DataFrame()\n",
    "    for index, row in df.iterrows():\n",
    "        elapsed_time = time.time() - start_time \n",
    "        print(index,\"{:02.2f}\".format((float(index)/df.shape[0])*100) + \"elapsed: \", str(timedelta(seconds=elapsed_time)))\n",
    "\n",
    "        geotiff_gcs_path = gcs_input_path + row.file_name + \".\" + row.extension\n",
    "        output_ee_asset_id = ee_output_path + \"/\" + row.file_name\n",
    "        properties = row.to_dict()\n",
    "\n",
    "        df_errors2 = aqueduct3.upload_geotiff_to_EE_imageCollection(geotiff_gcs_path, output_ee_asset_id, properties,index)\n",
    "        df_errors = df_errors.append(df_errors2) \n",
    "\n",
    "    # Storing error dataframe on ec2 and S3\n",
    "    df_errors.to_csv(\"{}/{}\".format(ec2_output_path,OUTPUT_FILE_NAME))\n",
    "    !aws s3 cp  {ec2_output_path} {s3_output_path} --recursive\n",
    "   \n",
    "    # Retry Failed Tasks Once\n",
    "    df_retry = df_errors.loc[df_errors['error'] != 0]\n",
    "    for index, row in df_retry.iterrows():\n",
    "        response = subprocess.check_output(row.command, shell=True)\n",
    "\n",
    "    return df,df_errors\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df,df_errors = main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:18.907899\n"
     ]
    }
   ],
   "source": [
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Previous runs:  \n",
    "0:00:18.907899"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 35",
   "language": "python",
   "name": "python35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
