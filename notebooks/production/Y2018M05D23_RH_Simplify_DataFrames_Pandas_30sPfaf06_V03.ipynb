{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input ec2: /volumes/data/Y2018M05D23_RH_Simplify_DataFrames_Pandas_30sPfaf06_V03/input_V08 \n",
      "Input postGIS table area: area_m2_30spfaf06 \n",
      "Input s3 riverdischarge: s3://wri-projects/Aqueduct30/processData/Y2018M05D16_RH_Final_Riverdischarge_30sPfaf06_V01/output_V06 \n",
      "Input s3 demand: s3://wri-projects/Aqueduct30/processData/Y2018M04D22_RH_Zonal_Stats_Demand_EE_V01/output_V01 \n",
      "Output s3: s3://wri-projects/Aqueduct30/processData/Y2018M05D23_RH_Simplify_DataFrames_Pandas_30sPfaf06_V03/output_V08/\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Combine and simplify demand and riverdischarge dataframes.\n",
    "-------------------------------------------------------------------------------\n",
    "\n",
    "Combine the area, demand and riverdischarge dataframes and put them in a \n",
    "simplified and cleaned format. A community question has been posted at: \n",
    "https://stackoverflow.com/questions/50486168/is-it-ok-to-split-value-and-parameter-in-database/50488411#50488411\n",
    "\n",
    "Args:\n",
    "    TESTING (Boolean) : Toggle testing case.\n",
    "    SCRIPT_NAME (string) : Script name.\n",
    "    OUTPUT_VERSION (integer) : output version.\n",
    "    DATABASE_ENDPOINT (string) : RDS or postGreSQL endpoint.\n",
    "    DATABASE_NAME (string) : Database name.\n",
    "    TABLE_NAME_AREA_30SPFAF06 (string) : Table name used for areas. Must exist\n",
    "        on same database as used in rest of script.\n",
    "    S3_INPUT_PATH_RIVERDISCHARGE (string) : AWS S3 input path for \n",
    "        riverdischarge.    \n",
    "    S3_INPUT_PATH_DEMAND (string) : AWS S3 input path for \n",
    "        demand.     \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "TESTING = 0\n",
    "OVERWRITE_INPUT = 0\n",
    "OVERWRITE_OUTPUT = 1\n",
    "SCRIPT_NAME = \"Y2018M05D23_RH_Simplify_DataFrames_Pandas_30sPfaf06_V03\"\n",
    "OUTPUT_VERSION = 8\n",
    "NODATA_VALUE = -9999\n",
    "\n",
    "DATABASE_ENDPOINT = \"aqueduct30v05.cgpnumwmfcqc.eu-central-1.rds.amazonaws.com\"\n",
    "DATABASE_NAME = \"database01\"\n",
    "\n",
    "# Area \n",
    "TABLE_NAME_AREA_30SPFAF06 = \"area_m2_30spfaf06\"\n",
    "\n",
    "# Riverdischarge\n",
    "S3_INPUT_PATH_RIVERDISCHARGE = \"s3://wri-projects/Aqueduct30/processData/Y2018M05D16_RH_Final_Riverdischarge_30sPfaf06_V01/output_V06\"\n",
    "\n",
    "# Demand\n",
    "S3_INPUT_PATH_DEMAND = \"s3://wri-projects/Aqueduct30/processData/Y2018M04D22_RH_Zonal_Stats_Demand_EE_V01/output_V01\"\n",
    "\n",
    "ec2_input_path = \"/volumes/data/{}/input_V{:02.0f}\".format(SCRIPT_NAME,OUTPUT_VERSION)\n",
    "ec2_output_path = \"/volumes/data/{}/output_V{:02.0f}\".format(SCRIPT_NAME,OUTPUT_VERSION)\n",
    "s3_output_path = \"s3://wri-projects/Aqueduct30/processData/{}/output_V{:02.0f}/\".format(SCRIPT_NAME,OUTPUT_VERSION)\n",
    "\n",
    "print(\"\\nInput ec2: \" + ec2_input_path,\n",
    "      \"\\nInput postGIS table area: \" + TABLE_NAME_AREA_30SPFAF06 ,\n",
    "      \"\\nInput s3 riverdischarge: \" + S3_INPUT_PATH_RIVERDISCHARGE,\n",
    "      \"\\nInput s3 demand: \" + S3_INPUT_PATH_DEMAND,\n",
    "      \"\\nOutput s3: \" + s3_output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y2018M05D31 UTC 12:23\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.5.4 |Anaconda, Inc.| (default, Nov 20 2017, 18:44:38) \\n[GCC 7.2.0]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time, datetime, sys\n",
    "dateString = time.strftime(\"Y%YM%mD%d\")\n",
    "timeString = time.strftime(\"UTC %H:%M\")\n",
    "start = datetime.datetime.now()\n",
    "print(dateString,timeString)\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if OVERWRITE_INPUT:\n",
    "    !rm -r {ec2_input_path}\n",
    "    !mkdir -p {ec2_input_path}\n",
    "    !aws s3 cp {S3_INPUT_PATH_RIVERDISCHARGE} {ec2_input_path} --recursive --exclude=\"*\" --include=\"*.pkl\"\n",
    "    !aws s3 cp {S3_INPUT_PATH_DEMAND} {ec2_input_path} --recursive --exclude=\"*\" --include=\"*.pkl\"\n",
    "\n",
    "if OVERWRITE_OUTPUT:\n",
    "    !rm -r {ec2_output_path}\n",
    "    !mkdir -p {ec2_output_path}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import aqueduct3\n",
    "from datetime import timedelta\n",
    "from sqlalchemy import *\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_area_df():\n",
    "    F = open(\"/.password\",\"r\")\n",
    "    password = F.read().splitlines()[0]\n",
    "    F.close()\n",
    "    \n",
    "    engine = create_engine(\"postgresql://rutgerhofste:{}@{}:5432/{}\".format(password,DATABASE_ENDPOINT,DATABASE_NAME))\n",
    "    connection = engine.connect()\n",
    "\n",
    "    if TESTING:\n",
    "        query = \"SELECT * FROM {} LIMIT 100\".format(TABLE_NAME_AREA_30SPFAF06)\n",
    "    else:\n",
    "        query = \"SELECT * FROM {}\".format(TABLE_NAME_AREA_30SPFAF06)\n",
    "    df_area = pd.read_sql(query,connection)\n",
    "    return df_area\n",
    "\n",
    "def pre_process_area(df):\n",
    "    df_out = df[[\"pfafid_30spfaf06\",\"area_m2_30spfaf06\",\"count\"]]\n",
    "    df_out.rename(columns={\"count\":\"area_count_30spfaf06\"},inplace=True)\n",
    "    df_out.set_index(\"pfafid_30spfaf06\",inplace=True)\n",
    "    return df_out\n",
    "\n",
    "\n",
    "def get_file_names(file_names,temporal_resolution,year,month):\n",
    "    \"\"\" Finds the filenames for riverdischarge and demand using regex.\n",
    "    -------------------------------------------------------------------------------\n",
    "    \n",
    "    WARNING: Month is set to 1 for yearly (annual) data for riverdischarge\n",
    "    whereas for demand month is set to 12. \n",
    "    \n",
    "    \n",
    "    Args:\n",
    "        file_names (list) : list of all file names.\n",
    "        temporal_resolution (string) : 'month' or 'year'\n",
    "        year (integer) : year [1960:2014]\n",
    "        month (integer) : month [1:12]. Not used if temporal_resolution is 'year'\n",
    "    \n",
    "    Returns:\n",
    "        matching_file_names (dict) : dictionary with matching filenames for \n",
    "            demand and discharge.\n",
    "    \n",
    "    \"\"\"   \n",
    "    \n",
    "    matching_file_names = {}    \n",
    "    matching_file_names[\"riverdischarge\"] = []\n",
    "    matching_file_names[\"demand\"] = []\n",
    "    \n",
    "    if temporal_resolution == \"year\":\n",
    "        month_riverdischarge = 1\n",
    "        month_demand = 12\n",
    "        riverdischarge_pattern = \"global_historical_combinedriverdischarge_{}_millionm3_30sPfaf06_1960_2014_I\\d\\d\\dY{:04.0f}M{:02.0f}.pkl\".format(temporal_resolution,year,month_riverdischarge)\n",
    "        demand_pattern = \"global_historical_P....._{}_m_5min_1960_2014_I\\d\\d\\dY{:04.0f}M{:02.0f}_reduced_06_30s_mean.pkl\".format(temporal_resolution,year,month_demand)      \n",
    "    else:\n",
    "        riverdischarge_pattern = \"global_historical_combinedriverdischarge_{}_millionm3_30sPfaf06_1960_2014_I\\d\\d\\dY{:04.0f}M{:02.0f}.pkl\".format(temporal_resolution,year,month)\n",
    "        demand_pattern = \"global_historical_P....._{}_m_5min_1960_2014_I\\d\\d\\dY{:04.0f}M{:02.0f}_reduced_06_30s_mean.pkl\".format(temporal_resolution,year,month)\n",
    "\n",
    "    for file_name in file_names:\n",
    "        if re.search(riverdischarge_pattern,file_name):\n",
    "            matching_file_names[\"riverdischarge\"].append(file_name)\n",
    "        elif re.search(demand_pattern,file_name):\n",
    "            matching_file_names[\"demand\"].append(file_name)\n",
    "    return matching_file_names\n",
    "\n",
    "def pre_process_df(df):\n",
    "    \"\"\" rename dataframe column and drastically simplify dataframe.\n",
    "    -------------------------------------------------------------------------------\n",
    "    \n",
    "    The column name will be in format: \n",
    "    domww_m_30spfaf06    \n",
    "    {indicator}_{unit}_{spatial_aggregation}\n",
    "    \n",
    "    The temporal resolution is not added to the schema.   \n",
    "        \n",
    "    Args:\n",
    "        df (pd.DataFrame) : input dataframe.\n",
    "    \n",
    "    Returns:\n",
    "        df_out (pd.DataFrame) : \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    df_in = df.copy()\n",
    "    \n",
    "    indicator = df_in.loc[0][\"indicator\"].lower()\n",
    "    unit = df_in.loc[0][\"unit\"].lower()\n",
    "    zones_spatial_resolution = df_in.loc[0][\"zones_spatial_resolution\"]\n",
    "    zones_pfaf_level = df_in.loc[0][\"zones_pfaf_level\"]    \n",
    "    \n",
    "    new_indicator_name = \"{}_{}_{}pfaf{:02.0f}\".format(indicator,unit,zones_spatial_resolution,zones_pfaf_level)\n",
    "    new_count_name = \"{}_count_{}pfaf{:02.0f}\".format(indicator,zones_spatial_resolution,zones_pfaf_level)\n",
    "    new_zones_name = \"pfafid_{}pfaf{:02.0f}\".format(zones_spatial_resolution,zones_pfaf_level)\n",
    "    \n",
    "    df_out = df_in[[\"zones\",\"count\",\"mean\",\"temporal_resolution\",\"year\",\"month\"]]\n",
    "    df_out.rename(columns={\"mean\":new_indicator_name,\n",
    "                           \"count\":new_count_name,\n",
    "                           \"zones\":new_zones_name},\n",
    "                  inplace=True)\n",
    "    \n",
    "    df_out[new_zones_name] = df_out[new_zones_name].astype(np.int64)\n",
    "    df_out.set_index(new_zones_name,inplace=True)\n",
    "    df_out.sort_index(axis=1, inplace=True)\n",
    "    return df_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/python35/lib/python3.5/site-packages/pandas/core/frame.py:3027: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "df_area = get_area_df()\n",
    "df_area = pre_process_area(df_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_m2_30spfaf06</th>\n",
       "      <th>area_count_30spfaf06</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pfafid_30spfaf06</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111011</th>\n",
       "      <td>1.885917e+09</td>\n",
       "      <td>2536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111012</th>\n",
       "      <td>2.925797e+09</td>\n",
       "      <td>3921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111013</th>\n",
       "      <td>8.924229e+08</td>\n",
       "      <td>1194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111014</th>\n",
       "      <td>4.206268e+09</td>\n",
       "      <td>5605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111015</th>\n",
       "      <td>1.659706e+10</td>\n",
       "      <td>21873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  area_m2_30spfaf06  area_count_30spfaf06\n",
       "pfafid_30spfaf06                                         \n",
       "111011                 1.885917e+09                  2536\n",
       "111012                 2.925797e+09                  3921\n",
       "111013                 8.924229e+08                  1194\n",
       "111014                 4.206268e+09                  5605\n",
       "111015                 1.659706e+10                 21873"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_area.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_names = os.listdir(ec2_input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temporal_resolutions = [\"year\",\"month\"]\n",
    "years = range(1960,2014+1)\n",
    "months = range(1,12+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if TESTING:\n",
    "    temporal_resolutions = [\"month\",\"year\"]\n",
    "    years = range(1960,1962)\n",
    "    months = range(1,3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_matchingfilenames(matching_file_names,df_area,ec2_input_path):\n",
    "    \"\"\" Merge Area, Demand and riverdischarge \n",
    "    -------------------------------------------------------------------------------\n",
    "    \n",
    "    Uses area as left table and performs a left join of demand (8x) and \n",
    "    riverdischarge. \n",
    "    \n",
    "    \n",
    "    Args:\n",
    "        matchingfile_names (dict) : Dictionary with list of strings with file names\n",
    "            of demand and riverdischarge pickled dataframe.\n",
    "        df_area (pd.DataFrame) : Pandas dataframe with area used as left table. \n",
    "        ec2_input_path (string) : ec2 input path. \n",
    "    \n",
    "    Returns:\n",
    "        df_merged (pd.DataFrame) : Merged Pandas DataFrame. \n",
    "    \n",
    "    \"\"\"\n",
    "    df_merged = df_area.copy()\n",
    "    for indicator, matching_file_names in matching_file_names.items():   \n",
    "        for matching_file_name in matching_file_names:    \n",
    "            file_path = \"{}/{}\".format(ec2_input_path,matching_file_name)\n",
    "            df = pd.read_pickle(file_path)   \n",
    "\n",
    "            if indicator == \"riverdischarge\":\n",
    "                df.rename(columns={\"count_mainchannel\":\"count\",\n",
    "                                   \"riverdischarge_millionm3\":\"mean\",\n",
    "                                   \"year_mainchannel\":\"year\",\n",
    "                                   \"month_mainchannel\":\"month\",\n",
    "                                   \"temporal_resolution_mainchannel\":\"temporal_resolution\",\n",
    "                                   \"indicator_mainchannel\":\"indicator\",\n",
    "                                   \"unit_mainchannel\":\"unit\",\n",
    "                                   \"zones_spatial_resolution_mainchannel\":\"zones_spatial_resolution\",\n",
    "                                   \"zones_pfaf_level_mainchannel\":\"zones_pfaf_level\"},\n",
    "                          inplace = True)  \n",
    "\n",
    "\n",
    "            elif indicator == \"demand\":\n",
    "                pass\n",
    "            df_cleaned = pre_process_df(df)\n",
    "\n",
    "\n",
    "            df_merged = df_merged.merge(right= df_cleaned,\n",
    "                                         how=\"left\",\n",
    "                                         left_index =True,\n",
    "                                         right_index = True,\n",
    "                                         suffixes = [\"\",\"_duplicate\"])\n",
    "\n",
    "            try:\n",
    "                # Take first non null \n",
    "                df_merged['month'].fillna(df_merged['month_duplicate'])\n",
    "                df_merged['year'].fillna(df_merged['year_duplicate'])\n",
    "                df_merged['temporal_resolution'].fillna(df_merged['temporal_resolution_duplicate'])\n",
    "                \n",
    "                \n",
    "                df_merged = df_merged.drop(columns = [\"month_duplicate\",\n",
    "                                                      \"temporal_resolution_duplicate\",\n",
    "                                                      \"year_duplicate\"] ) \n",
    "                \n",
    "                # Try to cast to integer                \n",
    "                df_merged[\"month\"] = df_merged[\"month\"].astype(np.int64)\n",
    "                df_merged[\"year\"] = df_merged[\"year\"].astype(np.int64)\n",
    "                 \n",
    "            except:\n",
    "                pass\n",
    "    df_merged[\"riverdischarge_m_30spfaf06\"] = (df_merged[\"riverdischarge_millionm3_30spfaf06\"] * 1e6) / df_merged[\"area_m2_30spfaf06\"]\n",
    "    df_merged.drop(columns=[\"riverdischarge_millionm3_30spfaf06\"],inplace=True)\n",
    "    df_merged.sort_index(axis=1, inplace=True)\n",
    "    #df_merged.fillna(NODATA_VALUE, inplace=True) \n",
    "    \n",
    "    return df_merged\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/python35/lib/python3.5/site-packages/pandas/core/frame.py:3027: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n",
      "/opt/anaconda3/envs/python35/lib/python3.5/site-packages/ipykernel_launcher.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/anaconda3/envs/python35/lib/python3.5/site-packages/ipykernel_launcher.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 001 Elapsed: 0:00:00.000220\n",
      "1 year 1960 1\n",
      "Index: 002 Elapsed: 0:00:01.214159\n",
      "2 year 1961 1\n",
      "Index: 003 Elapsed: 0:00:02.433167\n",
      "3 year 1962 1\n",
      "Index: 004 Elapsed: 0:00:03.647914\n",
      "4 year 1963 1\n",
      "Index: 005 Elapsed: 0:00:04.872039\n",
      "5 year 1964 1\n",
      "Index: 006 Elapsed: 0:00:06.070001\n",
      "6 year 1965 1\n",
      "Index: 007 Elapsed: 0:00:07.294872\n",
      "7 year 1966 1\n",
      "Index: 008 Elapsed: 0:00:08.552490\n",
      "8 year 1967 1\n",
      "Index: 009 Elapsed: 0:00:09.812196\n",
      "9 year 1968 1\n",
      "Index: 010 Elapsed: 0:00:11.135460\n",
      "10 year 1969 1\n",
      "Index: 011 Elapsed: 0:00:12.448747\n",
      "11 year 1970 1\n",
      "Index: 012 Elapsed: 0:00:13.733602\n",
      "12 year 1971 1\n",
      "Index: 013 Elapsed: 0:00:14.989258\n",
      "13 year 1972 1\n",
      "Index: 014 Elapsed: 0:00:16.237114\n",
      "14 year 1973 1\n",
      "Index: 015 Elapsed: 0:00:17.519596\n",
      "15 year 1974 1\n",
      "Index: 016 Elapsed: 0:00:18.739959\n",
      "16 year 1975 1\n",
      "Index: 017 Elapsed: 0:00:19.964954\n",
      "17 year 1976 1\n",
      "Index: 018 Elapsed: 0:00:21.235436\n",
      "18 year 1977 1\n",
      "Index: 019 Elapsed: 0:00:22.437075\n",
      "19 year 1978 1\n",
      "Index: 020 Elapsed: 0:00:23.649261\n",
      "20 year 1979 1\n",
      "Index: 021 Elapsed: 0:00:24.917970\n",
      "21 year 1980 1\n",
      "Index: 022 Elapsed: 0:00:26.172991\n",
      "22 year 1981 1\n",
      "Index: 023 Elapsed: 0:00:27.498500\n",
      "23 year 1982 1\n",
      "Index: 024 Elapsed: 0:00:28.773154\n",
      "24 year 1983 1\n",
      "Index: 025 Elapsed: 0:00:30.024500\n",
      "25 year 1984 1\n",
      "Index: 026 Elapsed: 0:00:31.267771\n",
      "26 year 1985 1\n",
      "Index: 027 Elapsed: 0:00:32.523758\n",
      "27 year 1986 1\n",
      "Index: 028 Elapsed: 0:00:33.758306\n",
      "28 year 1987 1\n",
      "Index: 029 Elapsed: 0:00:35.016080\n",
      "29 year 1988 1\n",
      "Index: 030 Elapsed: 0:00:36.389653\n",
      "30 year 1989 1\n",
      "Index: 031 Elapsed: 0:00:37.685287\n",
      "31 year 1990 1\n",
      "Index: 032 Elapsed: 0:00:38.947039\n",
      "32 year 1991 1\n",
      "Index: 033 Elapsed: 0:00:40.182827\n",
      "33 year 1992 1\n",
      "Index: 034 Elapsed: 0:00:41.420846\n",
      "34 year 1993 1\n",
      "Index: 035 Elapsed: 0:00:42.676329\n",
      "35 year 1994 1\n",
      "Index: 036 Elapsed: 0:00:43.923133\n",
      "36 year 1995 1\n",
      "Index: 037 Elapsed: 0:00:45.185764\n",
      "37 year 1996 1\n",
      "Index: 038 Elapsed: 0:00:46.455506\n",
      "38 year 1997 1\n",
      "Index: 039 Elapsed: 0:00:47.694966\n",
      "39 year 1998 1\n",
      "Index: 040 Elapsed: 0:00:48.983958\n",
      "40 year 1999 1\n",
      "Index: 041 Elapsed: 0:00:50.216997\n",
      "41 year 2000 1\n",
      "Index: 042 Elapsed: 0:00:51.440208\n",
      "42 year 2001 1\n",
      "Index: 043 Elapsed: 0:00:52.649702\n",
      "43 year 2002 1\n",
      "Index: 044 Elapsed: 0:00:53.847071\n",
      "44 year 2003 1\n",
      "Index: 045 Elapsed: 0:00:55.027318\n",
      "45 year 2004 1\n",
      "Index: 046 Elapsed: 0:00:56.228255\n",
      "46 year 2005 1\n",
      "Index: 047 Elapsed: 0:00:57.433567\n",
      "47 year 2006 1\n",
      "Index: 048 Elapsed: 0:00:58.649206\n",
      "48 year 2007 1\n",
      "Index: 049 Elapsed: 0:00:59.859542\n",
      "49 year 2008 1\n",
      "Index: 050 Elapsed: 0:01:01.063435\n",
      "50 year 2009 1\n",
      "Index: 051 Elapsed: 0:01:02.294198\n",
      "51 year 2010 1\n",
      "Index: 052 Elapsed: 0:01:03.513837\n",
      "52 year 2011 1\n",
      "Index: 053 Elapsed: 0:01:04.736134\n",
      "53 year 2012 1\n",
      "Index: 054 Elapsed: 0:01:05.953724\n",
      "54 year 2013 1\n",
      "Index: 055 Elapsed: 0:01:07.200130\n",
      "55 year 2014 1\n",
      "Index: 056 Elapsed: 0:01:08.426820\n",
      "56 month 1960 1\n",
      "Index: 057 Elapsed: 0:01:09.647198\n",
      "57 month 1960 2\n",
      "Index: 058 Elapsed: 0:01:10.846027\n",
      "58 month 1960 3\n",
      "Index: 059 Elapsed: 0:01:12.066006\n",
      "59 month 1960 4\n",
      "Index: 060 Elapsed: 0:01:13.333965\n",
      "60 month 1960 5\n",
      "Index: 061 Elapsed: 0:01:14.597174\n",
      "61 month 1960 6\n",
      "Index: 062 Elapsed: 0:01:15.840788\n",
      "62 month 1960 7\n",
      "Index: 063 Elapsed: 0:01:17.095585\n",
      "63 month 1960 8\n",
      "Index: 064 Elapsed: 0:01:18.361225\n",
      "64 month 1960 9\n",
      "Index: 065 Elapsed: 0:01:19.638042\n",
      "65 month 1960 10\n",
      "Index: 066 Elapsed: 0:01:20.934697\n",
      "66 month 1960 11\n",
      "Index: 067 Elapsed: 0:01:22.172971\n",
      "67 month 1960 12\n",
      "Index: 068 Elapsed: 0:01:23.409607\n",
      "68 month 1961 1\n",
      "Index: 069 Elapsed: 0:01:24.647429\n",
      "69 month 1961 2\n",
      "Index: 070 Elapsed: 0:01:25.887844\n",
      "70 month 1961 3\n",
      "Index: 071 Elapsed: 0:01:27.163371\n",
      "71 month 1961 4\n",
      "Index: 072 Elapsed: 0:01:28.559361\n",
      "72 month 1961 5\n",
      "Index: 073 Elapsed: 0:01:29.953465\n",
      "73 month 1961 6\n",
      "Index: 074 Elapsed: 0:01:31.304287\n",
      "74 month 1961 7\n",
      "Index: 075 Elapsed: 0:01:32.641407\n",
      "75 month 1961 8\n",
      "Index: 076 Elapsed: 0:01:34.015184\n",
      "76 month 1961 9\n",
      "Index: 077 Elapsed: 0:01:35.299876\n",
      "77 month 1961 10\n",
      "Index: 078 Elapsed: 0:01:36.626931\n",
      "78 month 1961 11\n",
      "Index: 079 Elapsed: 0:01:37.893425\n",
      "79 month 1961 12\n",
      "Index: 080 Elapsed: 0:01:39.164878\n",
      "80 month 1962 1\n",
      "Index: 081 Elapsed: 0:01:40.407723\n",
      "81 month 1962 2\n",
      "Index: 082 Elapsed: 0:01:41.614250\n",
      "82 month 1962 3\n",
      "Index: 083 Elapsed: 0:01:42.863851\n",
      "83 month 1962 4\n",
      "Index: 084 Elapsed: 0:01:44.098991\n",
      "84 month 1962 5\n",
      "Index: 085 Elapsed: 0:01:45.329590\n",
      "85 month 1962 6\n",
      "Index: 086 Elapsed: 0:01:46.603156\n",
      "86 month 1962 7\n",
      "Index: 087 Elapsed: 0:01:47.831423\n",
      "87 month 1962 8\n",
      "Index: 088 Elapsed: 0:01:49.064135\n",
      "88 month 1962 9\n",
      "Index: 089 Elapsed: 0:01:50.373030\n",
      "89 month 1962 10\n",
      "Index: 090 Elapsed: 0:01:51.649406\n",
      "90 month 1962 11\n",
      "Index: 091 Elapsed: 0:01:52.922074\n",
      "91 month 1962 12\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "start_time = time.time()\n",
    "for temporal_resolution in temporal_resolutions:\n",
    "    if temporal_resolution == \"month\":\n",
    "        for year in years:\n",
    "            for month in months:\n",
    "                i = i + 1\n",
    "                elapsed_time = time.time() - start_time \n",
    "                print(\"Index: {:03.0f} Elapsed: {}\".format(i, timedelta(seconds=elapsed_time)))\n",
    "                print(i,temporal_resolution,year,month)\n",
    "                matching_file_names = get_file_names(file_names,temporal_resolution,year,month) \n",
    "                df_merged = process_matchingfilenames(matching_file_names,df_area,ec2_input_path)\n",
    "                output_file_name = \"global_historical_merged_{}_m_30sPfaf06_1960_2014_Y{:04.0f}M{:02.0f}.pkl\".format(temporal_resolution,year,month)\n",
    "                output_path = \"{}/{}\".format(ec2_output_path,output_file_name)\n",
    "                df_merged.to_pickle(output_path)        \n",
    "    elif temporal_resolution == \"year\":\n",
    "        for year in years:\n",
    "            month = 1\n",
    "            i = i + 1\n",
    "            elapsed_time = time.time() - start_time \n",
    "            print(\"Index: {:03.0f} Elapsed: {}\".format(i, timedelta(seconds=elapsed_time)))\n",
    "            print(i,temporal_resolution,year,month)\n",
    "            matching_file_names = get_file_names(file_names,temporal_resolution,year,month) \n",
    "            df_merged = process_matchingfilenames(matching_file_names,df_area,ec2_input_path)\n",
    "            output_file_name = \"global_historical_merged_{}_m_30sPfaf06_1960_2014_Y{:04.0f}M{:02.0f}.pkl\".format(temporal_resolution,year,month)\n",
    "            output_path = \"{}/{}\".format(ec2_output_path,output_file_name)\n",
    "            df_merged.to_pickle(output_path)     \n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "                     \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp {ec2_output_path} {s3_output_path} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous Runs:  \n",
    "0:39:39.668227  \n",
    "0:42:53.025204  \n",
    "0:47:08.975392  \n",
    "0:31:06.810078\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 35",
   "language": "python",
   "name": "python35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
