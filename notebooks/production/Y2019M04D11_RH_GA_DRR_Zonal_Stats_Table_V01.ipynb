{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCS_INPUT_PATH: gs://aqueduct30_v01/Y2019M01D29_RH_GA_DR_Zonal_Stats_GADM_EE_V01/output_V03\n",
      "ec2_input_path: /volumes/data/Y2019M04D11_RH_GA_DRR_Zonal_Stats_Table_V01/input_V03\n",
      "ec2_output_path: /volumes/data/Y2019M04D11_RH_GA_DRR_Zonal_Stats_Table_V01/output_V03\n",
      "s3_output_path: s3://wri-projects/Aqueduct30/processData/Y2019M04D11_RH_GA_DRR_Zonal_Stats_Table_V01/output_V03/\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Post process aggregations from drought risk EE.\n",
    "-------------------------------------------------------------------------------\n",
    "\n",
    "Store drought risk result in tabular format, compatible with other baseline \n",
    "water stress, baseline water depletion, interannual variability, seasonal \n",
    "variobility. \n",
    "\n",
    "indicator weights \n",
    "drr withdrawal per sector\n",
    "\n",
    "Author: Rutger Hofste\n",
    "Date: 20190411\n",
    "Kernel: python35\n",
    "Docker: rutgerhofste/gisdocker:ubuntu16.04\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "TESTING = 0\n",
    "SCRIPT_NAME = \"Y2019M04D11_RH_GA_DRR_Zonal_Stats_Table_V01\"\n",
    "OUTPUT_VERSION = 3\n",
    "\n",
    "GCS_INPUT_PATH = \"gs://aqueduct30_v01/Y2019M01D29_RH_GA_DR_Zonal_Stats_GADM_EE_V01/output_V03\"\n",
    "\n",
    "BQ_PROJECT_ID = \"aqueduct30\"\n",
    "BQ_DATASET_NAME = \"aqueduct30v01\"\n",
    "BQ_INPUT_TABLE_NAME_LABEL = \"y2018m12d04_rh_master_merge_rawdata_gpd_v02_v09\"\n",
    "BQ_INPUT_TABLE_NAME_GADM  = \"y2018m11d12_rh_gadm36_level1_rds_to_bq_v01_v01\"\n",
    "BQ_OUTPUT_TABLE_NAME = \"{}_v{:02.0f}\".format(SCRIPT_NAME,OUTPUT_VERSION).lower()\n",
    "\n",
    "\n",
    "ec2_input_path = \"/volumes/data/{}/input_V{:02.0f}\".format(SCRIPT_NAME,OUTPUT_VERSION) \n",
    "ec2_output_path = \"/volumes/data/{}/output_V{:02.0f}\".format(SCRIPT_NAME,OUTPUT_VERSION) \n",
    "\n",
    "s3_output_path = \"s3://wri-projects/Aqueduct30/processData/{}/output_V{:02.0f}/\".format(SCRIPT_NAME,OUTPUT_VERSION)\n",
    "\n",
    "print(\"GCS_INPUT_PATH: \" + GCS_INPUT_PATH +\n",
    "      \"\\nec2_input_path: \" +  ec2_input_path + \n",
    "      \"\\nec2_output_path: \" + ec2_output_path + \n",
    "      \"\\ns3_output_path: \" + s3_output_path  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y2019M04D15 UTC 14:03\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.5.4 |Anaconda, Inc.| (default, Nov 20 2017, 18:44:38) \\n[GCC 7.2.0]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time, datetime, sys\n",
    "dateString = time.strftime(\"Y%YM%mD%d\")\n",
    "timeString = time.strftime(\"UTC %H:%M\")\n",
    "start = datetime.datetime.now()\n",
    "print(dateString,timeString)\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r {ec2_input_path}\n",
    "!rm -r {ec2_output_path}\n",
    "!mkdir -p {ec2_input_path}\n",
    "!mkdir -p {ec2_output_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://aqueduct30_v01/Y2019M01D29_RH_GA_DR_Zonal_Stats_GADM_EE_V01/output_V03/Dom_weighted_drr_sumee_export.csv...\n",
      "Copying gs://aqueduct30_v01/Y2019M01D29_RH_GA_DR_Zonal_Stats_GADM_EE_V01/output_V03/Dom_weights_sumee_export.csv...\n",
      "Copying gs://aqueduct30_v01/Y2019M01D29_RH_GA_DR_Zonal_Stats_GADM_EE_V01/output_V03/Ind_weighted_drr_sumee_export.csv...\n",
      "Copying gs://aqueduct30_v01/Y2019M01D29_RH_GA_DR_Zonal_Stats_GADM_EE_V01/output_V03/Ind_weights_sumee_export.csv...\n",
      "Copying gs://aqueduct30_v01/Y2019M01D29_RH_GA_DR_Zonal_Stats_GADM_EE_V01/output_V03/Irr_weighted_drr_sumee_export.csv...\n",
      "Copying gs://aqueduct30_v01/Y2019M01D29_RH_GA_DR_Zonal_Stats_GADM_EE_V01/output_V03/Irr_weights_sumee_export.csv...\n",
      "Copying gs://aqueduct30_v01/Y2019M01D29_RH_GA_DR_Zonal_Stats_GADM_EE_V01/output_V03/Liv_weights_sumee_export.csv...\n",
      "Copying gs://aqueduct30_v01/Y2019M01D29_RH_GA_DR_Zonal_Stats_GADM_EE_V01/output_V03/Liv_weighted_drr_sumee_export.csv...\n",
      "Copying gs://aqueduct30_v01/Y2019M01D29_RH_GA_DR_Zonal_Stats_GADM_EE_V01/output_V03/One_weighted_drr_sumee_export.csv...\n",
      "Copying gs://aqueduct30_v01/Y2019M01D29_RH_GA_DR_Zonal_Stats_GADM_EE_V01/output_V03/One_weights_sumee_export.csv...\n",
      "Copying gs://aqueduct30_v01/Y2019M01D29_RH_GA_DR_Zonal_Stats_GADM_EE_V01/output_V03/Tot_weighted_drr_sumee_export.csv...\n",
      "Copying gs://aqueduct30_v01/Y2019M01D29_RH_GA_DR_Zonal_Stats_GADM_EE_V01/output_V03/Tot_weights_sumee_export.csv...\n",
      "/ [12/12 files][  1.9 MiB/  1.9 MiB] 100% Done                                  \n",
      "Operation completed over 12 objects/1.9 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp {GCS_INPUT_PATH}/* {ec2_input_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/.google.json\"\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = \"aqueduct30\"\n",
    "client = bigquery.Client(project=BQ_PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT\n",
    "  indicator,\n",
    "  AVG(cat) AS cat,\n",
    "  label\n",
    "FROM\n",
    "  `{}.{}.{}`\n",
    "GROUP BY\n",
    "  label, indicator\n",
    "ORDER BY\n",
    "  indicator, cat\n",
    "\"\"\".format(BQ_PROJECT_ID,BQ_DATASET_NAME,BQ_INPUT_TABLE_NAME_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_labels = pd.read_gbq(query=sql,\n",
    "                        project_id =BQ_PROJECT_ID,\n",
    "                        dialect=\"standard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indicator</th>\n",
       "      <th>cat</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bwd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bwd</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Arid and Low Water Use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bwd</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low (&lt;5%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bwd</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low - Medium (5-25%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  indicator  cat                   label\n",
       "0      None  NaN                    None\n",
       "1       bwd  NaN                    None\n",
       "2       bwd -1.0  Arid and Low Water Use\n",
       "3       bwd  0.0               Low (<5%)\n",
       "4       bwd  1.0    Low - Medium (5-25%)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GADM Level 1 names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT\n",
    "  gid_1,\n",
    "  gid_0,\n",
    "  name_1,\n",
    "  name_0\n",
    "FROM\n",
    "  `{}.{}.{}`\n",
    "ORDER BY\n",
    "  gid_1\n",
    "\"\"\".format(BQ_PROJECT_ID,BQ_DATASET_NAME,BQ_INPUT_TABLE_NAME_GADM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_gadm_1 = pd.read_gbq(query=sql,\n",
    "                        project_id =BQ_PROJECT_ID,\n",
    "                        dialect=\"standard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GADM Level 0 names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT\n",
    "  name_0,\n",
    "  ANY_VALUE(gid_0) as gid_0\n",
    "FROM\n",
    "  `{}.{}.{}`\n",
    "GROUP BY\n",
    "  name_0\n",
    "ORDER BY\n",
    "  name_0\n",
    "\"\"\".format(BQ_PROJECT_ID,BQ_DATASET_NAME,BQ_INPUT_TABLE_NAME_GADM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_gadm_0 = pd.read_gbq(query=sql,\n",
    "                       project_id =BQ_PROJECT_ID,\n",
    "                       dialect=\"standard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_to_category(score):\n",
    "    if np.isnan(score):\n",
    "        cat = np.nan\n",
    "    else:\n",
    "        if score < 5:\n",
    "            cat = int(np.floor(score))\n",
    "        else:\n",
    "            cat = 4\n",
    "    return cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weights_df(sector):\n",
    "    \"\"\" Get Dataframe Per sector\n",
    "    \n",
    "    \"\"\"\n",
    "    input_file_name = \"{}_weights_sumee_export.csv\".format(sector)\n",
    "    input_file_path = \"{}/{}\".format(ec2_input_path,input_file_name)\n",
    "    df_weights = pd.read_csv(input_file_path)\n",
    "    df_weights.drop(columns=[\"system:index\",\".geo\"],\n",
    "                    inplace=True)\n",
    "    df_weights.rename(columns={\"sum\":\"sum_weights\"},\n",
    "                      inplace=True)\n",
    "    return df_weights\n",
    "\n",
    "def get_weighted_indicator_df(indicator):\n",
    "    \"\"\" Get DataFrame per indicator\n",
    "\n",
    "    \"\"\"\n",
    "    input_file_name = \"{}_weighted_{}_sumee_export.csv\".format(sector,indicator)\n",
    "    input_file_path = \"{}/{}\".format(ec2_input_path,input_file_name)\n",
    "    df = pd.read_csv(input_file_path)\n",
    "    df.drop(columns=[\"system:index\",\".geo\"],\n",
    "            inplace=True)\n",
    "    df.rename(columns={\"sum\":\"sum_weighted_indicator\"},inplace=True)\n",
    "    df[\"indicator_name\"] = indicator\n",
    "    df[\"weight\"] = sector\n",
    "    return df\n",
    "    \n",
    "\n",
    "def province_to_country(df,sector,indicator):\n",
    "    \"\"\" Convert province level dataframe to country level\n",
    "    DataFrame\n",
    "    \n",
    "    \n",
    "    \"\"\"   \n",
    "    df[\"gid_0\"] = df[\"gid_1\"].apply(lambda x:  x.split(\".\")[0])\n",
    "    \n",
    "    grouped = df.groupby('gid_0')\n",
    "    df_country = df.groupby(by=\"gid_0\",as_index=False).sum()\n",
    "    df_country[\"indicator_name\"] = indicator\n",
    "    df_country[\"weight\"] = sector\n",
    "    return df_country\n",
    "\n",
    "def process_df(df):\n",
    "    \"\"\" Calculate Score, add cat and label. \n",
    "    \n",
    "    Due to the zonal statistics in Google Earth Engine, \n",
    "    some semi masked cells produce score higher than 5. \n",
    "    Clipping all scores above 5 to 5. \n",
    "    \n",
    "    Sorts columns alphabetically.\n",
    "    \n",
    "    Ranks based on score. Uses minimum rank:\n",
    "    http://www.datasciencemadesimple.com/rank-dataframe-python-pandas-min-max-dense-rank-group/\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    df[\"score\"]  = df[\"sum_weighted_indicator\"] / df[\"sum_weights\"]\n",
    "    df[\"score\"].clip(lower=None,upper=5,inplace=True)\n",
    "    df[\"cat\"] = df[\"score\"].apply(score_to_category)\n",
    "    df = df.reindex(sorted(df.columns), axis=1)\n",
    "    df = pd.merge(left=df,\n",
    "                   right=df_labels,\n",
    "                   how=\"left\",\n",
    "                   left_on=[\"indicator_name\",\"cat\"],\n",
    "                   right_on=[\"indicator\",\"cat\"])\n",
    "    df.drop(columns=[\"indicator\"],\n",
    "            inplace=True)\n",
    "    df[\"score_ranked\"] = df[\"score\"].rank(ascending=False,method=\"min\")\n",
    "    return df\n",
    "\n",
    "def  export_df(df,geographic_scale):\n",
    "    \"\"\" Export Dataframe as csv on e2\n",
    "    and table on BigQuery\n",
    "    \n",
    "    Args:\n",
    "        df(pd.DataFrame)  :  DataFrame to export.\n",
    "        geographic_scale : \"country\" or \"province\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if geographic_scale == \"country\":\n",
    "        df_merged = pd.merge(left=df,\n",
    "                             right=df_gadm_0,\n",
    "                             how=\"left\",\n",
    "                             left_on=\"gid_0\",\n",
    "                             right_on=\"gid_0\")\n",
    "        df_merged = df_merged.reindex(sorted(df_merged.columns), axis=1)\n",
    "        df_merged_csv = df_merged.set_index(\"gid_0\")\n",
    "    elif geographic_scale == \"province\":\n",
    "        df.drop(columns=[\"gid_0\"],inplace=True)\n",
    "        df_merged = pd.merge(left=df,\n",
    "                             right=df_gadm_1,\n",
    "                             how=\"left\",\n",
    "                             left_on=\"gid_1\",\n",
    "                             right_on=\"gid_1\")\n",
    "        df_merged = df_merged.reindex(sorted(df_merged.columns), axis=1)\n",
    "        df_merged_csv = df_merged.set_index(\"gid_1\")\n",
    "    \n",
    "    \n",
    "    output_file_path_ec2 = \"{}/{}_{}_V{:02.0f}.csv\".format(ec2_output_path,SCRIPT_NAME,geographic_scale,OUTPUT_VERSION)\n",
    "    df_merged_csv.to_csv(path_or_buf=output_file_path_ec2,index=True)\n",
    "    \n",
    "    destination_table = \"{}.{}_{}_V{:02.0f}\".format(BQ_DATASET_NAME,SCRIPT_NAME,geographic_scale,OUTPUT_VERSION).lower()\n",
    "\n",
    "    df_merged.to_gbq(destination_table=destination_table,\n",
    "                     project_id=BQ_PROJECT_ID,\n",
    "                     if_exists=\"replace\")\n",
    "\n",
    "    return df_merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sectors = [\"One\",\"Tot\",\"Dom\",\"Ind\",\"Irr\",\"Liv\"]\n",
    "#indicators = [\"bws\",\"bwd\",\"iav\",\"sev\",\"gtd\",\"drr\",\"rfr\",\"cfr\",\"ucw\",\"cep\",\"udw\",\"usa\",\"rri\"]\n",
    "indicators = [\"drr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sector: One indicator:  drr\n",
      "sector: Tot indicator:  drr\n",
      "sector: Dom indicator:  drr\n",
      "sector: Ind indicator:  drr\n",
      "sector: Irr indicator:  drr\n",
      "sector: Liv indicator:  drr\n"
     ]
    }
   ],
   "source": [
    "df_appended_gid_1 = pd.DataFrame()\n",
    "df_appended_gid_0 = pd.DataFrame()\n",
    "\n",
    "for sector in sectors:\n",
    "    for indicator in indicators:\n",
    "        print(\"sector:\" , sector , \"indicator: \", indicator)\n",
    "        df_weights_gid_1 = get_weights_df(sector)\n",
    "        df_indicator_gid_1 = get_weighted_indicator_df(indicator)\n",
    "        df_gid_1 = pd.merge(left=df_weights_gid_1,\n",
    "                                   right=df_indicator_gid_1,\n",
    "                                   how=\"inner\",\n",
    "                                   left_on=\"gid_1\",\n",
    "                                   right_on=\"gid_1\")\n",
    "        df_gid_0 = province_to_country(df_gid_1,sector,indicator)\n",
    "        df_gid_0 = process_df(df_gid_0)\n",
    "        df_gid_1 = process_df(df_gid_1)\n",
    "        \n",
    "        df_appended_gid_0 = df_appended_gid_0.append(df_gid_0)\n",
    "        df_appended_gid_1 = df_appended_gid_1.append(df_gid_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:05,  5.40s/it]\n",
      "3it [00:10,  3.61s/it]\n"
     ]
    }
   ],
   "source": [
    "df_gid_0 = export_df(df_appended_gid_0,\"country\")\n",
    "df_gid_1 = export_df(df_appended_gid_1,\"province\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1368, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gid_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21696, 12)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gid_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>gid_0</th>\n",
       "      <th>gid_1</th>\n",
       "      <th>indicator_name</th>\n",
       "      <th>label</th>\n",
       "      <th>name_0</th>\n",
       "      <th>name_1</th>\n",
       "      <th>score</th>\n",
       "      <th>score_ranked</th>\n",
       "      <th>sum_weighted_indicator</th>\n",
       "      <th>sum_weights</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>BRA</td>\n",
       "      <td>BRA.19_1</td>\n",
       "      <td>drr</td>\n",
       "      <td>Low (0.0-0.2)</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Rio de Janeiro</td>\n",
       "      <td>0.441798</td>\n",
       "      <td>1924.0</td>\n",
       "      <td>24338.923394</td>\n",
       "      <td>55090.650980</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>BRA</td>\n",
       "      <td>BRA.13_1</td>\n",
       "      <td>drr</td>\n",
       "      <td>Low (0.0-0.2)</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Minas Gerais</td>\n",
       "      <td>0.440685</td>\n",
       "      <td>1930.0</td>\n",
       "      <td>319877.492602</td>\n",
       "      <td>725864.294118</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>BRA</td>\n",
       "      <td>BRA.25_1</td>\n",
       "      <td>drr</td>\n",
       "      <td>Low (0.0-0.2)</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>0.569868</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>178065.243423</td>\n",
       "      <td>312467.552941</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>BRA</td>\n",
       "      <td>BRA.8_1</td>\n",
       "      <td>drr</td>\n",
       "      <td>Low (0.0-0.2)</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Espírito Santo</td>\n",
       "      <td>0.550465</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>29881.856909</td>\n",
       "      <td>54284.796078</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>BRA</td>\n",
       "      <td>BRA.5_1</td>\n",
       "      <td>drr</td>\n",
       "      <td>Low (0.0-0.2)</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Bahia</td>\n",
       "      <td>0.485500</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>327664.100909</td>\n",
       "      <td>674900.239216</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat gid_0     gid_1 indicator_name          label  name_0          name_1  \\\n",
       "0   0   BRA  BRA.19_1            drr  Low (0.0-0.2)  Brazil  Rio de Janeiro   \n",
       "1   0   BRA  BRA.13_1            drr  Low (0.0-0.2)  Brazil    Minas Gerais   \n",
       "2   0   BRA  BRA.25_1            drr  Low (0.0-0.2)  Brazil       São Paulo   \n",
       "3   0   BRA   BRA.8_1            drr  Low (0.0-0.2)  Brazil  Espírito Santo   \n",
       "4   0   BRA   BRA.5_1            drr  Low (0.0-0.2)  Brazil           Bahia   \n",
       "\n",
       "      score  score_ranked  sum_weighted_indicator    sum_weights weight  \n",
       "0  0.441798        1924.0            24338.923394   55090.650980    One  \n",
       "1  0.440685        1930.0           319877.492602  725864.294118    One  \n",
       "2  0.569868        1220.0           178065.243423  312467.552941    One  \n",
       "3  0.550465        1340.0            29881.856909   54284.796078    One  \n",
       "4  0.485500        1726.0           327664.100909  674900.239216    One  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gid_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ../../../../data/Y2019M04D11_RH_GA_DRR_Zonal_Stats_Table_V01/output_V03/Y2019M04D11_RH_GA_DRR_Zonal_Stats_Table_V01_country_V03.csv to s3://wri-projects/Aqueduct30/processData/Y2019M04D11_RH_GA_DRR_Zonal_Stats_Table_V01/output_V03/Y2019M04D11_RH_GA_DRR_Zonal_Stats_Table_V01_country_V03.csv\n",
      "upload: ../../../../data/Y2019M04D11_RH_GA_DRR_Zonal_Stats_Table_V01/output_V03/Y2019M04D11_RH_GA_DRR_Zonal_Stats_Table_V01_province_V03.csv to s3://wri-projects/Aqueduct30/processData/Y2019M04D11_RH_GA_DRR_Zonal_Stats_Table_V01/output_V03/Y2019M04D11_RH_GA_DRR_Zonal_Stats_Table_V01_province_V03.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp {ec2_output_path} {s3_output_path} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:41.101792\n"
     ]
    }
   ],
   "source": [
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous runs:   \n",
    "0:00:41.101792"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 35",
   "language": "python",
   "name": "python35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
