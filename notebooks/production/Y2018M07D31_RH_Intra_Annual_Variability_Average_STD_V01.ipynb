{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bq dataset name:  aqueduct30v01 \n",
      "BQ_INPUT_TABLE_NAME:  y2018m07d30_rh_gcs_to_bq_v01_v02 \n",
      "Output bq table name:  y2018m07d31_rh_intra_annual_variability_average_std_v01_v01\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Calculate intra annual variability intermediate results.\n",
    "-------------------------------------------------------------------------------\n",
    "intra annual variability abbreviation is sv or seasonal veriability.\n",
    "\n",
    "Using total blue water vs using available blue water. \n",
    "\n",
    "Aqueduct is a project that manages risk so including consumption will lead to \n",
    "a better estimation of the water that is available to you. \n",
    "\n",
    "There are multiple ways to calculate intra annual variability.\n",
    "\n",
    "1. Calculate coefficient of variation for each year (jan-dec) and take the mean\n",
    "of those values. \n",
    "1. Calculate the mean of jan, feb etc. of all years and then calculate the \n",
    "coeficeint of variation, similar to Aqueduct 21 and used in Aqueduct 30 for\n",
    "consistency reasons.\n",
    "\n",
    "Author: Rutger Hofste\n",
    "Date: 20180731\n",
    "Kernel: python35\n",
    "Docker: rutgerhofste/gisdocker:ubuntu16.04\n",
    "\n",
    "Args:\n",
    "    TESTING (Boolean) : Toggle testing case.\n",
    "    SCRIPT_NAME (string) : Script name.\n",
    "    OUTPUT_VERSION (integer) : output version.\n",
    "    DATABASE_ENDPOINT (string) : RDS or postGreSQL endpoint.\n",
    "    DATABASE_NAME (string) : Database name.\n",
    "    TABLE_NAME_AREA_30SPFAF06 (string) : Table name used for areas. Must exist\n",
    "        on same database as used in rest of script.\n",
    "    S3_INPUT_PATH_RIVERDISCHARGE (string) : AWS S3 input path for \n",
    "        riverdischarge.    \n",
    "    S3_INPUT_PATH_DEMAND (string) : AWS S3 input path for \n",
    "        demand.  \n",
    "\"\"\"\n",
    "\n",
    "TESTING = 0\n",
    "OVERWRITE_OUTPUT = 1\n",
    "SCRIPT_NAME = 'Y2018M07D31_RH_Intra_Annual_Variability_Average_STD_V01'\n",
    "OUTPUT_VERSION = 1\n",
    "\n",
    "\n",
    "BQ_PROJECT_ID = \"aqueduct30\"\n",
    "BQ_OUTPUT_DATASET_NAME = \"aqueduct30v01\"\n",
    "BQ_INPUT_TABLE_NAME = \"y2018m07d30_rh_gcs_to_bq_v01_v02\"\n",
    "BQ_OUTPUT_TABLE_NAME = \"{}_v{:02.0f}\".format(SCRIPT_NAME,OUTPUT_VERSION).lower()\n",
    "\n",
    "print(\"bq dataset name: \", BQ_OUTPUT_DATASET_NAME,\n",
    "      \"\\nBQ_INPUT_TABLE_NAME: \", BQ_INPUT_TABLE_NAME,\n",
    "      \"\\nOutput bq table name: \", BQ_OUTPUT_TABLE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y2018M08D02 UTC 09:34\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.5.4 |Anaconda, Inc.| (default, Nov 20 2017, 18:44:38) \\n[GCC 7.2.0]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time, datetime, sys\n",
    "dateString = time.strftime(\"Y%YM%mD%d\")\n",
    "timeString = time.strftime(\"UTC %H:%M\")\n",
    "start = datetime.datetime.now()\n",
    "print(dateString,timeString)\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/.google.json\"\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = \"aqueduct30\"\n",
    "from google.cloud import bigquery\n",
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pre_process_table(bq_output_dataset_name,bq_output_table_name,overwrite=False):\n",
    "    \"\"\" Checks if a bq table exists and deletes if necessary.\n",
    "    \n",
    "    Args:\n",
    "        bq_output_dataset_name (string): BQ Dataset name.\n",
    "        bq_output_table_name (string): BQ table name.\n",
    "    Returns:\n",
    "        1\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    dataset_ref = client.dataset(bq_output_dataset_name)\n",
    "    tables_server = list(client.list_tables(dataset_ref))\n",
    "    tables_client = list(map(lambda x: x.table_id,tables_server))\n",
    "    table_exists = bq_output_table_name in tables_client\n",
    "    if table_exists:\n",
    "        print(\"Table {}{} exists\".format(bq_output_dataset_name,bq_output_table_name))\n",
    "        if overwrite:\n",
    "            table_ref = dataset_ref.table(bq_output_table_name)\n",
    "            client.delete_table(table_ref)\n",
    "            print(\"Overwrite True, deleting table {}{}\".format(bq_output_dataset_name,bq_output_table_name))\n",
    "        else:\n",
    "            print(\"Overwrite False, keeping table {}{}\".format(bq_output_dataset_name,bq_output_table_name))\n",
    "    else:\n",
    "        print(\"Table {}.{} does not exist\".format(bq_output_dataset_name,bq_output_table_name))\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table aqueduct30v01.y2018m07d31_rh_intra_annual_variability_average_std_v01_v01 does not exist\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_process_table(BQ_OUTPUT_DATASET_NAME,BQ_OUTPUT_TABLE_NAME,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql =  \"WITH cte AS (\"\n",
    "sql +=\" SELECT\"\n",
    "sql +=  \" pfafid_30spfaf06,\"\n",
    "sql +=  \" month,\"\n",
    "sql +=  \" AVG(riverdischarge_m_30spfaf06) AS avg_riverdischarge_m_30spfaf06\"\n",
    "sql +=\" FROM\"\n",
    "sql +=  \" `aqueduct30.{}.{}`\".format(BQ_OUTPUT_DATASET_NAME,BQ_INPUT_TABLE_NAME) \n",
    "sql +=\" WHERE\"\n",
    "sql +=    \" temporal_resolution = 'month'\"\n",
    "sql +=\" GROUP BY \"\n",
    "sql +=  \" pfafid_30spfaf06,\"\n",
    "sql +=  \" month\"   \n",
    "sql +=\" )\"\n",
    "sql +=\" SELECT pfafid_30spfaf06,\"\n",
    "sql +=  \" AVG(avg_riverdischarge_m_30spfaf06) AS avg_riverdischarge_m_30spfaf06,\"\n",
    "sql +=  \" STDDEV(avg_riverdischarge_m_30spfaf06) AS stddev_riverdischarge_m_30spfaf06\"\n",
    "sql +=\" FROM cte\"\n",
    "sql +=\" GROUP BY \"\n",
    "sql +=  \" pfafid_30spfaf06\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#sql +=  \" stddev_riverdischarge_m_30spfaf06 / nullif(stddev_riverdischarge_m_30spfaf06,0) AS cv_riverdischarge_m_30spfaf06\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"WITH cte AS ( SELECT pfafid_30spfaf06, month, AVG(riverdischarge_m_30spfaf06) AS avg_riverdischarge_m_30spfaf06 FROM `aqueduct30.aqueduct30v01.y2018m07d30_rh_gcs_to_bq_v01_v02` WHERE temporal_resolution = 'month' GROUP BY  pfafid_30spfaf06, month ) SELECT pfafid_30spfaf06, AVG(avg_riverdischarge_m_30spfaf06) AS avg_riverdischarge_m_30spfaf06, STDDEV(avg_riverdischarge_m_30spfaf06) AS stddev_riverdischarge_m_30spfaf06 FROM cte GROUP BY  pfafid_30spfaf06\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "job_config = bigquery.QueryJobConfig()\n",
    "table_ref = client.dataset(BQ_OUTPUT_DATASET_NAME).table(BQ_OUTPUT_TABLE_NAME)\n",
    "job_config.destination = table_ref\n",
    "\n",
    "if TESTING:\n",
    "    job_config.dry_run = True\n",
    "    job_config.use_query_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query_job = client.query(query=sql,\n",
    "                         location=\"US\",\n",
    "                         job_config=job_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table.RowIterator at 0x7f18a3b0ee80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_job.result(timeout=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:03.794641\n"
     ]
    }
   ],
   "source": [
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous runs:  \n",
    "0:00:09.085433\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 35",
   "language": "python",
   "name": "python35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
