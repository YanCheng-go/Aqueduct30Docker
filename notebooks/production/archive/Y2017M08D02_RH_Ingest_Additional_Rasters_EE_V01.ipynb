{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest Additional Rasters on Earth Engine\n",
    "\n",
    "* Purpose of script: This notebook will ingest some of the missing rasters to Earth Engine like streamflow direction, DEM etc. \n",
    "* Author: Rutger Hofste\n",
    "* Kernel used: python27\n",
    "* Date created: 20170802"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "1. gcloud authorization (`gcloud init`)\n",
    "1. earthengine authorization (`earthengine authorize`)\n",
    "1. aws authorization (`aws configure`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "S3_INPUT_PATH_SAMPLE = \"s3://wri-projects/Aqueduct30/rawData/WRI/samplegeotiff\"\n",
    "S3_INPUT_PATH = \"s3://wri-projects/Aqueduct30/rawData/Utrecht/additionalFiles/flowNetwork/topo_pcrglobwb_05min\"\n",
    "INPUTLOCATION_SAMPLE_GEOTIFF = \"/volumes/data/PCRGlobWB20V01/additional/sampleGeotiff.tiff\"\n",
    "EC2_INPUT_PATH = \"/volumes/data/Y2017M08D02_RH_Ingest_Additional_Rasters_EE_V01/input\"\n",
    "EC2_OUTPUT_PATH = \"/volumes/data/Y2017M08D02_RH_Ingest_Additional_Rasters_EE_V01/output\"\n",
    "GCS_PATH = \"gs://aqueduct30_v01/Y2017M08D02_RH_Ingest_Additional_Rasters_EE_V01/output/\"\n",
    "EE_BASE = \"projects/WRI-Aquaduct/PCRGlobWB20V07/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir -p {EC2_INPUT_PATH}\n",
    "!mkdir -p {EC2_OUTPUT_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://wri-projects/Aqueduct30/rawData/WRI/samplegeotiff/readme.txt to ../../../../data/Y2017M08D02_RH_Ingest_Additional_Rasters_EE_V01/input/readme.txt\n",
      "download: s3://wri-projects/Aqueduct30/rawData/WRI/samplegeotiff/sampleGeotiff.tiff to ../../../../data/Y2017M08D02_RH_Ingest_Additional_Rasters_EE_V01/input/sampleGeotiff.tiff\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp {S3_INPUT_PATH_SAMPLE} {EC2_INPUT_PATH} --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the file is actually copied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create working environment and copy relevant files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from osgeo import ogr, osr, gdal\n",
    "except:\n",
    "    sys.exit('ERROR: cannot find GDAL/OGR modules')\n",
    "    \n",
    "from netCDF4 import Dataset\n",
    "import os\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import datetime\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readFile(filename):\n",
    "    filehandle = gdal.Open(filename)\n",
    "    band1 = filehandle.GetRasterBand(1)\n",
    "    geotransform = filehandle.GetGeoTransform()\n",
    "    geoproj = filehandle.GetProjection()\n",
    "    Z = band1.ReadAsArray()\n",
    "    xsize = filehandle.RasterXSize\n",
    "    ysize = filehandle.RasterYSize\n",
    "    filehandle = None\n",
    "    return xsize,ysize,geotransform,geoproj,Z\n",
    "\n",
    "def writeFile(filename,geotransform,geoprojection,data):\n",
    "    (x,y) = data.shape\n",
    "    format = \"GTiff\"\n",
    "    driver = gdal.GetDriverByName(format)\n",
    "    # you can change the dataformat but be sure to be able to store negative values including -9999\n",
    "    dst_datatype = gdal.GDT_Float32\n",
    "    dst_ds = driver.Create(filename,y,x,1,dst_datatype, [ 'COMPRESS=LZW' ])\n",
    "    dst_ds.GetRasterBand(1).SetNoDataValue(-9999)\n",
    "    dst_ds.GetRasterBand(1).WriteArray(data)\n",
    "    dst_ds.SetGeoTransform(geotransform)\n",
    "    dst_ds.SetProjection(geoprojection)\n",
    "    dst_ds = None\n",
    "    return 1\n",
    "\n",
    "def splitKey(key):\n",
    "    prefix, extension = key.split(\".\")\n",
    "    fileName = prefix.split(\"/\")[-1]\n",
    "    values = re.split(\"_|-\", fileName)\n",
    "    keyz = [\"indicator\",\"spatial_resolution\",\"units\"]\n",
    "    outDict = dict(zip(keyz, values))\n",
    "    outDict[\"fileName\"]=fileName\n",
    "    outDict[\"extension\"]=extension\n",
    "    return outDict\n",
    "\n",
    "def uploadEE(index,row):\n",
    "    target = EE_BASE + row.fileName\n",
    "    source = GCS_PATH + row.fileName + \".\" + row.extension\n",
    "    metadata = \"--nodata_value=%s -p extension=%s -p filename=%s -p indicator=%s -p spatial_resolution=%s -p units=%s -p ingested_by=%s -p exportdescription=%s\" %(row.nodata,row.extension,row.fileName,row.indicator,row.spatial_resolution, row.units, row.ingested_by, row.exportdescription)\n",
    "    command = \"/opt/anaconda3/bin/earthengine upload image --asset_id %s %s %s\" % (target, source,metadata)\n",
    "    try:\n",
    "        response = subprocess.check_output(command, shell=True)\n",
    "        outDict = {\"command\":command,\"response\":response,\"error\":0}\n",
    "        df_errors2 = pd.DataFrame(outDict,index=[index])\n",
    "        pass\n",
    "    except:\n",
    "        try:\n",
    "            outDict = {\"command\":command,\"response\":response,\"error\":1}\n",
    "        except:\n",
    "            outDict = {\"command\":command,\"response\":-9999,\"error\":2}\n",
    "        df_errors2 = pd.DataFrame(outDict,index=[index])\n",
    "        print(\"error\")\n",
    "    return df_errors2\n",
    "\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extension                                                           tif\n",
    "fileName              global_droughtseveritystandardisedsoilmoisture...\n",
    "geographic_range                                                 global\n",
    "indicator                       droughtseveritystandardisedsoilmoisture\n",
    "spatial_resolution                                                 5min\n",
    "temporal_range_max                                                 2014\n",
    "temporal_range_min                                                 1960\n",
    "nodata                                                            -9999\n",
    "ingested_by                                                RutgerHofste\n",
    "exportdescription               droughtseveritystandardisedsoilmoisture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[xsizeSample,ysizeSample,geotransformSample,geoprojSample,ZSample] = readFile(os.path.join(EC2_INPUT_PATH,\"sampleGeotiff.tiff\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## PCRGlobWB auxiliary datasets\n",
    "\n",
    "after receiving the results from Yoshi, there was a fair amount of information missing such as flow direction, basins etc. Rens van Beek has been very supportive and provided WRI with some auxiliary datasets. This script will put them in the right format, upload to GCS and ingest them to Earth Engine.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!aws s3 cp \\\n",
    "{S3_INPUT_PATH} \\\n",
    "{EC2_INPUT_PATH} \\\n",
    "--recursive \\\n",
    "--quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy to EC2 instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "renaming the files with a structured name indicator_5min_unit.map\n",
    "\n",
    "copy from readme.txt file on S3\n",
    "\n",
    "\n",
    "Data received from Rens van Beek on Feb 24 2017. Rutger Hofste\n",
    "topo_pcrglobwb_05min.zip  \n",
    "\n",
    "|Archive Length |   Date |   Time |    Name | Units | newName | \n",
    "|---:|---:|---:|---:| ---:| ---:|\n",
    "|37325056|  02-24-2017| 15:46 |  accumulated_drainage_area_05min_sqkm.map| $$km^2$$ |accumulateddrainagearea_05min_km2.map |\n",
    "|37325056|  02-24-2017 |15:45 |  cellsize05min.correct.map| $$m^2$$ |cellsize_05min_m2.map |\n",
    "|37325056| 02-24-2017| 15:44 |  gtopo05min.map| $$m$$ |gtopo_05min_km2.map|\n",
    "|9331456|  02-24-2017| 15:45 |   lddsound_05min.map| numpad |lddsound_05min_numpad.map |\n",
    "|121306624| | |               4 files| | |\n",
    "\n",
    "All files are 5 arc minute maps in PCRaster format and WGS84 projection (implicit).\n",
    "The gtopo05min.map is the DEM from the gtopo30 dataset that we use for downscaling meteo data occasionally. This is consistent with the CRU climate data sets and the hydro1k drainage dataset. Elevation is in **metres**. The cellsize05.correct.map is the surface area of a geographic cell in **m2** per 5 arc minute cell. The lddsound_05min.map is identical to the LDD we sent you earlier with the **8-point pour algorithm**.(numpad e.g. 7 is NW 6 is E etc.) The accumulated_drainage_area_05min_sqkm.map is the accumulated drainage area in **km2** per cell along the LDD.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mv {EC2_INPUT_PATH}/accumulated_drainage_area_05min_sqkm.map \\\n",
    "{EC2_INPUT_PATH}/accumulateddrainagearea_05min_km2.map\n",
    "!mv {EC2_INPUT_PATH}/cellsize05min.correct.map \\\n",
    "{EC2_INPUT_PATH}/cellsize_05min_m2.map\n",
    "!mv {EC2_INPUT_PATH}/gtopo05min.map \\\n",
    "{EC2_INPUT_PATH}/gtopo_05min_m.map\n",
    "!mv {EC2_INPUT_PATH}/lddsound_05min.map \\\n",
    "{EC2_INPUT_PATH}/lddsound_05min_numpad.map\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = os.listdir(EC2_INPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cellsize_05min_m2.map', 'sampleGeotiff.tiff', 'readme.txt', 'lddsound_05min_numpad.map', 'accumulateddrainagearea_05min_km2.map', 'geotiff', 'gtopo_05min_m.map']\n"
     ]
    }
   ],
   "source": [
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cellsize_05min_m2.map\n",
      "lddsound_05min_numpad.map\n",
      "accumulateddrainagearea_05min_km2.map\n",
      "gtopo_05min_m.map\n"
     ]
    }
   ],
   "source": [
    "newExtension =\".tif\"\n",
    "for oneFile in files:\n",
    "    if oneFile.endswith(\".map\"):\n",
    "        print(oneFile)\n",
    "        base , extension = oneFile.split(\".\")\n",
    "        xsize,ysize,geotransform,geoproj,Z = readFile(os.path.join(EC2_INPUT_PATH,oneFile))\n",
    "        Z[Z<-9990]= -9999\n",
    "        Z[Z>1e19] = -9999\n",
    "        outputFileName = base + newExtension\n",
    "        writeFile(os.path.join(EC2_OUTPUT_PATH,outputFileName),geotransformSample,geoprojSample,Z)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload Auxiliary files to GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file:///volumes/data/Y2017M08D02_RH_Ingest_Additional_Rasters_EE_V01/output/accumulateddrainagearea_05min_km2.tif [Content-Type=image/tiff]...\n",
      "Copying file:///volumes/data/Y2017M08D02_RH_Ingest_Additional_Rasters_EE_V01/output/gtopo_05min_km2.tif [Content-Type=image/tiff]...\n",
      "Copying file:///volumes/data/Y2017M08D02_RH_Ingest_Additional_Rasters_EE_V01/output/cellsize_05min_m2.tif [Content-Type=image/tiff]...\n",
      "Copying file:///volumes/data/Y2017M08D02_RH_Ingest_Additional_Rasters_EE_V01/output/gtopo_05min_m.tif [Content-Type=image/tiff]...\n",
      "Copying file:///volumes/data/Y2017M08D02_RH_Ingest_Additional_Rasters_EE_V01/output/lddsound_05min_numpad.tif [Content-Type=image/tiff]...\n",
      "\\ [5/5 files][ 24.4 MiB/ 24.4 MiB] 100% Done                                    \n",
      "Operation completed over 5 objects/24.4 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp \\\n",
    "{EC2_OUTPUT_PATH}/*.tif \\\n",
    "{GCS_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ingest GCS data in earthengine. Some metadata is missing, therefore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "command = (\"/opt/google-cloud-sdk/bin/gsutil ls %s\") %(GCS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys = subprocess.check_output(command,shell=True)\n",
    "keys = keys.decode('UTF-8').splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'gs://aqueduct30_v01/Y2017M08D02_RH_Ingest_Additional_Rasters_EE_V01/output/accumulateddrainagearea_05min_km2.tif', u'gs://aqueduct30_v01/Y2017M08D02_RH_Ingest_Additional_Rasters_EE_V01/output/cellsize_05min_m2.tif', u'gs://aqueduct30_v01/Y2017M08D02_RH_Ingest_Additional_Rasters_EE_V01/output/gtopo_05min_km2.tif', u'gs://aqueduct30_v01/Y2017M08D02_RH_Ingest_Additional_Rasters_EE_V01/output/gtopo_05min_m.tif', u'gs://aqueduct30_v01/Y2017M08D02_RH_Ingest_Additional_Rasters_EE_V01/output/lddsound_05min_numpad.tif']\n"
     ]
    }
   ],
   "source": [
    "print(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload Rasterized HydroBasin files to GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "i = 0\n",
    "for key in keys:\n",
    "    i = i+1\n",
    "    outDict = splitKey(key)\n",
    "    df2 = pd.DataFrame(outDict,index=[i])\n",
    "    df = df.append(df2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"nodata\"] = -9999\n",
    "df[\"ingested_by\"] =\"RutgerHofste\"\n",
    "df[\"exportdescription\"] = df[\"indicator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, '20.00', 'elapsed: ', '0:00:00.001246')\n",
      "(2, '40.00', 'elapsed: ', '0:00:01.262325')\n",
      "(3, '60.00', 'elapsed: ', '0:00:02.437589')\n",
      "(4, '80.00', 'elapsed: ', '0:00:03.646388')\n",
      "(5, '100.00', 'elapsed: ', '0:00:04.827735')\n"
     ]
    }
   ],
   "source": [
    "df_errors = pd.DataFrame()\n",
    "start_time = time.time()\n",
    "rows = df.shape[0]*1.0\n",
    "for index, row in df.iterrows():\n",
    "    elapsed_time = time.time() - start_time \n",
    "    print(index,\"%.2f\" %((index/rows)*100), \"elapsed: \", str(timedelta(seconds=elapsed_time)))\n",
    "    df_errors2 = uploadEE(index,row)\n",
    "    df_errors = df_errors.append(df_errors2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 27",
   "language": "python",
   "name": "python27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
