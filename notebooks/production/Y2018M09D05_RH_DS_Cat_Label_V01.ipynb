{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCS_INPUT_PATH:  gs://aqueduct30_v01/Y2018M09D05_RH_DS_Zonal_Stats_V01/output_V04/ \n",
      "ec2_input_path:  /volumes/data/Y2018M09D05_RH_DS_Cat_Label_V01/output_V01 \n",
      "BQ_OUTPUT_DATASET_NAME:  aqueduct30v01 \n",
      "BQ_OUTPUT_TABLE_NAME:  y2018m09d05_rh_ds_cat_label_v01_v01\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Add category and Label for drought severity.\n",
    "-------------------------------------------------------------------------------\n",
    "\n",
    "Drought Severity Soil Moisture \n",
    "\n",
    "\n",
    "0- 0.1 Low\n",
    "0.1 - 0.25 Low - Medium\n",
    "0.25 - 0.5 Medium - High\n",
    "0.5 - 0.75 High\n",
    "0.75 - 0 Extremely High\n",
    "\n",
    "\n",
    "Using Linear Interpolation\n",
    "\n",
    "if x < 0.1\n",
    "    y = max(0,10x)\n",
    "elif 0.1<x<0.25\n",
    "    y = (20/3)*x + (1/3)\n",
    "else\n",
    "    y = min(5,4*x+1)\n",
    "\n",
    "Author: Rutger Hofste\n",
    "Date: 20180905\n",
    "Kernel: python35\n",
    "Docker: rutgerhofste/gisdocker:ubuntu16.04\n",
    "\n",
    "Args:\n",
    "\n",
    "    SCRIPT_NAME (string) : Script name\n",
    "    INPUT_VERSION (integer) : input version, see readme and output number\n",
    "                              of previous script.\n",
    "    OUTPUT_VERSION (integer) : output version for ec2 and s3.\n",
    "    \n",
    "    \n",
    "Returns:\n",
    "\n",
    "Result:\n",
    "    Table on Google Bigquery.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "SCRIPT_NAME = \"Y2018M09D05_RH_DS_Cat_Label_V01\"\n",
    "OUTPUT_VERSION = 1\n",
    "\n",
    "GCS_INPUT_PATH = \"gs://aqueduct30_v01/Y2018M09D05_RH_DS_Zonal_Stats_V01/output_V04/\"\n",
    "\n",
    "\n",
    "BQ_PROJECT_ID = \"aqueduct30\"\n",
    "BQ_OUTPUT_DATASET_NAME = \"aqueduct30v01\"\n",
    "BQ_OUTPUT_TABLE_NAME = \"{}_v{:02.0f}\".format(SCRIPT_NAME,OUTPUT_VERSION).lower()\n",
    "\n",
    "ec2_input_path = \"/volumes/data/{}/output_V{:02.0f}\".format(SCRIPT_NAME,OUTPUT_VERSION) \n",
    "\n",
    "\n",
    "print(\"GCS_INPUT_PATH: \",GCS_INPUT_PATH,\n",
    "      \"\\nec2_input_path: \",ec2_input_path,\n",
    "      \"\\nBQ_OUTPUT_DATASET_NAME: \", BQ_OUTPUT_DATASET_NAME,\n",
    "      \"\\nBQ_OUTPUT_TABLE_NAME: \",BQ_OUTPUT_TABLE_NAME\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y2018M09D07 UTC 15:35\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.5.4 |Anaconda, Inc.| (default, Nov 20 2017, 18:44:38) \\n[GCC 7.2.0]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time, datetime, sys\n",
    "dateString = time.strftime(\"Y%YM%mD%d\")\n",
    "timeString = time.strftime(\"UTC %H:%M\")\n",
    "start = datetime.datetime.now()\n",
    "print(dateString,timeString)\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -r {ec2_input_path}\n",
    "!mkdir -p {ec2_input_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://aqueduct30_v01/Y2018M09D05_RH_DS_Zonal_Stats_V01/output_V04/droughtseveritysoilmoistureee_export.csv...\n",
      "Copying gs://aqueduct30_v01/Y2018M09D05_RH_DS_Zonal_Stats_V01/output_V04/droughtseveritystreamflowee_export.csv...\n",
      "/ [2/2 files][  1.0 MiB/  1.0 MiB] 100% Done                                    \n",
      "Operation completed over 2 objects/1.0 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp {GCS_INPUT_PATH}* {ec2_input_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.cloud import bigquery\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/.google.json\"\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = \"aqueduct30\"\n",
    "client = bigquery.Client(project=BQ_PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def raw_value_to_score_droughtseverity(x):\n",
    "    \"\"\" Linear interpolation\n",
    "    \n",
    "    thresholds set by Yoshi\n",
    "    \n",
    "    Using Linear Interpolation\n",
    "\n",
    "    if x < 0.1\n",
    "        y = max(0,10x)\n",
    "    elif 0.1<x<0.25\n",
    "        y = (20/3)*x + (1/3)\n",
    "    else\n",
    "        y = min(5,4*x+1)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    if x == -9999:\n",
    "        y = -9999\n",
    "    elif x<0.1:\n",
    "        y = max(10*x,0)\n",
    "    elif (x >= 0.1) and ( x < 0.25):\n",
    "        y = (20/3)*x + 1/3\n",
    "    elif (x >= 0.25):\n",
    "        y = min(4*x + 1,5)\n",
    "    return y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def score_to_category(score):\n",
    "    if score != 5:\n",
    "        cat = int(np.floor(score))\n",
    "    else:\n",
    "        cat = 4\n",
    "    return cat\n",
    "\n",
    "\n",
    "def category_to_label(cat):\n",
    "    if cat == -9999:\n",
    "        label = \"NoData\"\n",
    "    elif cat == 0:\n",
    "        label = \"Low\"\n",
    "    elif cat == 1:\n",
    "        label = \"Low - Medium\"\n",
    "    elif cat == 2:\n",
    "        label = \"Medium - High\"\n",
    "    elif cat == 3:\n",
    "        label = \"High\"\n",
    "    elif cat == 4: \n",
    "        label = \"Extremely High\"\n",
    "    else:\n",
    "        label = \"Error\"\n",
    "    return label\n",
    "\n",
    "def process_droughtseveritysoilmoisture(df):\n",
    "    df[\"droughtseveritysoilmoisture_score\"] = df[\"droughtseveritysoilmoisture_dimensionless\"].apply(raw_value_to_score_droughtseverity)\n",
    "    df[\"droughtseveritysoilmoisture_cat\"] = df[\"droughtseveritysoilmoisture_score\"].apply(score_to_category)\n",
    "    df[\"droughtseveritysoilmoisture_label\"] = df[\"droughtseveritysoilmoisture_cat\"].apply(category_to_label)\n",
    "    return df\n",
    "    \n",
    "def process_droughtseveritystreamflow(df):\n",
    "    df[\"droughtseveritystreamflow_score\"] = df[\"droughtseveritystreamflow_dimensionless\"].apply(raw_value_to_score_droughtseverity)\n",
    "    df[\"droughtseveritystreamflow_cat\"] = df[\"droughtseveritystreamflow_score\"].apply(score_to_category)\n",
    "    df[\"droughtseveritystreamflow_label\"] = df[\"droughtseveritystreamflow_cat\"].apply(category_to_label)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = os.listdir(ec2_input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['droughtseveritystreamflowee_export.csv',\n",
       " 'droughtseveritysoilmoistureee_export.csv']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def  group_basins(pfaf_id):\n",
    "    \"\"\" Returns pfaf_id unless part of the complex -180 degree meridian crossing\n",
    "    polygons.    \n",
    "    \n",
    "    \"\"\"\n",
    "    group_subbasins = [353011,353012,353013]    \n",
    "    if pfaf_id in group_subbasins:\n",
    "        pfaf_id_grouping = 353011\n",
    "    else:\n",
    "        pfaf_id_grouping = pfaf_id\n",
    "    return pfaf_id_grouping\n",
    "\n",
    "def process_duplicate_pfafid(df,value_column_name,weight_column_name,group_by_attribute):\n",
    "    \"\"\" Handles statistics for the basins crossing the -180 meridian. \n",
    "    \n",
    "    handles the first case: duplicate pfaf_ids.\n",
    "    \n",
    "    pfaf_id's of features:\n",
    "    \n",
    "    \n",
    "    1 -----------------\n",
    "    Western Hemisphere:\n",
    "        PFAF_ID = 353020,\n",
    "        SUB_AREA = 5236.9 \n",
    "    \n",
    "    Eastern Hemisphere:    \n",
    "        PFAF_ID = 353020 \n",
    "        SUB_AREA = 2498.7\n",
    "    \n",
    "    solution: weighted aggregation and remove duplicate pfaf_id's\n",
    "    \n",
    "    \n",
    "    2---------------\n",
    "\n",
    "    Eastern Hemisphere\n",
    "        \n",
    "        PFAF_ID 353012\n",
    "        SUB_AREA = 111764.6\n",
    "    \n",
    "    Western Hemisphere\n",
    "        PFAF_ID = 353011     \n",
    "        SUB_AREA = 28931.1\n",
    "\n",
    "        PFAF_ID = 353013 \n",
    "        SUB_AREA = 7363.9\n",
    "      \n",
    "    \n",
    "    solution: weighted aggregation and store result in each row. \n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame) : Dataframe with weigths and values.\n",
    "        value_column_name (string): Name of column with values.\n",
    "        weight_column_name (string): Name of column with weights.\n",
    "        group_by_attribute (string): Group by attribute. \n",
    "    Returns\n",
    "        df_out (DataFrame) : dataframe with weighted values.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    df_temp = df.copy()\n",
    "    df_temp[\"weighted_values\"] = df[weight_column_name] * df[value_column_name]\n",
    "    df_temp_sums = df_temp.groupby(by=group_by_attribute,as_index=False).sum()\n",
    "    df_temp_sums[value_column_name] = df_temp_sums[\"weighted_values\"] / df_temp_sums[weight_column_name]\n",
    "    df_temp_sums = df_temp_sums[[group_by_attribute,value_column_name]]\n",
    "    return df_temp_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "droughtseveritystreamflowee_export.csv\n",
      "droughtseveritysoilmoistureee_export.csv\n"
     ]
    }
   ],
   "source": [
    "d_out = {}\n",
    "for one_file in files:\n",
    "    print(one_file)\n",
    "    input_file_path = \"{}/{}\".format(ec2_input_path,one_file)\n",
    "    df = pd.read_csv(input_file_path)\n",
    "    df = df.fillna(-9999)\n",
    "    df[\"PFAF_ID_GROUPING\"] = df[\"PFAF_ID\"].apply(group_basins)\n",
    "    \n",
    "    if one_file ==\"droughtseveritysoilmoistureee_export.csv\":       \n",
    "        df_weighted = process_duplicate_pfafid(df,\"droughtseveritysoilmoisture_dimensionless\",\"SUB_AREA\",\"PFAF_ID_GROUPING\")\n",
    "        df = df.drop(\"droughtseveritysoilmoisture_dimensionless\",axis=1)\n",
    "        df_merge = df.merge(right=df_weighted,how=\"left\",on=\"PFAF_ID_GROUPING\")\n",
    "        df_merge = df_merge.drop(\"PFAF_ID_GROUPING\",axis=1)\n",
    "        df_merge = df_merge.drop(\"SUB_AREA\",axis=1)\n",
    "        df_merge = df_merge.groupby(by=\"PFAF_ID\",as_index=False).first()\n",
    "        d_out[one_file] = process_droughtseveritysoilmoisture(df_merge)\n",
    "        \n",
    "    elif one_file ==\"droughtseveritystreamflowee_export.csv\":\n",
    "        df_weighted = process_duplicate_pfafid(df,\"droughtseveritystreamflow_dimensionless\",\"SUB_AREA\",\"PFAF_ID_GROUPING\")\n",
    "        df = df.drop(\"droughtseveritystreamflow_dimensionless\",axis=1)\n",
    "        df_merge = df.merge(right=df_weighted,how=\"left\",on=\"PFAF_ID_GROUPING\")\n",
    "        df_merge = df_merge.drop(\"PFAF_ID_GROUPING\",axis=1)\n",
    "        df_merge = df_merge.drop(\"SUB_AREA\",axis=1)\n",
    "        df_merge = df_merge.groupby(by=\"PFAF_ID\",as_index=False).first()\n",
    "        d_out[one_file] = process_droughtseveritystreamflow(df_merge)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_merged = d_out[\"droughtseveritysoilmoistureee_export.csv\"].merge(right=d_out[\"droughtseveritystreamflowee_export.csv\"],\n",
    "                                                                    how=\"left\",\n",
    "                                                                    on=\"PFAF_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PFAF_ID</th>\n",
       "      <th>droughtseveritysoilmoisture_dimensionless</th>\n",
       "      <th>droughtseveritysoilmoisture_score</th>\n",
       "      <th>droughtseveritysoilmoisture_cat</th>\n",
       "      <th>droughtseveritysoilmoisture_label</th>\n",
       "      <th>droughtseveritystreamflow_dimensionless</th>\n",
       "      <th>droughtseveritystreamflow_score</th>\n",
       "      <th>droughtseveritystreamflow_cat</th>\n",
       "      <th>droughtseveritystreamflow_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111011</td>\n",
       "      <td>0.530724</td>\n",
       "      <td>3.122896</td>\n",
       "      <td>3</td>\n",
       "      <td>High</td>\n",
       "      <td>0.952224</td>\n",
       "      <td>4.808896</td>\n",
       "      <td>4</td>\n",
       "      <td>Extremely High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111012</td>\n",
       "      <td>0.206655</td>\n",
       "      <td>1.711035</td>\n",
       "      <td>1</td>\n",
       "      <td>Low - Medium</td>\n",
       "      <td>0.222732</td>\n",
       "      <td>1.818216</td>\n",
       "      <td>1</td>\n",
       "      <td>Low - Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111013</td>\n",
       "      <td>0.211859</td>\n",
       "      <td>1.745730</td>\n",
       "      <td>1</td>\n",
       "      <td>Low - Medium</td>\n",
       "      <td>1.228510</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>Extremely High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111014</td>\n",
       "      <td>0.208129</td>\n",
       "      <td>1.720861</td>\n",
       "      <td>1</td>\n",
       "      <td>Low - Medium</td>\n",
       "      <td>11.148084</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>Extremely High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111015</td>\n",
       "      <td>0.177538</td>\n",
       "      <td>1.516918</td>\n",
       "      <td>1</td>\n",
       "      <td>Low - Medium</td>\n",
       "      <td>7.308789</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>Extremely High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PFAF_ID  droughtseveritysoilmoisture_dimensionless  \\\n",
       "0   111011                                   0.530724   \n",
       "1   111012                                   0.206655   \n",
       "2   111013                                   0.211859   \n",
       "3   111014                                   0.208129   \n",
       "4   111015                                   0.177538   \n",
       "\n",
       "   droughtseveritysoilmoisture_score  droughtseveritysoilmoisture_cat  \\\n",
       "0                           3.122896                                3   \n",
       "1                           1.711035                                1   \n",
       "2                           1.745730                                1   \n",
       "3                           1.720861                                1   \n",
       "4                           1.516918                                1   \n",
       "\n",
       "  droughtseveritysoilmoisture_label  droughtseveritystreamflow_dimensionless  \\\n",
       "0                              High                                 0.952224   \n",
       "1                      Low - Medium                                 0.222732   \n",
       "2                      Low - Medium                                 1.228510   \n",
       "3                      Low - Medium                                11.148084   \n",
       "4                      Low - Medium                                 7.308789   \n",
       "\n",
       "   droughtseveritystreamflow_score  droughtseveritystreamflow_cat  \\\n",
       "0                         4.808896                              4   \n",
       "1                         1.818216                              1   \n",
       "2                         5.000000                              4   \n",
       "3                         5.000000                              4   \n",
       "4                         5.000000                              4   \n",
       "\n",
       "  droughtseveritystreamflow_label  \n",
       "0                  Extremely High  \n",
       "1                    Low - Medium  \n",
       "2                  Extremely High  \n",
       "3                  Extremely High  \n",
       "4                  Extremely High  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16396, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "destination_table = \"{}.{}\".format(BQ_OUTPUT_DATASET_NAME,BQ_OUTPUT_TABLE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:12,  6.34s/it]\n"
     ]
    }
   ],
   "source": [
    "df_merged.to_gbq(destination_table=destination_table,\n",
    "                 project_id=BQ_PROJECT_ID,\n",
    "                 chunksize=10000,\n",
    "                 if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:26.999023\n"
     ]
    }
   ],
   "source": [
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous runs:  \n",
    "0:00:17.856315  \n",
    "0:00:26.999023"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 35",
   "language": "python",
   "name": "python35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
