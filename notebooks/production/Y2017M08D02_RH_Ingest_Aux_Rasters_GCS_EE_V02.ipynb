{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input gcs: gs://aqueduct30_v01/Y2018M04D18_RH_Convert_Aux_Rasters_Geotiff_V01/output_V04/\n",
      "Output ee: projects/WRI-Aquaduct/PCRGlobWB20_Aux_V02\n",
      "Output S3: s3://wri-projects/Aqueduct30/processData/Y2017M08D02_RH_Ingest_Aux_Rasters_GCS_EE_V02/output_V02\n",
      "Output ec2: /volumes/data/Y2017M08D02_RH_Ingest_Aux_Rasters_GCS_EE_V02/output_V02\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Ingest additional rasters like DEM, LDD etc. \n",
    "-------------------------------------------------------------------------------\n",
    "This notebook will upload the geotiff files of auxiliary rasters \n",
    "from Google Cloud Storage and into the WRI/aqueduct earthengine bucket. \n",
    "\n",
    "Requirements:\n",
    "    Authorize earthengine by running in your terminal: earthengine \n",
    "                                                       authenticate\n",
    "\n",
    "    you need to have access to the WRI-Aquaduct (yep a Google employee made a\n",
    "    typo) bucket to ingest the data. Rutger can grant access to write to this \n",
    "    folder. \n",
    "\n",
    "    Have access to the Google Cloud Storage Bucket\n",
    "    \n",
    "    AWS CLI configured\n",
    "\n",
    "Make sure to set the project to Aqueduct30 by running\n",
    "`gcloud config set project aqueduct30`\n",
    "\n",
    "Code follows the Google for Python Styleguide. Exception are the scripts that \n",
    "use earth engine since this is camelCase instead of underscore.\n",
    "\n",
    "Author: Rutger Hofste\n",
    "Date: 20170802\n",
    "Kernel: python27\n",
    "Docker: rutgerhofste/gisdocker:ubuntu16.04\n",
    "\n",
    "Args:    \n",
    "    TESTING (Boolean) : Toggle Testing Mode.\n",
    "    OVERWRITE (Boolean) : Overwrite old folder !CAUTION!\n",
    "    SCRIPT_NAME (string) : Script name.\n",
    "    PREVIOUS_SCRIPT_NAME (string) : Previous script name.\n",
    "    INPUT_VERSION (integer) : Input version.\n",
    "    OUTPUT_VERSION (integer) : Output version. \n",
    "    OUTPUT_FILE_NAME (string) : File Name for a csv file containing the failed tasks. \n",
    "\n",
    "\n",
    "    GCS_BASE (string) : Google Cloud Storage output namespace.   \n",
    "    EE_BASE (string) : Earth Engine folder to store the assets.\n",
    "    \n",
    "    OUTPUT_FILE_NAME (string) : File Name for a csv file containing the failed tasks. \n",
    "    SEPARATOR (regex) : Regular expression of separators used in geotiff\n",
    "      filenames.     \n",
    "    SCHEMA (list) : A list of strings containing the schema. See \n",
    "      aqueduct3.split_key() for more info.\n",
    "    EXTRA_PROPERTIES (Dictionary) : Extra properties to add to assets. nodata_value,\n",
    "      script used are common properties.\n",
    "    \n",
    "Returns:\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Input Parameters\n",
    "TESTING = 0\n",
    "OVERWRITE = 1 # !CAUTION!\n",
    "SCRIPT_NAME = \"Y2017M08D02_RH_Ingest_Aux_Rasters_GCS_EE_V02\"\n",
    "PREVIOUS_SCRIPT_NAME = \"Y2018M04D18_RH_Convert_Aux_Rasters_Geotiff_V01\"\n",
    "\n",
    "INPUT_VERSION  = 4\n",
    "OUTPUT_VERSION = 2\n",
    "\n",
    "OUTPUT_FILE_NAME = \"df_errors.csv\"\n",
    "\n",
    "SEPARATOR = \"_|-\"\n",
    "\n",
    "SCHEMA = [\"geographic_range\",\n",
    "    \"indicator\",\n",
    "    \"unit\",\n",
    "    \"spatial_resolution\",\n",
    "]\n",
    "\n",
    "EXTRA_PROPERTIES = {\"nodata_value\":-9999,\n",
    "                    \"ingested_by\" : \"RutgerHofste\",\n",
    "                    \"script_used\": SCRIPT_NAME,\n",
    "                    \"output_version\":OUTPUT_VERSION}\n",
    "\n",
    "\n",
    "\n",
    "gcs_input_path = \"gs://aqueduct30_v01/{}/output_V{:02.0f}/\".format(PREVIOUS_SCRIPT_NAME,INPUT_VERSION)\n",
    "ee_output_path = \"projects/WRI-Aquaduct/PCRGlobWB20_Aux_V{:02.0f}\".format(OUTPUT_VERSION)\n",
    "s3_output_path = \"s3://wri-projects/Aqueduct30/processData/{}/output_V{:02.0f}\".format(SCRIPT_NAME,OUTPUT_VERSION)\n",
    "ec2_output_path = \"/volumes/data/{}/output_V{:02.0f}\".format(SCRIPT_NAME,OUTPUT_VERSION)\n",
    "\n",
    "\n",
    "print(\"Input gcs: \" +  gcs_input_path +\n",
    "      \"\\nOutput ee: \" + ee_output_path +\n",
    "      \"\\nOutput S3: \" + s3_output_path +\n",
    "      \"\\nOutput ec2: \" + ec2_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y2018M04D18 UTC 11:46\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.5.4 |Anaconda, Inc.| (default, Nov 20 2017, 18:44:38) \\n[GCC 7.2.0]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time, datetime, sys\n",
    "dateString = time.strftime(\"Y%YM%mD%d\")\n",
    "timeString = time.strftime(\"UTC %H:%M\")\n",
    "start = datetime.datetime.now()\n",
    "print(dateString,timeString)\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import subprocess\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import aqueduct3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "earthengine rm -r projects/WRI-Aquaduct/PCRGlobWB20_Aux_V02\n",
      "earthengine create folder projects/WRI-Aquaduct/PCRGlobWB20_Aux_V02\n",
      "1 25.00elapsed:  0:00:04.816185\n",
      "2 50.00elapsed:  0:00:08.135525\n",
      "3 75.00elapsed:  0:00:11.156627\n",
      "4 100.00elapsed:  0:00:14.129289\n",
      "upload: ../../../../data/Y2017M08D02_RH_Ingest_Aux_Rasters_GCS_EE_V02/output_V02/df_errors.csv to s3://wri-projects/Aqueduct30/processData/Y2017M08D02_RH_Ingest_Aux_Rasters_GCS_EE_V02/output_V02/df_errors.csv\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    start_time = time.time()\n",
    "    !mkdir -p {ec2_output_path}\n",
    "    keys = aqueduct3.get_GCS_keys(gcs_input_path)\n",
    "    df = aqueduct3.keys_to_df(keys,SEPARATOR,SCHEMA)\n",
    "    df = df.assign(**EXTRA_PROPERTIES) #Python >3.5\n",
    "    \n",
    "    # EXTRA FOR AUX FILES ONLY, replace nodata_value for ldd.\n",
    "    df.loc[df['file_name'] == \"global_lddsound_numpad_05min\", \"nodata_value\"] = 255\n",
    "    \n",
    "    df[\"exportdescription\"] = df[\"indicator\"]\n",
    "    df = df.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "    # Earth Engine Preparations\n",
    "    # Create folder\n",
    "    if OVERWRITE:\n",
    "        command = \"earthengine rm -r {}\".format(ee_output_path)\n",
    "        print(command)\n",
    "        subprocess.check_output(command,shell=True)\n",
    "\n",
    "    command = \"earthengine create folder {}\".format(ee_output_path)\n",
    "    print(command)\n",
    "    subprocess.check_output(command,shell=True)\n",
    "\n",
    "\n",
    "    if TESTING:\n",
    "            df = df[1:3] \n",
    "\n",
    "    df_errors = pd.DataFrame()\n",
    "    for index, row in df.iterrows():\n",
    "        elapsed_time = time.time() - start_time \n",
    "        print(index,\"{:02.2f}\".format((float(index)/df.shape[0])*100) + \"elapsed: \", str(timedelta(seconds=elapsed_time)))\n",
    "\n",
    "        geotiff_gcs_path = gcs_input_path + row.file_name + \".\" + row.extension\n",
    "        output_ee_asset_id = ee_output_path + \"/\" + row.file_name\n",
    "        properties = row.to_dict()\n",
    "\n",
    "        df_errors2 = aqueduct3.upload_geotiff_to_EE_imageCollection(geotiff_gcs_path, output_ee_asset_id, properties,index)\n",
    "        df_errors = df_errors.append(df_errors2) \n",
    "\n",
    "    # Storing error dataframe on ec2 and S3\n",
    "    df_errors.to_csv(\"{}/{}\".format(ec2_output_path,OUTPUT_FILE_NAME))\n",
    "    !aws s3 cp  {ec2_output_path} {s3_output_path} --recursive\n",
    "\n",
    "    # Retry Failed Tasks Once\n",
    "    df_retry = df_errors.loc[df_errors['error'] != 0]\n",
    "    for index, row in df_retry.iterrows():\n",
    "        response = subprocess.check_output(row.command, shell=True)\n",
    "\n",
    "    return df,df_errors\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df,df_errors = main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:19.245867\n"
     ]
    }
   ],
   "source": [
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous Runs:  \n",
    "0:00:17.908362  \n",
    "0:00:19.245867"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 35",
   "language": "python",
   "name": "python35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
