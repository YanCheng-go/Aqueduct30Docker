{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input gcs: gs://aqueduct30_v01/Y2018M06D08_RH_QA_Aqueduct21_Demand_Ingest_GCS_EE_V01/output_V01/\n",
      "Output ee: projects/WRI-Aquaduct/Y2018M06D08_RH_QA_Aqueduct21_Demand_Ingest_GCS_EE_V01/output_V02\n"
     ]
    }
   ],
   "source": [
    "\"\"\" QA for water stress in several basin\n",
    "-------------------------------------------------------------------------------\n",
    "\n",
    "This first step was done manually using arcMap since the .gdb is not ogc \n",
    "compliant.\n",
    "\n",
    "Input data: wri-projects/Aqueduct2x/Aqueduct21Data/demand\n",
    "Algorithm used: ArcMap batch copy raster\n",
    "\n",
    "Uploaded to:\n",
    "\n",
    "s3://wri-projects/Aqueduct30/qaData/Y2018M06D08_RH_QA_Aqueduct21_Demand_Ingest_GCS_EE_V01/\n",
    "output_V01/\n",
    "\n",
    "and copied to \n",
    "\n",
    "gs://aqueduct30_v01/Y2018M06D08_RH_QA_Aqueduct21_Demand_Ingest_GCS_EE_V01/\n",
    "output_V01/\n",
    "\n",
    "Author: Rutger Hofste\n",
    "Date: 20180604\n",
    "Kernel: python35\n",
    "Docker: rutgerhofste/gisdocker:ubuntu16.04\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "TESTING = 1\n",
    "OVERWRITE_OUTPUT = 1\n",
    "SCRIPT_NAME = 'Y2018M06D08_RH_QA_Aqueduct21_Demand_Ingest_GCS_EE_V01'\n",
    "OUTPUT_VERSION = 2\n",
    "\n",
    "OUTPUT_FILE_NAME = \"df_errors.csv\"\n",
    "\n",
    "SEPARATOR = \"_|-\"\n",
    "\n",
    "SCHEMA = [\"indicator\"]\n",
    "\n",
    "EXTRA_PROPERTIES = {\"nodata_value\":-1.79769e+308,\n",
    "                    \"ingested_by\" : \"RutgerHofste\",\n",
    "                    \"script_used\": SCRIPT_NAME,\n",
    "                    \"output_version\":OUTPUT_VERSION}\n",
    "\n",
    "\n",
    "\n",
    "GCS_INPUT_PATH = \"gs://aqueduct30_v01/Y2018M06D08_RH_QA_Aqueduct21_Demand_Ingest_GCS_EE_V01/output_V01/\"\n",
    "\n",
    "ee_output_path = \"projects/WRI-Aquaduct/{}/output_V{:02.0f}\".format(SCRIPT_NAME,OUTPUT_VERSION)\n",
    "ec2_output_path = \"/volumes/data/{}/output_V{:02.0f}\".format(SCRIPT_NAME,OUTPUT_VERSION)\n",
    "s3_output_path = \"s3://wri-projects/Aqueduct30/qaData/{}/output_V{:02.0f}\".format(SCRIPT_NAME,OUTPUT_VERSION)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Input gcs: \" +  GCS_INPUT_PATH+\n",
    "      \"\\nOutput ee: \"+ ee_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y2018M06D08 UTC 16:20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.5.4 |Anaconda, Inc.| (default, Nov 20 2017, 18:44:38) \\n[GCC 7.2.0]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time, datetime, sys\n",
    "dateString = time.strftime(\"Y%YM%mD%d\")\n",
    "timeString = time.strftime(\"UTC %H:%M\")\n",
    "start = datetime.datetime.now()\n",
    "print(dateString,timeString)\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import subprocess\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import aqueduct3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if OVERWRITE_OUTPUT:\n",
    "    command = \"earthengine rm -r {}\".format(ee_output_path)\n",
    "    subprocess.check_output(command,shell=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys = aqueduct3.get_GCS_keys(GCS_INPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "earthengine create folder projects/WRI-Aquaduct/Y2018M06D08_RH_QA_Aqueduct21_Demand_Ingest_GCS_EE_V01 b'Asset projects/WRI-Aquaduct/Y2018M06D08_RH_QA_Aqueduct21_Demand_Ingest_GCS_EE_V01 already exists\\n'\n",
      "earthengine create folder projects/WRI-Aquaduct/Y2018M06D08_RH_QA_Aqueduct21_Demand_Ingest_GCS_EE_V01/output_V02 b''\n",
      "upload: ../../../../data/Y2018M06D08_RH_QA_Aqueduct21_Demand_Ingest_GCS_EE_V01/output_V02/df_errors.csv to s3://wri-projects/Aqueduct30/qaData/Y2018M06D08_RH_QA_Aqueduct21_Demand_Ingest_GCS_EE_V01/output_V02/df_errors.csv\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    start_time = time.time()\n",
    "    !mkdir -p {ec2_output_path}\n",
    "    keys = aqueduct3.get_GCS_keys(GCS_INPUT_PATH)\n",
    "    # Limiting to tiffs for now.\n",
    "    keys = list(filter(lambda x: x.endswith('.tif'), keys))\n",
    "    df = aqueduct3.keys_to_df(keys,SEPARATOR,SCHEMA)\n",
    "    df = df.assign(**EXTRA_PROPERTIES)\n",
    "    df[\"exportdescription\"] = df[\"file_name\"]\n",
    "    df = df.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "    # Earth Engine Preparations\n",
    "    # Create folder (create parent if non existent)\n",
    "    \n",
    "    result = aqueduct3.earthengine.create_ee_folder_recursive(ee_output_path,OVERWRITE_OUTPUT)\n",
    "    \n",
    "    df_errors = pd.DataFrame()\n",
    "    for index, row in df.iterrows():\n",
    "        geotiff_gcs_path = GCS_INPUT_PATH + row.file_name + \".\" + row.extension\n",
    "        output_ee_asset_id = ee_output_path + \"/\" + row.file_name\n",
    "        properties = row.to_dict()\n",
    "        df_errors2 = aqueduct3.upload_geotiff_to_EE_imageCollection(geotiff_gcs_path, output_ee_asset_id, properties,index)\n",
    "        df_errors = df_errors.append(df_errors2) \n",
    "    df_errors.to_csv(\"{}/{}\".format(ec2_output_path,OUTPUT_FILE_NAME))\n",
    "    !aws s3 cp  {ec2_output_path} {s3_output_path} --recursive\n",
    "    return df,df_errors\n",
    "                             \n",
    "if __name__ == \"__main__\":\n",
    "    df,df_errors = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:37.967053\n"
     ]
    }
   ],
   "source": [
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous runs:  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 35",
   "language": "python",
   "name": "python35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
