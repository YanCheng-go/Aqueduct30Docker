{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Combine zonal statistics of different indicators and calculate flux. \n",
    "-------------------------------------------------------------------------------\n",
    "zonal_stats_ca_aq21ee_export.csv\n",
    "\n",
    "Author: Rutger Hofste\n",
    "Date: 20180619\n",
    "Kernel: python35\n",
    "Docker: rutgerhofste/gisdocker:ubuntu16.04\n",
    "\n",
    "Args:\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "OVERWRITE = 1\n",
    "TESTING = 0\n",
    "SCRIPT_NAME = \"Y2018M06D19_RH_QA_AQ21_AQ30_Demand_Cleanup_V01\"\n",
    "OUTPUT_VERSION = 1\n",
    "\n",
    "GCS_INPUT_PATH = \"gs://aqueduct30_v01/Y2018M06D18_RH_QA_AQ21_AQ30_Demand_Zonal_Stats_EE_V01/output_V02\"\n",
    "\n",
    "AQ21_SHAPEFILE_S3_INPUT_PATH = \"s3://wri-projects/Aqueduct30/qaData/Y2018M06D05_RH_QA_Aqueduct21_Flux_Shapefile_V01/output_V05\"\n",
    "AQ30_SHAPEFILE_S3_INPUT_PATH = \"s3://wri-projects/Aqueduct30/processData/Y2017M08D02_RH_Merge_HydroBasins_V02/output_V04/\"\n",
    "\n",
    "AQ21_INPUT_FILE_NAME = \"aqueduct21_flux\"\n",
    "AQ30_INPUT_FILE_NAME = \"hybas_lev06_v1c_merged_fiona_V04\"\n",
    "\n",
    "ECKERT_IV_PROJ4_STRING = \"+proj=eck4 +lon_0=0 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs\"\n",
    "\n",
    "\n",
    "ec2_input_path = \"/volumes/data/{}/input_V{:02.0f}\".format(SCRIPT_NAME,OUTPUT_VERSION)\n",
    "ec2_output_path = \"/volumes/data/{}/output_V{:02.0f}\".format(SCRIPT_NAME,OUTPUT_VERSION) \n",
    "s3_output_path = \"s3://wri-projects/Aqueduct30/qaData/{}/output_V{:02.0f}\".format(SCRIPT_NAME,OUTPUT_VERSION)\n",
    "\n",
    "print(\"Input GCS : \" + GCS_INPUT_PATH +\n",
    "      \"\\nInput ec2: \" + ec2_input_path + \n",
    "      \"\\nOutput ec2: \" + ec2_output_path +\n",
    "      \"\\nOutput s3: \" + ec2_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, datetime, sys, logging\n",
    "dateString = time.strftime(\"Y%YM%mD%d\")\n",
    "timeString = time.strftime(\"UTC %H:%M\")\n",
    "start = datetime.datetime.now()\n",
    "print(dateString,timeString)\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if OVERWRITE:\n",
    "    !rm -r {ec2_input_path}\n",
    "    !rm -r {ec2_output_path}\n",
    "    !mkdir -p {ec2_input_path}\n",
    "    !mkdir -p {ec2_output_path}\n",
    "else: \n",
    "    !mkdir -p {ec2_input_path}\n",
    "    !mkdir -p {ec2_output_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aq 21 shapefile\n",
    "!aws s3 cp {AQ21_SHAPEFILE_S3_INPUT_PATH} {ec2_input_path} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aq 30 shapefile\n",
    "!aws s3 cp {AQ30_SHAPEFILE_S3_INPUT_PATH} {ec2_input_path} --recursive --exclude \"*\" --include \"hybas_lev06_v1c_merged_fiona_V04*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zonal Stats\n",
    "\n",
    "!gsutil cp {GCS_INPUT_PATH}/* {ec2_input_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Shapefiles of Aqueduct 2.1 and 3.0\n",
    "\n",
    "aq21_input_file_path = \"{}/{}.shp\".format(ec2_input_path,AQ21_INPUT_FILE_NAME)\n",
    "gdf_aq21 = gpd.read_file(aq21_input_file_path )\n",
    "gdf_aq21 = gdf_aq21.set_index(\"GU\")\n",
    "\n",
    "aq30_input_file_path = \"{}/{}.shp\".format(ec2_input_path,AQ30_INPUT_FILE_NAME)\n",
    "gdf_aq30 = gpd.read_file(aq30_input_file_path )\n",
    "\n",
    "gdf_aq30_eckert4 = gdf_aq30.to_crs(ECKERT_IV_PROJ4_STRING)\n",
    "gdf_aq30[\"area_m2\"] = gdf_aq30_eckert4.geometry.area\n",
    "gdf_aq30 = gdf_aq30.set_index(\"PFAF_ID\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aqueduct_versions = [\"aq21\",\"aq30\"]\n",
    "sectors = [\"a\",\"d\",\"i\",\"t\"]\n",
    "demand_types = [\"c\",\"u\"]\n",
    "\n",
    "for aqueduct_version in aqueduct_versions:  \n",
    "    \n",
    "    if aqueduct_version == \"aq21\":\n",
    "        gdf_left = gdf_aq21.copy()\n",
    "        index_name = \"GU\"\n",
    "    elif aqueduct_version == \"aq30\":\n",
    "        gdf_left = gdf_aq30.copy()\n",
    "        index_name = \"PFAF_ID\"\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "    for demand_type in demand_types:\n",
    "        for sector in sectors:\n",
    "            print(aqueduct_version,demand_type,sector)\n",
    "            input_file_name = \"zonal_stats_{}{}_{}ee_export.csv\".format(demand_type,sector,aqueduct_version)\n",
    "            input_file_path = ec2_input_path + \"/\" + input_file_name\n",
    "            df_in = pd.read_csv(input_file_path)\n",
    "            \n",
    "            df_out = df_in[[\"sum\",\"count\",index_name]].copy()\n",
    "            df_out = df_out.set_index(index_name)\n",
    "            \n",
    "            df_out = df_out.rename(columns={\"sum\":\"sum_{}{}_m3\".format(demand_type,sector),\n",
    "                                            \"count\":\"count_{}{}_dimensionless\".format(demand_type,sector)})\n",
    "            gdf_left  = gdf_left.merge(right=df_out,\n",
    "                                   how=\"left\",\n",
    "                                   left_index = True,\n",
    "                                   right_index = True)\n",
    "    gdf_out = gdf_left\n",
    "    df_out = pd.DataFrame(gdf_out.drop(\"geometry\",1))\n",
    "    output_file_path_no_ext = \"{}{}\".format(ec2_output_path,aqueduct_version)\n",
    "    \n",
    "    gdf_left.to_file(driver='ESRI Shapefile', filename=output_file_path_no_ext+\".shp\")\n",
    "    df_out.to_csv(output_file_path_no_ext+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!aws s3 cp {ec2_output_path} {s3_output_path} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous runs:  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 35",
   "language": "python",
   "name": "python35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
